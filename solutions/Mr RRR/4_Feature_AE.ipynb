{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4_Feature_AE_and_Submission (Step 4)\n",
        "# - Train AE using Step 3 Selection (cfcs top4), with test as valid\n",
        "# - Early stopping: patience=100, max_epochs=5000\n",
        "# - Save AE artifacts with _valid suffix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SEL2_TRAIN: e:\\Desktop\\Mr RRR_Helios Corn Futures Climate Challenge_Repo\\Data\\Selection\\train_cfcs_0.5_top4_2.parquet\n",
            "SEL2_TEST : e:\\Desktop\\Mr RRR_Helios Corn Futures Climate Challenge_Repo\\Data\\Selection\\test_cfcs_0.5_top4_2.parquet\n",
            "AE_TAG_2_VALID: ae_cfcs_0.5_top4_2_valid\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import sys\n",
        "import subprocess\n",
        "import random\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "except ModuleNotFoundError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"torch\"])\n",
        "    import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "# Reproducibility seed\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "pd.set_option(\"display.width\", 140)\n",
        "\n",
        "RISK_CATEGORIES = [\"heat_stress\", \"unseasonably_cold\", \"excess_precip\", \"drought\"]\n",
        "\n",
        "# Local / Kaggle compatibility\n",
        "if Path(\"/kaggle/input\").exists():\n",
        "    OUT_DIR = Path(\"/kaggle/working\")\n",
        "else:\n",
        "    OUT_DIR = Path.cwd()\n",
        "\n",
        "SEL_DIR = OUT_DIR / \"Data\" / \"Selection\"\n",
        "SEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --- Selection_2 (cfcs top4) ---\n",
        "SIGNIFICANCE_THRESHOLD = 0.5\n",
        "THRESH_TAG_2 = f\"{SIGNIFICANCE_THRESHOLD:.2f}\".rstrip(\"0\").rstrip(\".\")\n",
        "TAG_2 = f\"cfcs_{THRESH_TAG_2}_top4_2\"\n",
        "SEL2_TRAIN = SEL_DIR / f\"train_{TAG_2}.parquet\"\n",
        "SEL2_TEST = SEL_DIR / f\"test_{TAG_2}.parquet\"\n",
        "AE_TAG_2 = f\"ae_{TAG_2}\"\n",
        "AE_TAG_2_VALID = f\"{AE_TAG_2}_valid\"\n",
        "\n",
        "print(\"SEL2_TRAIN:\", SEL2_TRAIN)\n",
        "print(\"SEL2_TEST :\", SEL2_TEST)\n",
        "print(\"AE_TAG_2_VALID:\", AE_TAG_2_VALID)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, input_dim: int, latent_dim: int = 3):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, latent_dim),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, input_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        x_hat = self.decoder(z)\n",
        "        return x_hat, z\n",
        "\n",
        "\n",
        "def pick_ae_features(df: pd.DataFrame) -> list[str]:\n",
        "    features: list[str] = []\n",
        "\n",
        "    def _add(col: str):\n",
        "        if col in df.columns and col not in features:\n",
        "            features.append(col)\n",
        "\n",
        "    # Prefer engineered continuous features\n",
        "    for r in RISK_CATEGORIES:\n",
        "        _add(f\"climate_risk_{r}_score\")\n",
        "        _add(f\"climate_risk_{r}_change_7d\")\n",
        "        _add(f\"climate_risk_{r}_ma_14d\")\n",
        "        _add(f\"climate_risk_country_{r}_weighted_sum\")\n",
        "\n",
        "    _add(\"climate_risk_heat_drought_interact\")\n",
        "    _add(\"climate_risk_overall_weighted\")\n",
        "\n",
        "    # Fallback to all continuous climate_risk_ features if too few\n",
        "    if len(features) < 3:\n",
        "        fallback = [\n",
        "            c\n",
        "            for c in df.columns\n",
        "            if c.startswith(\"climate_risk_\")\n",
        "            and not c.endswith(\"_low\")\n",
        "            and not c.endswith(\"_med\")\n",
        "            and not c.endswith(\"_high\")\n",
        "        ]\n",
        "        for c in fallback:\n",
        "            _add(c)\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def add_ae_time_features(df: pd.DataFrame, base_cols: list[str]) -> list[str]:\n",
        "    # Keep only raw AE features; no extra time transforms\n",
        "    return list(base_cols)\n",
        "\n",
        "\n",
        "def compute_cfcs_official(\n",
        "    df: pd.DataFrame,\n",
        "    climate_cols: list[str],\n",
        "    futures_cols: list[str],\n",
        "    sig_th: float = 0.5,\n",
        ") -> dict:\n",
        "    if \"date_on\" not in df.columns:\n",
        "        raise ValueError(\"df missing date_on\")\n",
        "    if \"country_name\" not in df.columns:\n",
        "        raise ValueError(\"df missing country_name\")\n",
        "\n",
        "    date = pd.to_datetime(df[\"date_on\"], errors=\"coerce\")\n",
        "    ym = date.dt.to_period(\"M\")\n",
        "\n",
        "    corrs = []\n",
        "\n",
        "    for (country, period), g in df.assign(_ym=ym).groupby([\"country_name\", \"_ym\"], dropna=False):\n",
        "        c_cols = [c for c in climate_cols if g[c].std(ddof=0) > 0]\n",
        "        f_cols = [c for c in futures_cols if g[c].std(ddof=0) > 0]\n",
        "        if not c_cols or not f_cols:\n",
        "            continue\n",
        "\n",
        "        corr_mat = g[c_cols + f_cols].corr(method=\"pearson\")\n",
        "        block = corr_mat.loc[c_cols, f_cols].round(5).to_numpy().ravel()\n",
        "        corrs.extend(block[~np.isnan(block)])\n",
        "\n",
        "    if len(corrs) == 0:\n",
        "        return {\n",
        "            \"cfcs\": 0.0,\n",
        "            \"avg_sig_corr\": 0.0,\n",
        "            \"max_corr\": 0.0,\n",
        "            \"sig_pct\": 0.0,\n",
        "            \"sig_count\": 0,\n",
        "            \"total\": 0,\n",
        "        }\n",
        "\n",
        "    corrs = np.asarray(corrs)\n",
        "    abs_corrs = np.abs(corrs)\n",
        "    sig = abs_corrs[abs_corrs >= sig_th]\n",
        "\n",
        "    avg_sig = float(sig.mean()) if sig.size else 0.0\n",
        "    max_corr = float(abs_corrs.max())\n",
        "    sig_pct = float(sig.size / abs_corrs.size * 100.0)\n",
        "\n",
        "    avg_sig_score = min(100.0, avg_sig * 100.0)\n",
        "    max_score = min(100.0, max_corr * 100.0)\n",
        "\n",
        "    cfcs = (0.5 * avg_sig_score) + (0.3 * max_score) + (0.2 * sig_pct)\n",
        "\n",
        "    return {\n",
        "        \"cfcs\": round(cfcs, 4),\n",
        "        \"avg_sig_corr\": round(avg_sig, 6),\n",
        "        \"max_corr\": round(max_corr, 6),\n",
        "        \"sig_pct\": round(sig_pct, 6),\n",
        "        \"sig_count\": int(sig.size),\n",
        "        \"total\": int(abs_corrs.size),\n",
        "    }\n",
        "\n",
        "\n",
        "def run_ae_pipeline(\n",
        "    train_df: pd.DataFrame,\n",
        "    test_df: pd.DataFrame,\n",
        "    tag: str,\n",
        "    max_epochs: int = 200,\n",
        "    patience: int | None = None,\n",
        "    output_tag: str | None = None,\n",
        ") -> None:\n",
        "    ae_features = pick_ae_features(train_df)\n",
        "    print(f\"[{tag}] ae_features: {len(ae_features)}\")\n",
        "    if len(ae_features) < 3:\n",
        "        raise ValueError(f\"[{tag}] Not enough AE features (<3). Check input columns.\")\n",
        "\n",
        "    if \"date_on\" not in test_df.columns or \"country_name\" not in test_df.columns:\n",
        "        raise ValueError(\"test_df missing date_on or country_name; cannot compute CFCS\")\n",
        "\n",
        "    futures_cols = [c for c in test_df.columns if c.startswith(\"futures_\")]\n",
        "    if not futures_cols:\n",
        "        raise ValueError(\"test_df missing futures_ columns; cannot compute CFCS\")\n",
        "\n",
        "    X_train = train_df[ae_features].fillna(0.0)\n",
        "    X_test = test_df[ae_features].fillna(0.0)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    save_tag = output_tag or tag\n",
        "\n",
        "    joblib.dump(scaler, SEL_DIR / f\"ae_scaler_{save_tag}.joblib\")\n",
        "    pd.DataFrame({\"feature\": ae_features}).to_parquet(SEL_DIR / f\"ae_input_features_{save_tag}.parquet\", index=False)\n",
        "\n",
        "    torch.manual_seed(42)\n",
        "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "\n",
        "    model = AutoEncoder(input_dim=X_train_tensor.shape[1], latent_dim=3)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    base_ae_cols = [\n",
        "        \"climate_risk_ae_z1\",\n",
        "        \"climate_risk_ae_z2\",\n",
        "        \"climate_risk_ae_z3\",\n",
        "        \"climate_risk_ae_recon_error\",\n",
        "    ]\n",
        "\n",
        "    best_state = None\n",
        "    best_cfcs = float(\"-inf\")\n",
        "    best_epoch = -1\n",
        "    wait = 0\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        x_hat, _ = model(X_train_tensor)\n",
        "        loss = loss_fn(x_hat, X_train_tensor)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if patience is not None:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                x_hat_val, z_val = model(X_test_tensor)\n",
        "                recon = ((x_hat_val - X_test_tensor) ** 2).mean(dim=1).numpy()\n",
        "                z_val = z_val.numpy()\n",
        "\n",
        "            val_df = test_df[[\"country_name\", \"date_on\"] + futures_cols].copy()\n",
        "            val_df[\"climate_risk_ae_z1\"] = z_val[:, 0]\n",
        "            val_df[\"climate_risk_ae_z2\"] = z_val[:, 1]\n",
        "            val_df[\"climate_risk_ae_z3\"] = z_val[:, 2]\n",
        "            val_df[\"climate_risk_ae_recon_error\"] = recon\n",
        "\n",
        "            val_cfcs = compute_cfcs_official(\n",
        "                val_df,\n",
        "                climate_cols=base_ae_cols,\n",
        "                futures_cols=futures_cols,\n",
        "            )[\"cfcs\"]\n",
        "\n",
        "            if val_cfcs > best_cfcs + 1e-8:\n",
        "                best_cfcs = val_cfcs\n",
        "                best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "                best_epoch = epoch\n",
        "                wait = 0\n",
        "            else:\n",
        "                wait += 1\n",
        "\n",
        "            if epoch % 50 == 0:\n",
        "                print(f\"[{tag}] epoch {epoch}, train_loss={loss.item():.6f}, cfcs={val_cfcs:.4f}, best={best_cfcs:.4f}\")\n",
        "\n",
        "            if wait >= patience:\n",
        "                print(f\"[{tag}] early stop at epoch {epoch}, best_epoch={best_epoch}, best_cfcs={best_cfcs:.4f}\")\n",
        "                break\n",
        "        else:\n",
        "            if epoch % 50 == 0:\n",
        "                print(f\"[{tag}] epoch {epoch}, loss={loss.item():.6f}\")\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    torch.save(model.state_dict(), SEL_DIR / f\"ae_model_{save_tag}.pth\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _, z_train = model(X_train_tensor)\n",
        "        xhat_train, _ = model(X_train_tensor)\n",
        "        _, z_test = model(X_test_tensor)\n",
        "        xhat_test, _ = model(X_test_tensor)\n",
        "\n",
        "    z_train = z_train.numpy()\n",
        "    z_test = z_test.numpy()\n",
        "\n",
        "    train_df[\"climate_risk_ae_z1\"] = z_train[:, 0]\n",
        "    train_df[\"climate_risk_ae_z2\"] = z_train[:, 1]\n",
        "    train_df[\"climate_risk_ae_z3\"] = z_train[:, 2]\n",
        "    test_df[\"climate_risk_ae_z1\"] = z_test[:, 0]\n",
        "    test_df[\"climate_risk_ae_z2\"] = z_test[:, 1]\n",
        "    test_df[\"climate_risk_ae_z3\"] = z_test[:, 2]\n",
        "\n",
        "    train_df[\"climate_risk_ae_recon_error\"] = ((xhat_train - X_train_tensor) ** 2).mean(dim=1).numpy()\n",
        "    test_df[\"climate_risk_ae_recon_error\"] = ((xhat_test - X_test_tensor) ** 2).mean(dim=1).numpy()\n",
        "\n",
        "    ae_cols = add_ae_time_features(train_df, base_ae_cols)\n",
        "    _ = add_ae_time_features(test_df, base_ae_cols)\n",
        "\n",
        "    pd.DataFrame({\"feature\": ae_cols}).to_parquet(SEL_DIR / f\"selected_features_ae_{save_tag}.parquet\", index=False)\n",
        "\n",
        "    key_cols = [c for c in [\"ID\", \"date_on\", \"country_name\", \"region_name\", \"region_id\"] if c in train_df.columns]\n",
        "    futures_cols = [c for c in train_df.columns if c.startswith(\"futures_\")]\n",
        "\n",
        "    keep_cols = key_cols + ae_cols + futures_cols\n",
        "    keep_cols = [c for c in keep_cols if c in train_df.columns]\n",
        "\n",
        "    train_out = train_df[keep_cols].copy()\n",
        "    test_out = test_df[keep_cols].copy()\n",
        "\n",
        "    train_out.to_parquet(SEL_DIR / f\"train_ae_{save_tag}.parquet\", index=False)\n",
        "    test_out.to_parquet(SEL_DIR / f\"test_ae_{save_tag}.parquet\", index=False)\n",
        "\n",
        "    print(f\"[{save_tag}] saved train_ae/test_ae + selected_features_ae\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sel2 train (exclude last 90d): (247805, 26) test: (64691, 26)\n",
            "[ae_cfcs_0.5_top4_2] ae_features: 4\n",
            "[ae_cfcs_0.5_top4_2] epoch 0, train_loss=1.075589, cfcs=65.9457, best=65.9457\n",
            "[ae_cfcs_0.5_top4_2] epoch 50, train_loss=0.898554, cfcs=65.8220, best=66.2882\n",
            "[ae_cfcs_0.5_top4_2] epoch 100, train_loss=0.467929, cfcs=65.0134, best=66.4525\n",
            "[ae_cfcs_0.5_top4_2] epoch 150, train_loss=0.067967, cfcs=64.5696, best=66.4525\n",
            "[ae_cfcs_0.5_top4_2] early stop at epoch 155, best_epoch=55, best_cfcs=66.4525\n",
            "[ae_cfcs_0.5_top4_2_valid] saved train_ae/test_ae + selected_features_ae\n"
          ]
        }
      ],
      "source": [
        "# === Selection_2 (cfcs top4) ===\n",
        "\n",
        "assert SEL2_TRAIN.exists(), f\"missing: {SEL2_TRAIN}\"\n",
        "assert SEL2_TEST.exists(), f\"missing: {SEL2_TEST}\"\n",
        "\n",
        "train_df_2 = pd.read_parquet(SEL2_TRAIN)\n",
        "test_df_2 = pd.read_parquet(SEL2_TEST)\n",
        "\n",
        "# Exclude last 90 days from train\n",
        "if \"date_on\" not in train_df_2.columns:\n",
        "    raise ValueError(\"train_df_2 missing date_on; cannot filter by time\")\n",
        "\n",
        "train_df_2 = train_df_2.copy()\n",
        "train_df_2[\"date_on\"] = pd.to_datetime(train_df_2[\"date_on\"], errors=\"coerce\")\n",
        "max_date = train_df_2[\"date_on\"].max()\n",
        "cutoff = max_date - pd.Timedelta(days=90)\n",
        "train_df_2 = train_df_2[train_df_2[\"date_on\"] <= cutoff].copy()\n",
        "\n",
        "print(\"sel2 train (exclude last 90d):\", train_df_2.shape, \"test:\", test_df_2.shape)\n",
        "\n",
        "run_ae_pipeline(\n",
        "    train_df_2,\n",
        "    test_df_2,\n",
        "    AE_TAG_2,\n",
        "    max_epochs=5000,\n",
        "    patience=100,\n",
        "    output_tag=AE_TAG_2_VALID,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.13.6)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
