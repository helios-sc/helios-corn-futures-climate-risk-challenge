{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1_Data_Processing (Step 1)\n",
        "# - Load raw data (competition CSV)\n",
        "# - Forward-fill NaN for climate/futures by region_id + date_on time series\n",
        "# - Drop rows where futures_* are still missing (no trading day)\n",
        "# - Save to Data/Processing/processed.parquet\n",
        "# - Create valid_ids.parquet (used for Step 4 submission alignment)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATA_DIR: e:\\Desktop\\Mr RRR_Helios Corn Futures Climate Challenge_Repo\\forecasting-the-future-the-helios-corn-climate-challenge\n",
            "OUT_DIR : e:\\Desktop\\Mr RRR_Helios Corn Futures Climate Challenge_Repo\n",
            "RAW_MAIN: True e:\\Desktop\\Mr RRR_Helios Corn Futures Climate Challenge_Repo\\forecasting-the-future-the-helios-corn-climate-challenge\\corn_climate_risk_futures_daily_master.csv\n",
            "RAW_SHARE: True e:\\Desktop\\Mr RRR_Helios Corn Futures Climate Challenge_Repo\\forecasting-the-future-the-helios-corn-climate-challenge\\corn_regional_market_share.csv\n",
            "PROC_DIR: e:\\Desktop\\Mr RRR_Helios Corn Futures Climate Challenge_Repo\\Data\\Processing\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "pd.set_option(\"display.width\", 140)\n",
        "\n",
        "# Local / Kaggle compatibility\n",
        "if Path(\"/kaggle/input\").exists():\n",
        "    DATA_DIR = Path(\"/kaggle/input/forecasting-the-future-the-helios-corn-climate-challenge\")\n",
        "    OUT_DIR = Path(\"/kaggle/working\")\n",
        "else:\n",
        "    BASE_DIR = Path.cwd()\n",
        "    DATA_DIR = BASE_DIR / \"forecasting-the-future-the-helios-corn-climate-challenge\"\n",
        "    OUT_DIR = BASE_DIR\n",
        "\n",
        "RAW_MAIN = DATA_DIR / \"corn_climate_risk_futures_daily_master.csv\"\n",
        "RAW_SHARE = DATA_DIR / \"corn_regional_market_share.csv\"\n",
        "\n",
        "PROC_DIR = OUT_DIR / \"Data\" / \"Processing\"\n",
        "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"DATA_DIR:\", DATA_DIR)\n",
        "print(\"OUT_DIR :\", OUT_DIR)\n",
        "print(\"RAW_MAIN:\", RAW_MAIN.exists(), RAW_MAIN)\n",
        "print(\"RAW_SHARE:\", RAW_SHARE.exists(), RAW_SHARE)\n",
        "print(\"PROC_DIR:\", PROC_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "raw df: (320661, 41)\n",
            "date_on null: 0\n",
            "date range: 2016-01-01 00:00:00 ~ 2025-12-15 00:00:00\n",
            "climate cols: 12\n",
            "futures cols: 17\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "\n",
        "df = pd.read_csv(RAW_MAIN, low_memory=False)\n",
        "df[\"date_on\"] = pd.to_datetime(df[\"date_on\"], errors=\"coerce\")\n",
        "\n",
        "print(\"raw df:\", df.shape)\n",
        "print(\"date_on null:\", int(df[\"date_on\"].isna().sum()))\n",
        "print(\"date range:\", df[\"date_on\"].min(), \"~\", df[\"date_on\"].max())\n",
        "\n",
        "climate_cols = [c for c in df.columns if c.startswith(\"climate_risk_\")]\n",
        "futures_cols = [c for c in df.columns if c.startswith(\"futures_\")]\n",
        "\n",
        "print(\"climate cols:\", len(climate_cols))\n",
        "print(\"futures cols:\", len(futures_cols))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "after ffill: climate NaN total: 0\n",
            "after ffill: futures NaN total: 3638\n"
          ]
        }
      ],
      "source": [
        "# Forward-fill NaN: apply ffill to climate_risk_* and futures_* (by region_id)\n",
        "# Then set remaining climate NaN to 0 (usually at the series start)\n",
        "\n",
        "KEY_COLS = [\"ID\", \"region_id\", \"date_on\"]\n",
        "ffill_cols = [c for c in (climate_cols + futures_cols) if c not in KEY_COLS]\n",
        "\n",
        "work = df.sort_values([\"region_id\", \"date_on\"]).copy()\n",
        "work[ffill_cols] = work.groupby(\"region_id\")[ffill_cols].ffill()\n",
        "\n",
        "# Remaining climate NaN -> 0\n",
        "work[climate_cols] = work[climate_cols].fillna(0)\n",
        "\n",
        "print(\"after ffill: climate NaN total:\", int(work[climate_cols].isna().sum().sum()))\n",
        "print(\"after ffill: futures NaN total:\", int(work[futures_cols].isna().sum().sum()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rows before: 320661\n",
            "rows after dropna(futures): 320447\n",
            "saved: e:\\Desktop\\Mr RRR_Helios Corn Futures Climate Challenge_Repo\\Data\\Processing\\processed.parquet\n",
            "saved: e:\\Desktop\\Mr RRR_Helios Corn Futures Climate Challenge_Repo\\Data\\Processing\\valid_ids.parquet | unique IDs: 320447\n"
          ]
        }
      ],
      "source": [
        "# Drop rows with missing futures_* and save parquet\n",
        "\n",
        "before_rows = len(work)\n",
        "work_valid = work.dropna(subset=futures_cols).copy()\n",
        "\n",
        "print(\"rows before:\", before_rows)\n",
        "print(\"rows after dropna(futures):\", len(work_valid))\n",
        "\n",
        "out_path = PROC_DIR / \"processed.parquet\"\n",
        "work_valid.to_parquet(out_path, index=False)\n",
        "print(\"saved:\", out_path)\n",
        "\n",
        "# Save valid ID list (for later submission alignment)\n",
        "valid_ids_path = PROC_DIR / \"valid_ids.parquet\"\n",
        "(\n",
        "    pd.DataFrame({\"ID\": work_valid[\"ID\"].astype(str)})\n",
        "    .drop_duplicates()\n",
        "    .to_parquet(valid_ids_path, index=False)\n",
        ")\n",
        "print(\"saved:\", valid_ids_path, \"| unique IDs:\", work_valid[\"ID\"].nunique())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.13.6)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
