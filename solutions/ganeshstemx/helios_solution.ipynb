{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa7a49f2",
   "metadata": {
    "_cell_guid": "4d228ec3-c3b0-47e3-bb75-f9a97bc7195b",
    "_uuid": "70f29106-2432-4abc-bcbe-fd44909b4db8",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:24.566237Z",
     "iopub.status.busy": "2026-01-30T16:52:24.565738Z",
     "iopub.status.idle": "2026-01-30T16:52:24.571402Z",
     "shell.execute_reply": "2026-01-30T16:52:24.570542Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.020667,
     "end_time": "2026-01-30T16:52:24.573502",
     "exception": false,
     "start_time": "2026-01-30T16:52:24.552835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helios Corn Futures Climate Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14ac1d66",
   "metadata": {
    "_cell_guid": "305db4d4-8fba-473d-b1ce-b880fb0fbf97",
    "_uuid": "80de6d05-3278-4484-aaff-2d7fddad8509",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:24.593476Z",
     "iopub.status.busy": "2026-01-30T16:52:24.593145Z",
     "iopub.status.idle": "2026-01-30T16:52:27.748328Z",
     "shell.execute_reply": "2026-01-30T16:52:27.746900Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.173593,
     "end_time": "2026-01-30T16:52:27.756465",
     "exception": false,
     "start_time": "2026-01-30T16:52:24.582872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " HELIOS CORN FUTURES CLIMATE CHALLENGE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" HELIOS CORN FUTURES CLIMATE CHALLENGE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Risk categories and levels\n",
    "RISK_CATEGORIES = ['heat_stress', 'unseasonably_cold', 'excess_precip', 'drought']\n",
    "RISK_LEVELS = ['low', 'medium', 'high']\n",
    "\n",
    "# Feature analysis settings\n",
    "SIGNIFICANCE_THRESHOLD = 0.6\n",
    "TOP_N_FEATURES = 5  # Use top N features for scoring\n",
    "\n",
    "# Feature selection strategy: 'sig_count', 'max_corr', 'avg_sig_corr', or 'weighted'\n",
    "FEATURE_SELECTION_STRATEGY = 'sig_count'\n",
    "\n",
    "# Correlation thresholds for feature removal\n",
    "CORRELATION_THRESHOLD_GENERAL = 0.98  # Remove features with >= 98% correlation\n",
    "CORRELATION_THRESHOLD_SPECIFIC = 0.70  # Remove features correlated with specific features in FEATURES_TO_REMOVE list\n",
    "\n",
    "# Specific features to remove (and their >= 70% correlated counterparts)\n",
    "FEATURES_TO_REMOVE = [\n",
    "    \"climate_risk_country_quartile_std_excess_precip_risk_medium\",\n",
    "    \"climate_risk_quartile_agg_excess_precip_risk_medium_std\",\n",
    "    \"climate_risk_quartile_agg_heat_stress_risk_medium_mean\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac2ae982",
   "metadata": {
    "_cell_guid": "b28b30e8-644c-4189-9db0-cd00e4f72dd8",
    "_uuid": "3801e636-dc87-40e7-ae39-b6cc3d1772fb",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:27.778592Z",
     "iopub.status.busy": "2026-01-30T16:52:27.778086Z",
     "iopub.status.idle": "2026-01-30T16:52:27.782838Z",
     "shell.execute_reply": "2026-01-30T16:52:27.781883Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017498,
     "end_time": "2026-01-30T16:52:27.784841",
     "exception": false,
     "start_time": "2026-01-30T16:52:27.767343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data paths\n",
    "DATA_PATH = '/kaggle/input/forecasting-the-future-the-helios-corn-climate-challenge/'\n",
    "OUTPUT_PATH = '/kaggle/working/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3f4a5ca",
   "metadata": {
    "_cell_guid": "dd32de7b-5cbf-42a1-b28b-8c5627ab3f8c",
    "_uuid": "7f60ece2-ca53-4c15-bae1-3df6ad588726",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:27.806669Z",
     "iopub.status.busy": "2026-01-30T16:52:27.805949Z",
     "iopub.status.idle": "2026-01-30T16:52:27.836041Z",
     "shell.execute_reply": "2026-01-30T16:52:27.834903Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.043168,
     "end_time": "2026-01-30T16:52:27.838386",
     "exception": false,
     "start_time": "2026-01-30T16:52:27.795218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FEATURE ENGINEERING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def quarter_to_date(year, quarter):\n",
    "    \"\"\"Convert year-quarter to the first date of that quarter.\"\"\"\n",
    "    month = (quarter - 1) * 3 + 1  # Q1=1, Q2=4, Q3=7, Q4=10\n",
    "    return pd.Timestamp(year=year, month=month, day=1)\n",
    "\n",
    "\n",
    "def create_time_bins(df, date_col, quarters_per_bin, bin_name,\n",
    "                     start_year, start_quarter, end_year, end_quarter, verbose=True):\n",
    "    \"\"\"\n",
    "    Create time-based bins for temporal grouping.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame - Input dataframe\n",
    "    date_col : str - Name of the date column\n",
    "    quarters_per_bin : int - Number of quarters per bin\n",
    "    bin_name : str - Name for the bin column (e.g., 'decile', 'tredecile')\n",
    "    start_year, start_quarter : int - Start of date range\n",
    "    end_year, end_quarter : int - End of date range\n",
    "    verbose : bool - Whether to print configuration details\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Series with bin assignments\n",
    "    \"\"\"\n",
    "    total_quarters = (end_year - start_year) * 4 + (end_quarter - start_quarter) + 1\n",
    "    num_bins = int(np.ceil(total_quarters / quarters_per_bin))\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\n{bin_name.upper()} Configuration:\")\n",
    "        print(f\"Quarters per bin: {quarters_per_bin}\")\n",
    "        print(f\"Number of bins: {num_bins}\")\n",
    "\n",
    "    # Generate bin boundaries\n",
    "    bin_boundaries = []\n",
    "    current_year, current_quarter = start_year, start_quarter\n",
    "    bin_boundaries.append(quarter_to_date(current_year, current_quarter))\n",
    "\n",
    "    for _ in range(num_bins):\n",
    "        new_quarter = current_quarter + quarters_per_bin\n",
    "        new_year = current_year + (new_quarter - 1) // 4\n",
    "        new_quarter = ((new_quarter - 1) % 4) + 1\n",
    "        bin_boundaries.append(quarter_to_date(new_year, new_quarter))\n",
    "        current_year, current_quarter = new_year, new_quarter\n",
    "\n",
    "    # Extend last boundary to cover remaining dates\n",
    "    bin_boundaries[-1] = pd.Timestamp(year=end_year + 1, month=1, day=1)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Bin boundaries:\")\n",
    "        for i in range(num_bins):\n",
    "            print(f\"Bin {i}: {bin_boundaries[i].date()} to {bin_boundaries[i+1].date()}\")\n",
    "\n",
    "    return pd.cut(df[date_col], bins=bin_boundaries, labels=False, include_lowest=True).fillna(0).astype(int)\n",
    "\n",
    "\n",
    "def create_groupby_agg_features(df, source_cols, groupby_cols, agg_funcs,\n",
    "                                feature_prefix, created_features_list):\n",
    "    \"\"\"\n",
    "    Create groupby aggregation features for climate risk data.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame - Input dataframe (modified in place)\n",
    "    source_cols : list - Source columns to aggregate (climate_risk_cnt_locations_*)\n",
    "    groupby_cols : list - Columns to group by\n",
    "    agg_funcs : list - Aggregation functions ['max', 'mean', 'std', etc.]\n",
    "    feature_prefix : str - Prefix for feature names (e.g., 'climate_risk_groupby_date_decile')\n",
    "    created_features_list : list - List to append created feature names to\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    int - Number of features created\n",
    "    \"\"\"\n",
    "    feature_count = 0\n",
    "    for source_col in source_cols:\n",
    "        # Extract risk type name from source column\n",
    "        risk_name = source_col.replace('climate_risk_cnt_locations_', '')\n",
    "\n",
    "        for agg_func in agg_funcs:\n",
    "            feat_name = f'{feature_prefix}_{risk_name}_{agg_func}'\n",
    "            df[feat_name] = df.groupby(groupby_cols)[source_col].transform(agg_func)\n",
    "            df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "            created_features_list.append(feat_name)\n",
    "            feature_count += 1\n",
    "\n",
    "    return feature_count\n",
    "\n",
    "\n",
    "def create_spatial_std_features(df, source_cols, date_col, feature_prefix, created_features_list):\n",
    "    \"\"\"\n",
    "    Create spatial standard deviation features (std across regions on same date).\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame - Input dataframe (modified in place)\n",
    "    source_cols : list - Source columns to compute std for\n",
    "    date_col : str - Date column name for grouping\n",
    "    feature_prefix : str - Prefix for feature names (e.g., 'climate_risk_spatial_std_date_decile')\n",
    "    created_features_list : list - List to append created feature names to\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    int - Number of features created\n",
    "    \"\"\"\n",
    "    feature_count = 0\n",
    "    for source_col in source_cols:\n",
    "        risk_name = source_col.replace('climate_risk_cnt_locations_', '')\n",
    "        feat_name = f'{feature_prefix}_{risk_name}'\n",
    "        df[feat_name] = df.groupby(date_col)[source_col].transform('std')\n",
    "        df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "        created_features_list.append(feat_name)\n",
    "        feature_count += 1\n",
    "\n",
    "    return feature_count\n",
    "\n",
    "\n",
    "def create_groupby_std_features(df, source_cols, groupby_cols, feature_prefix, created_features_list):\n",
    "    \"\"\"\n",
    "    Create groupby standard deviation features (std within specified groups).\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame - Input dataframe (modified in place)\n",
    "    source_cols : list - Source columns to compute std for\n",
    "    groupby_cols : list - Columns to group by (e.g., ['country_name', 'time_bin'])\n",
    "    feature_prefix : str - Prefix for feature names\n",
    "    created_features_list : list - List to append created feature names to\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    int - Number of features created\n",
    "    \"\"\"\n",
    "    feature_count = 0\n",
    "    for source_col in source_cols:\n",
    "        risk_name = source_col.replace('climate_risk_cnt_locations_', '')\n",
    "        feat_name = f'{feature_prefix}_{risk_name}'\n",
    "        df[feat_name] = df.groupby(groupby_cols)[source_col].transform('std')\n",
    "        df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "        created_features_list.append(feat_name)\n",
    "        feature_count += 1\n",
    "\n",
    "    return feature_count\n",
    "\n",
    "\n",
    "def create_categorical_encoding(df, source_col, feature_name, created_features_list):\n",
    "    \"\"\"\n",
    "    Create encoded feature from categorical column.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame - Input dataframe (modified in place)\n",
    "    source_col : str - Source categorical column\n",
    "    feature_name : str - Name for the encoded feature\n",
    "    created_features_list : list - List to append created feature names to\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    int - Number of features created (always 1)\n",
    "    \"\"\"\n",
    "    category_map = {val: idx for idx, val in enumerate(df[source_col].unique())}\n",
    "    df[feature_name] = df[source_col].map(category_map)\n",
    "    created_features_list.append(feature_name)\n",
    "    return 1\n",
    "\n",
    "\n",
    "def create_risk_score_features(df, risk_categories, feature_prefix, created_features_list,\n",
    "                                weights=(1, 2, 3)):\n",
    "    \"\"\"\n",
    "    Create weighted risk score features combining low/medium/high counts.\n",
    "\n",
    "    Score = (low * w1 + medium * w2 + high * w3) / (low + medium + high + epsilon)\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame - Input dataframe (modified in place)\n",
    "    risk_categories : list - Risk category names (e.g., ['heat_stress', 'drought'])\n",
    "    feature_prefix : str - Prefix for feature names\n",
    "    created_features_list : list - List to append created feature names to\n",
    "    weights : tuple - Weights for (low, medium, high) risk levels\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    int - Number of features created\n",
    "    \"\"\"\n",
    "    feature_count = 0\n",
    "    w_low, w_med, w_high = weights\n",
    "\n",
    "    for risk_type in risk_categories:\n",
    "        low_col = f'climate_risk_cnt_locations_{risk_type}_risk_low'\n",
    "        med_col = f'climate_risk_cnt_locations_{risk_type}_risk_medium'\n",
    "        high_col = f'climate_risk_cnt_locations_{risk_type}_risk_high'\n",
    "\n",
    "        # Weighted risk score\n",
    "        total = df[low_col] + df[med_col] + df[high_col]\n",
    "        feat_name = f'{feature_prefix}_{risk_type}_score'\n",
    "        df[feat_name] = (df[low_col] * w_low + df[med_col] * w_med + df[high_col] * w_high) / (total + 1e-6)\n",
    "        df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "        created_features_list.append(feat_name)\n",
    "        feature_count += 1\n",
    "\n",
    "        # High risk ratio\n",
    "        feat_name = f'{feature_prefix}_{risk_type}_high_ratio'\n",
    "        df[feat_name] = df[high_col] / (total + 1e-6)\n",
    "        df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "        created_features_list.append(feat_name)\n",
    "        feature_count += 1\n",
    "\n",
    "    return feature_count\n",
    "\n",
    "\n",
    "def create_cross_risk_features(df, risk_pairs, feature_prefix, created_features_list):\n",
    "    \"\"\"\n",
    "    Create cross-risk interaction features (compound stress indicators).\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame - Input dataframe (modified in place)\n",
    "    risk_pairs : list of tuples - Pairs of risk types to combine, e.g., [('heat_stress', 'drought')]\n",
    "    feature_prefix : str - Prefix for feature names\n",
    "    created_features_list : list - List to append created feature names to\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    int - Number of features created\n",
    "    \"\"\"\n",
    "    feature_count = 0\n",
    "\n",
    "    for risk1, risk2 in risk_pairs:\n",
    "        for level in ['high', 'medium']:\n",
    "            col1 = f'climate_risk_cnt_locations_{risk1}_risk_{level}'\n",
    "            col2 = f'climate_risk_cnt_locations_{risk2}_risk_{level}'\n",
    "\n",
    "            # Product interaction (compound stress)\n",
    "            feat_name = f'{feature_prefix}_{risk1}_{risk2}_{level}_product'\n",
    "            df[feat_name] = df[col1] * df[col2]\n",
    "            df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "            created_features_list.append(feat_name)\n",
    "            feature_count += 1\n",
    "\n",
    "            # Sum interaction (combined stress)\n",
    "            feat_name = f'{feature_prefix}_{risk1}_{risk2}_{level}_sum'\n",
    "            df[feat_name] = df[col1] + df[col2]\n",
    "            df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "            created_features_list.append(feat_name)\n",
    "            feature_count += 1\n",
    "\n",
    "            # Max interaction (dominant stress)\n",
    "            feat_name = f'{feature_prefix}_{risk1}_{risk2}_{level}_max'\n",
    "            df[feat_name] = df[[col1, col2]].max(axis=1)\n",
    "            df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "            created_features_list.append(feat_name)\n",
    "            feature_count += 1\n",
    "\n",
    "    return feature_count\n",
    "\n",
    "\n",
    "def create_country_agg_features(df, source_cols, date_col, country_col, agg_funcs,\n",
    "                                 feature_prefix, created_features_list):\n",
    "    \"\"\"\n",
    "    Create country-level aggregation features (aggregate regional risks to country level).\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame - Input dataframe (modified in place)\n",
    "    source_cols : list - Source columns to aggregate\n",
    "    date_col : str - Date column name\n",
    "    country_col : str - Country column name\n",
    "    agg_funcs : list - Aggregation functions ['mean', 'max', 'sum', 'std']\n",
    "    feature_prefix : str - Prefix for feature names\n",
    "    created_features_list : list - List to append created feature names to\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    int - Number of features created\n",
    "    \"\"\"\n",
    "    feature_count = 0\n",
    "\n",
    "    for source_col in source_cols:\n",
    "        risk_name = source_col.replace('climate_risk_cnt_locations_', '')\n",
    "\n",
    "        for agg_func in agg_funcs:\n",
    "            feat_name = f'{feature_prefix}_{risk_name}_{agg_func}'\n",
    "            df[feat_name] = df.groupby([country_col, date_col])[source_col].transform(agg_func)\n",
    "            df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "            created_features_list.append(feat_name)\n",
    "            feature_count += 1\n",
    "\n",
    "    return feature_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cc31aa6",
   "metadata": {
    "_cell_guid": "3d762d7f-064d-4ed1-8975-18633499c9d9",
    "_uuid": "1d603d63-b7b6-4200-bcfc-00de0bb0276d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:27.858629Z",
     "iopub.status.busy": "2026-01-30T16:52:27.858326Z",
     "iopub.status.idle": "2026-01-30T16:52:31.458057Z",
     "shell.execute_reply": "2026-01-30T16:52:31.456905Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.61273,
     "end_time": "2026-01-30T16:52:31.460469",
     "exception": false,
     "start_time": "2026-01-30T16:52:27.847739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data...\n",
      "Dataset: 320,661 rows\n",
      "Date range: 2016-01-01 00:00:00 to 2025-12-15 00:00:00\n",
      "Countries: 11\n",
      "Regions: 89\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"\\nLoading data...\")\n",
    "df = pd.read_csv(f'{DATA_PATH}corn_climate_risk_futures_daily_master.csv')\n",
    "df['date_on'] = pd.to_datetime(df['date_on'])\n",
    "market_share_df = pd.read_csv(f'{DATA_PATH}corn_regional_market_share.csv')\n",
    "\n",
    "print(f\"Dataset: {len(df):,} rows\")\n",
    "print(f\"Date range: {df['date_on'].min()} to {df['date_on'].max()}\")\n",
    "print(f\"Countries: {df['country_name'].nunique()}\")\n",
    "print(f\"Regions: {df['region_name'].nunique()}\")\n",
    "\n",
    "# Create working copy\n",
    "merged_df = df.copy()\n",
    "\n",
    "# Add basic temporal features\n",
    "merged_df['year'] = merged_df['date_on'].dt.year\n",
    "merged_df['month'] = merged_df['date_on'].dt.month\n",
    "merged_df['day_of_year'] = merged_df['date_on'].dt.dayofyear\n",
    "merged_df['quarter'] = merged_df['date_on'].dt.quarter\n",
    "merged_df['week_of_year'] = merged_df['date_on'].dt.isocalendar().week\n",
    "\n",
    "# Merge market share\n",
    "merged_df = merged_df.merge(\n",
    "    market_share_df[['region_id', 'percent_country_production']],\n",
    "    on='region_id', how='left'\n",
    ")\n",
    "merged_df['percent_country_production'] = merged_df['percent_country_production'].fillna(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb13388b",
   "metadata": {
    "_cell_guid": "2722ba89-cc58-4a75-afe5-5d431831a38f",
    "_uuid": "2472b8f4-5287-449e-9f9f-e95e897e9770",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:31.491897Z",
     "iopub.status.busy": "2026-01-30T16:52:31.491470Z",
     "iopub.status.idle": "2026-01-30T16:52:31.507941Z",
     "shell.execute_reply": "2026-01-30T16:52:31.506466Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.035672,
     "end_time": "2026-01-30T16:52:31.510364",
     "exception": false,
     "start_time": "2026-01-30T16:52:31.474692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base setup complete: 320,661 rows\n",
      "\n",
      "================================================================================\n",
      " CREATING CLIMATE RISK FEATURES\n",
      "================================================================================\n",
      "\n",
      "Base climate risk columns: 12\n",
      "\n",
      "Data date range: 2016-01-01 to 2025-12-15\n",
      "Start: 2016 Q1, End: 2025 Q4\n",
      "Total quarters in data: 40\n"
     ]
    }
   ],
   "source": [
    "# Track all created features\n",
    "ALL_NEW_FEATURES = []\n",
    "\n",
    "print(f\"\\nBase setup complete: {len(merged_df):,} rows\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" CREATING CLIMATE RISK FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get all climate risk count columns\n",
    "climate_cols = [c for c in merged_df.columns if c.startswith('climate_risk_cnt_locations_')]\n",
    "print(f\"\\nBase climate risk columns: {len(climate_cols)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# TIME-BASED BINNING CONFIGURATION\n",
    "# ============================================================================\n",
    "# Derive date range dynamically from the dataset\n",
    "_min_date = merged_df['date_on'].min()\n",
    "_max_date = merged_df['date_on'].max()\n",
    "\n",
    "_start_year = _min_date.year\n",
    "_start_quarter = (_min_date.month - 1) // 3 + 1\n",
    "_end_year = _max_date.year\n",
    "_end_quarter = (_max_date.month - 1) // 3 + 1\n",
    "\n",
    "total_quarters = (_end_year - _start_year) * 4 + (_end_quarter - _start_quarter) + 1\n",
    "print(f\"\\nData date range: {_min_date.date()} to {_max_date.date()}\")\n",
    "print(f\"Start: {_start_year} Q{_start_quarter}, End: {_end_year} Q{_end_quarter}\")\n",
    "print(f\"Total quarters in data: {total_quarters}\")\n",
    "\n",
    "TIME_BIN_CONFIG = {\n",
    "    'start_year': _start_year,\n",
    "    'start_quarter': _start_quarter,\n",
    "    'end_year': _end_year,\n",
    "    'end_quarter': _end_quarter,\n",
    "    # Use ceiling division to produce exactly N bins (last bin may be smaller)\n",
    "    'quarters_per_tertile': max(1, -(-total_quarters // 3)),       # → 3 bins\n",
    "    'quarters_per_quartile': max(1, -(-total_quarters // 4)),      # → 4 bins\n",
    "    'quarters_per_quintile': max(1, -(-total_quarters // 5)),      # → 5 bins\n",
    "    'quarters_per_sextile': max(1, -(-total_quarters // 6)),       # → 6 bins\n",
    "    'quarters_per_octile': max(1, -(-total_quarters // 8)),        # → 8 bins\n",
    "    'quarters_per_decile': max(1, -(-total_quarters // 10)),       # → 10 bins\n",
    "    'quarters_per_tredecile': max(1, -(-total_quarters // 13)),    # → 13 bins\n",
    "    'quarters_per_vigintile': max(1, -(-total_quarters // 20)),    # → 20 bins\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d09c545",
   "metadata": {
    "_cell_guid": "014322d6-32c7-4b26-9e9d-46e6a653f06a",
    "_uuid": "0a7cd84b-2983-4995-abc4-06b181249582",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:31.534248Z",
     "iopub.status.busy": "2026-01-30T16:52:31.533781Z",
     "iopub.status.idle": "2026-01-30T16:52:31.618279Z",
     "shell.execute_reply": "2026-01-30T16:52:31.616880Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.099101,
     "end_time": "2026-01-30T16:52:31.620471",
     "exception": false,
     "start_time": "2026-01-30T16:52:31.521370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating time bins for all -ile divisions.\n",
      "\n",
      "TERTILE Configuration:\n",
      "Quarters per bin: 14\n",
      "Number of bins: 3\n",
      "Bin boundaries:\n",
      "Bin 0: 2016-01-01 to 2019-07-01\n",
      "Bin 1: 2019-07-01 to 2023-01-01\n",
      "Bin 2: 2023-01-01 to 2026-01-01\n",
      "\n",
      "QUARTILE Configuration:\n",
      "Quarters per bin: 10\n",
      "Number of bins: 4\n",
      "Bin boundaries:\n",
      "Bin 0: 2016-01-01 to 2018-07-01\n",
      "Bin 1: 2018-07-01 to 2021-01-01\n",
      "Bin 2: 2021-01-01 to 2023-07-01\n",
      "Bin 3: 2023-07-01 to 2026-01-01\n",
      "\n",
      "QUINTILE Configuration:\n",
      "Quarters per bin: 8\n",
      "Number of bins: 5\n",
      "Bin boundaries:\n",
      "Bin 0: 2016-01-01 to 2018-01-01\n",
      "Bin 1: 2018-01-01 to 2020-01-01\n",
      "Bin 2: 2020-01-01 to 2022-01-01\n",
      "Bin 3: 2022-01-01 to 2024-01-01\n",
      "Bin 4: 2024-01-01 to 2026-01-01\n",
      "\n",
      "SEXTILE Configuration:\n",
      "Quarters per bin: 7\n",
      "Number of bins: 6\n",
      "Bin boundaries:\n",
      "Bin 0: 2016-01-01 to 2017-10-01\n",
      "Bin 1: 2017-10-01 to 2019-07-01\n",
      "Bin 2: 2019-07-01 to 2021-04-01\n",
      "Bin 3: 2021-04-01 to 2023-01-01\n",
      "Bin 4: 2023-01-01 to 2024-10-01\n",
      "Bin 5: 2024-10-01 to 2026-01-01\n",
      "\n",
      "OCTILE Configuration:\n",
      "Quarters per bin: 5\n",
      "Number of bins: 8\n",
      "Bin boundaries:\n",
      "Bin 0: 2016-01-01 to 2017-04-01\n",
      "Bin 1: 2017-04-01 to 2018-07-01\n",
      "Bin 2: 2018-07-01 to 2019-10-01\n",
      "Bin 3: 2019-10-01 to 2021-01-01\n",
      "Bin 4: 2021-01-01 to 2022-04-01\n",
      "Bin 5: 2022-04-01 to 2023-07-01\n",
      "Bin 6: 2023-07-01 to 2024-10-01\n",
      "Bin 7: 2024-10-01 to 2026-01-01\n",
      "\n",
      "DECILE Configuration:\n",
      "Quarters per bin: 4\n",
      "Number of bins: 10\n",
      "Bin boundaries:\n",
      "Bin 0: 2016-01-01 to 2017-01-01\n",
      "Bin 1: 2017-01-01 to 2018-01-01\n",
      "Bin 2: 2018-01-01 to 2019-01-01\n",
      "Bin 3: 2019-01-01 to 2020-01-01\n",
      "Bin 4: 2020-01-01 to 2021-01-01\n",
      "Bin 5: 2021-01-01 to 2022-01-01\n",
      "Bin 6: 2022-01-01 to 2023-01-01\n",
      "Bin 7: 2023-01-01 to 2024-01-01\n",
      "Bin 8: 2024-01-01 to 2025-01-01\n",
      "Bin 9: 2025-01-01 to 2026-01-01\n",
      "\n",
      "TREDECILE Configuration:\n",
      "Quarters per bin: 4\n",
      "Number of bins: 10\n",
      "Bin boundaries:\n",
      "Bin 0: 2016-01-01 to 2017-01-01\n",
      "Bin 1: 2017-01-01 to 2018-01-01\n",
      "Bin 2: 2018-01-01 to 2019-01-01\n",
      "Bin 3: 2019-01-01 to 2020-01-01\n",
      "Bin 4: 2020-01-01 to 2021-01-01\n",
      "Bin 5: 2021-01-01 to 2022-01-01\n",
      "Bin 6: 2022-01-01 to 2023-01-01\n",
      "Bin 7: 2023-01-01 to 2024-01-01\n",
      "Bin 8: 2024-01-01 to 2025-01-01\n",
      "Bin 9: 2025-01-01 to 2026-01-01\n",
      "\n",
      "VIGINTILE Configuration:\n",
      "Quarters per bin: 2\n",
      "Number of bins: 20\n",
      "Bin boundaries:\n",
      "Bin 0: 2016-01-01 to 2016-07-01\n",
      "Bin 1: 2016-07-01 to 2017-01-01\n",
      "Bin 2: 2017-01-01 to 2017-07-01\n",
      "Bin 3: 2017-07-01 to 2018-01-01\n",
      "Bin 4: 2018-01-01 to 2018-07-01\n",
      "Bin 5: 2018-07-01 to 2019-01-01\n",
      "Bin 6: 2019-01-01 to 2019-07-01\n",
      "Bin 7: 2019-07-01 to 2020-01-01\n",
      "Bin 8: 2020-01-01 to 2020-07-01\n",
      "Bin 9: 2020-07-01 to 2021-01-01\n",
      "Bin 10: 2021-01-01 to 2021-07-01\n",
      "Bin 11: 2021-07-01 to 2022-01-01\n",
      "Bin 12: 2022-01-01 to 2022-07-01\n",
      "Bin 13: 2022-07-01 to 2023-01-01\n",
      "Bin 14: 2023-01-01 to 2023-07-01\n",
      "Bin 15: 2023-07-01 to 2024-01-01\n",
      "Bin 16: 2024-01-01 to 2024-07-01\n",
      "Bin 17: 2024-07-01 to 2025-01-01\n",
      "Bin 18: 2025-01-01 to 2025-07-01\n",
      "Bin 19: 2025-07-01 to 2026-01-01\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CREATE ALL TIME BINS\n",
    "# ============================================================================\n",
    "print(\"\\nCreating time bins for all -ile divisions.\")\n",
    "\n",
    "BIN_TYPES = [\n",
    "    \"tertile\",\n",
    "    \"quartile\",\n",
    "    \"quintile\",\n",
    "    \"sextile\",\n",
    "    \"octile\",\n",
    "    \"decile\",\n",
    "    \"tredecile\",\n",
    "    \"vigintile\",\n",
    "]\n",
    "\n",
    "COMMON_KWARGS = dict(\n",
    "    start_year=TIME_BIN_CONFIG[\"start_year\"],\n",
    "    start_quarter=TIME_BIN_CONFIG[\"start_quarter\"],\n",
    "    end_year=TIME_BIN_CONFIG[\"end_year\"],\n",
    "    end_quarter=TIME_BIN_CONFIG[\"end_quarter\"],\n",
    ")\n",
    "\n",
    "for bin_name in BIN_TYPES:\n",
    "    merged_df[f\"climate_risk_time_bin_{bin_name}\"] = create_time_bins(\n",
    "        merged_df,\n",
    "        \"date_on\",\n",
    "        quarters_per_bin=TIME_BIN_CONFIG[f\"quarters_per_{bin_name}\"],\n",
    "        bin_name=bin_name,\n",
    "        **COMMON_KWARGS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eaf5257",
   "metadata": {
    "_cell_guid": "e0560ca7-16d7-4e03-94ce-b271359170e0",
    "_uuid": "2ce37faa-cb45-4dda-8a6d-a0f7fde0a633",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:31.642455Z",
     "iopub.status.busy": "2026-01-30T16:52:31.642082Z",
     "iopub.status.idle": "2026-01-30T16:52:32.299096Z",
     "shell.execute_reply": "2026-01-30T16:52:32.297575Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.670642,
     "end_time": "2026-01-30T16:52:32.301534",
     "exception": false,
     "start_time": "2026-01-30T16:52:31.630892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Date Decile Groupby Features\n",
      "Creating spatial std features...\n",
      "Creating country-decile std features...\n",
      "Created 20 decile-based features\n"
     ]
    }
   ],
   "source": [
    "# DATE DECILE GROUPBY FEATURES\n",
    "# ============================================================================\n",
    "print(\"\\nDate Decile Groupby Features\")\n",
    "feature_count = 0\n",
    "\n",
    "# Define high-impact risk features for decile aggregation\n",
    "HIGH_IMPACT_RISK_COLS = [\n",
    "    'climate_risk_cnt_locations_heat_stress_risk_high',\n",
    "    'climate_risk_cnt_locations_drought_risk_high',\n",
    "    'climate_risk_cnt_locations_drought_risk_medium',\n",
    "    'climate_risk_cnt_locations_excess_precip_risk_medium',\n",
    "    'climate_risk_cnt_locations_heat_stress_risk_medium'\n",
    "]\n",
    "\n",
    "# Create groupby aggregation features using generic function\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=HIGH_IMPACT_RISK_COLS,\n",
    "    groupby_cols=['climate_risk_time_bin_decile', 'country_name'],\n",
    "    agg_funcs=['max', 'mean'],\n",
    "    feature_prefix='climate_risk_decile_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "\n",
    "# Create spatial std features (variation across regions on same date)\n",
    "print(\"Creating spatial std features...\")\n",
    "feature_count += create_spatial_std_features(\n",
    "    df=merged_df,\n",
    "    source_cols=HIGH_IMPACT_RISK_COLS,\n",
    "    date_col='date_on',\n",
    "    feature_prefix='climate_risk_spatial_std',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "# Create country-decile std features (variation within country-period groups)\n",
    "print(\"Creating country-decile std features...\")\n",
    "feature_count += create_groupby_std_features(\n",
    "    df=merged_df,\n",
    "    source_cols=HIGH_IMPACT_RISK_COLS,\n",
    "    groupby_cols=['country_name', 'climate_risk_time_bin_decile'],\n",
    "    feature_prefix='climate_risk_country_decile_std',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(f\"Created {feature_count} decile-based features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25fdfac6",
   "metadata": {
    "_cell_guid": "8e020456-a8f8-41b4-8a03-0d700092e096",
    "_uuid": "7904b72e-1b41-4ba3-aeef-4158596f41a2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:32.323722Z",
     "iopub.status.busy": "2026-01-30T16:52:32.323192Z",
     "iopub.status.idle": "2026-01-30T16:52:33.421323Z",
     "shell.execute_reply": "2026-01-30T16:52:33.419930Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.111577,
     "end_time": "2026-01-30T16:52:33.423611",
     "exception": false,
     "start_time": "2026-01-30T16:52:32.312034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Low-Risk Level Features\n",
      "Creating decile aggregation features...\n",
      "Creating spatial std features...\n",
      "Creating country-decile std features...\n",
      "Created 24 low-severity risk features\n"
     ]
    }
   ],
   "source": [
    "# LOW-RISK LEVEL FEATURES (Cold Stress and Low-Severity Risks)\n",
    "# ============================================================================\n",
    "print(\"\\nLow-Risk Level Features\")\n",
    "feature_count = 0\n",
    "\n",
    "# Define low-severity and cold stress risk columns\n",
    "LOW_SEVERITY_RISK_COLS = [\n",
    "    'climate_risk_cnt_locations_unseasonably_cold_risk_high',\n",
    "    'climate_risk_cnt_locations_unseasonably_cold_risk_medium',\n",
    "    'climate_risk_cnt_locations_unseasonably_cold_risk_low',\n",
    "    'climate_risk_cnt_locations_heat_stress_risk_low',\n",
    "    'climate_risk_cnt_locations_drought_risk_low',\n",
    "    'climate_risk_cnt_locations_excess_precip_risk_low',\n",
    "]\n",
    "\n",
    "# Decile-based aggregations (region-level)\n",
    "print(\"Creating decile aggregation features...\")\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=LOW_SEVERITY_RISK_COLS,\n",
    "    groupby_cols=['country_name', 'region_name', 'climate_risk_time_bin_decile'],\n",
    "    agg_funcs=['max', 'mean'],\n",
    "    feature_prefix='climate_risk_decile_region_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "# Spatial std features for low-severity risks\n",
    "print(\"Creating spatial std features...\")\n",
    "feature_count += create_spatial_std_features(\n",
    "    df=merged_df,\n",
    "    source_cols=LOW_SEVERITY_RISK_COLS,\n",
    "    date_col='date_on',\n",
    "    feature_prefix='climate_risk_low_severity_spatial_std',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "# Country-decile std features for low-severity risks\n",
    "print(\"Creating country-decile std features...\")\n",
    "feature_count += create_groupby_std_features(\n",
    "    df=merged_df,\n",
    "    source_cols=LOW_SEVERITY_RISK_COLS,\n",
    "    groupby_cols=['country_name', 'climate_risk_time_bin_decile'],\n",
    "    feature_prefix='climate_risk_low_severity_country_decile_std',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(f\"Created {feature_count} low-severity risk features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34f5cf87",
   "metadata": {
    "_cell_guid": "27517b27-44c3-4977-ac8c-c20b56af2970",
    "_uuid": "1b4331fc-3a9d-42a8-ba44-0a01d71a305a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:33.446682Z",
     "iopub.status.busy": "2026-01-30T16:52:33.446361Z",
     "iopub.status.idle": "2026-01-30T16:52:34.663716Z",
     "shell.execute_reply": "2026-01-30T16:52:34.661890Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.232652,
     "end_time": "2026-01-30T16:52:34.666332",
     "exception": false,
     "start_time": "2026-01-30T16:52:33.433680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "High-Impact Tredecile Features\n",
      "Creating tredecile country-weekly aggregation features...\n",
      "Created 30 high-impact tredecile features\n"
     ]
    }
   ],
   "source": [
    "# HIGH-IMPACT TREDECILE FEATURES\n",
    "# ============================================================================\n",
    "print(\"\\nHigh-Impact Tredecile Features\")\n",
    "feature_count = 0\n",
    "\n",
    "# Define medium and high severity risk columns for tredecile analysis\n",
    "MEDIUM_HIGH_SEVERITY_RISK_COLS = [\n",
    "    # Heat Stress Risk\n",
    "    'climate_risk_cnt_locations_heat_stress_risk_medium',\n",
    "    'climate_risk_cnt_locations_heat_stress_risk_high',\n",
    "    # Excess Precipitation Risk\n",
    "    'climate_risk_cnt_locations_excess_precip_risk_medium',\n",
    "    'climate_risk_cnt_locations_excess_precip_risk_high',\n",
    "    # Drought Risk\n",
    "    'climate_risk_cnt_locations_drought_risk_medium',\n",
    "    'climate_risk_cnt_locations_drought_risk_high'\n",
    "]\n",
    "\n",
    "# Tredecile-based country-weekly aggregations\n",
    "print(\"Creating tredecile country-weekly aggregation features...\")\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=MEDIUM_HIGH_SEVERITY_RISK_COLS,\n",
    "    groupby_cols=['climate_risk_time_bin_tredecile', 'country_name'],\n",
    "    agg_funcs=['max', 'min', 'std', 'var', 'mean'],\n",
    "    feature_prefix='climate_risk_tredecile_country_weekly_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(f\"Created {feature_count} high-impact tredecile features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d171ead",
   "metadata": {
    "_cell_guid": "f97095bf-8525-4446-9fad-d2f42eee13c7",
    "_uuid": "d3bfcd0a-514b-4f07-b148-7d35c34d2299",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:34.689088Z",
     "iopub.status.busy": "2026-01-30T16:52:34.688040Z",
     "iopub.status.idle": "2026-01-30T16:52:34.733438Z",
     "shell.execute_reply": "2026-01-30T16:52:34.732035Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.059535,
     "end_time": "2026-01-30T16:52:34.736278",
     "exception": false,
     "start_time": "2026-01-30T16:52:34.676743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Categorical Encoded Features\n",
      "Creating harvest period encoding...\n",
      "Created 1 categorical encoded features\n"
     ]
    }
   ],
   "source": [
    "# CATEGORICAL ENCODED FEATURES\n",
    "# ============================================================================\n",
    "print(\"\\nCategorical Encoded Features\")\n",
    "feature_count = 0\n",
    "\n",
    "# Encode harvest period (categorical → numerical)\n",
    "print(\"Creating harvest period encoding...\")\n",
    "feature_count += create_categorical_encoding(\n",
    "    df=merged_df,\n",
    "    source_col='harvest_period',\n",
    "    feature_name='climate_risk_harvest_period_encoded',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(f\"Created {feature_count} categorical encoded features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39df4eb0",
   "metadata": {
    "_cell_guid": "27a7f1af-73bc-47a4-afe6-d166cba55ab6",
    "_uuid": "d1594ab0-c060-4b6b-ab14-d677bdfcd1c4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:34.760288Z",
     "iopub.status.busy": "2026-01-30T16:52:34.759310Z",
     "iopub.status.idle": "2026-01-30T16:52:34.841472Z",
     "shell.execute_reply": "2026-01-30T16:52:34.840380Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.096093,
     "end_time": "2026-01-30T16:52:34.844075",
     "exception": false,
     "start_time": "2026-01-30T16:52:34.747982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Risk Score Features\n",
      "Creating risk score features...\n",
      "Created 8 risk score features\n"
     ]
    }
   ],
   "source": [
    "# RISK SCORE FEATURES\n",
    "# ============================================================================\n",
    "print(\"\\nRisk Score Features\")\n",
    "feature_count = 0\n",
    "\n",
    "# Create weighted risk scores for all risk categories\n",
    "print(\"Creating risk score features...\")\n",
    "feature_count += create_risk_score_features(\n",
    "    df=merged_df,\n",
    "    risk_categories=RISK_CATEGORIES,\n",
    "    feature_prefix='climate_risk',\n",
    "    created_features_list=ALL_NEW_FEATURES,\n",
    "    weights=(1, 2, 3)  # low=1, medium=2, high=3\n",
    ")\n",
    "\n",
    "print(f\"Created {feature_count} risk score features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db572005",
   "metadata": {
    "_cell_guid": "9ec972dd-3745-4446-ac3e-c541a30e748a",
    "_uuid": "3d2d7bb3-6480-4841-8d35-805e0b3e2684",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:34.867543Z",
     "iopub.status.busy": "2026-01-30T16:52:34.866586Z",
     "iopub.status.idle": "2026-01-30T16:52:35.197356Z",
     "shell.execute_reply": "2026-01-30T16:52:35.196054Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.345187,
     "end_time": "2026-01-30T16:52:35.200112",
     "exception": false,
     "start_time": "2026-01-30T16:52:34.854925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Risk Interaction Features\n",
      "Creating cross-risk interaction features...\n",
      "Created 18 cross-risk interaction features\n"
     ]
    }
   ],
   "source": [
    "# CROSS-RISK INTERACTION FEATURES\n",
    "# ============================================================================\n",
    "print(\"\\nCross-Risk Interaction Features\")\n",
    "feature_count = 0\n",
    "\n",
    "# Define meaningful risk pairs (compound stress scenarios)\n",
    "RISK_PAIRS = [\n",
    "    ('heat_stress', 'drought'),           # Hot + dry = severe crop stress\n",
    "    ('heat_stress', 'excess_precip'),     # Hot + wet = disease risk\n",
    "    ('unseasonably_cold', 'excess_precip'), # Cold + wet = frost/flooding\n",
    "    ('drought', 'heat_stress'),           # Already covered above, skip\n",
    "]\n",
    "# Remove duplicate pair\n",
    "RISK_PAIRS = [\n",
    "    ('heat_stress', 'drought'),\n",
    "    ('heat_stress', 'excess_precip'),\n",
    "    ('unseasonably_cold', 'excess_precip'),\n",
    "]\n",
    "\n",
    "print(\"Creating cross-risk interaction features...\")\n",
    "feature_count += create_cross_risk_features(\n",
    "    df=merged_df,\n",
    "    risk_pairs=RISK_PAIRS,\n",
    "    feature_prefix='climate_risk_interaction',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(f\"Created {feature_count} cross-risk interaction features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af282448",
   "metadata": {
    "_cell_guid": "918c0a80-259b-4e0a-8e74-5b1f87c7bdc4",
    "_uuid": "6253add1-2de0-449e-81a5-04e01848e21a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:35.222689Z",
     "iopub.status.busy": "2026-01-30T16:52:35.222323Z",
     "iopub.status.idle": "2026-01-30T16:52:35.807739Z",
     "shell.execute_reply": "2026-01-30T16:52:35.806249Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.600187,
     "end_time": "2026-01-30T16:52:35.810661",
     "exception": false,
     "start_time": "2026-01-30T16:52:35.210474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Country-Level Aggregation Features\n",
      "Creating country-level aggregation features...\n",
      "Created 12 country-level aggregation features\n"
     ]
    }
   ],
   "source": [
    "# COUNTRY-LEVEL AGGREGATION FEATURES\n",
    "# ============================================================================\n",
    "print(\"\\nCountry-Level Aggregation Features\")\n",
    "feature_count = 0\n",
    "\n",
    "# Select key risk columns for country-level aggregation\n",
    "COUNTRY_AGG_RISK_COLS = [\n",
    "    'climate_risk_cnt_locations_heat_stress_risk_high',\n",
    "    'climate_risk_cnt_locations_drought_risk_high',\n",
    "    'climate_risk_cnt_locations_excess_precip_risk_high',\n",
    "    'climate_risk_cnt_locations_unseasonably_cold_risk_high',\n",
    "]\n",
    "\n",
    "print(\"Creating country-level aggregation features...\")\n",
    "feature_count += create_country_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=COUNTRY_AGG_RISK_COLS,\n",
    "    date_col='date_on',\n",
    "    country_col='country_name',\n",
    "    agg_funcs=['mean', 'max', 'sum'],\n",
    "    feature_prefix='climate_risk_country_daily',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(f\"Created {feature_count} country-level aggregation features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed7d6bdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:35.834340Z",
     "iopub.status.busy": "2026-01-30T16:52:35.833359Z",
     "iopub.status.idle": "2026-01-30T16:52:42.143278Z",
     "shell.execute_reply": "2026-01-30T16:52:42.142112Z"
    },
    "papermill": {
     "duration": 6.323983,
     "end_time": "2026-01-30T16:52:42.145670",
     "exception": false,
     "start_time": "2026-01-30T16:52:35.821687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantile-Based Features\n",
      "\n",
      " Creating tertile-based features...\n",
      " Completed tertile features\n",
      "\n",
      " Creating quartile-based features...\n",
      " Completed quartile features\n",
      "\n",
      " Creating quintile-based features...\n",
      " Completed quintile features\n",
      "\n",
      " Creating sextile-based features...\n",
      " Completed sextile features\n",
      "\n",
      " Creating octile-based features...\n",
      " Completed octile features\n",
      "\n",
      " Creating decile-based features...\n",
      " Completed decile features\n",
      "\n",
      " Creating tredecile-based features...\n",
      " Completed tredecile features\n",
      "\n",
      " Creating vigintile-based features...\n",
      " Completed vigintile features\n",
      "Created 160 quartile-based features\n"
     ]
    }
   ],
   "source": [
    "# QUANTILE-BASED FEATURES\n",
    "# ============================================================================\n",
    "quantile_config = {\n",
    "    \"tertile\": \"climate_risk_time_bin_tertile\",\n",
    "    \"quartile\": \"climate_risk_time_bin_quartile\",\n",
    "    \"quintile\": \"climate_risk_time_bin_quintile\",\n",
    "    \"sextile\": \"climate_risk_time_bin_sextile\",\n",
    "    \"octile\": \"climate_risk_time_bin_octile\",\n",
    "    \"decile\": \"climate_risk_time_bin_decile\",\n",
    "    \"tredecile\": \"climate_risk_time_bin_tredecile\",\n",
    "    \"vigintile\": \"climate_risk_time_bin_vigintile\",\n",
    "}\n",
    "\n",
    "\n",
    "print(\"\\nQuantile-Based Features\")\n",
    "feature_count = 0\n",
    "\n",
    "for quantile_name, quantile_col in quantile_config.items():\n",
    "\n",
    "    print(f\"\\n Creating {quantile_name}-based features...\")\n",
    "\n",
    "    # Aggregation features\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=HIGH_IMPACT_RISK_COLS,\n",
    "        groupby_cols=[quantile_col, 'country_name'],\n",
    "        agg_funcs=['max', 'mean', 'std'],\n",
    "        feature_prefix=f'climate_risk_{quantile_name}_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "    # Country–quantile standard deviation features\n",
    "    feature_count += create_groupby_std_features(\n",
    "        df=merged_df,\n",
    "        source_cols=HIGH_IMPACT_RISK_COLS,\n",
    "        groupby_cols=['country_name', quantile_col],\n",
    "        feature_prefix=f'climate_risk_country_{quantile_name}_std',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "    print(f\" Completed {quantile_name} features\")\n",
    "\n",
    "print(f\"Created {feature_count} quartile-based features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab1c5d46",
   "metadata": {
    "_cell_guid": "b8420589-d705-41be-9410-e9799f60a122",
    "_uuid": "46b1a2d1-ba98-4939-b015-9f44371fb100",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:42.170580Z",
     "iopub.status.busy": "2026-01-30T16:52:42.170015Z",
     "iopub.status.idle": "2026-01-30T16:52:42.682529Z",
     "shell.execute_reply": "2026-01-30T16:52:42.681021Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.528473,
     "end_time": "2026-01-30T16:52:42.685238",
     "exception": false,
     "start_time": "2026-01-30T16:52:42.156765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Country-Relative Binning Features\n",
      "Creating country-relative bin features...\n",
      "Created 5 country-relative bin features\n"
     ]
    }
   ],
   "source": [
    "# COUNTRY-RELATIVE BINNING FEATURES\n",
    "# ============================================================================\n",
    "print(\"\\n Country-Relative Binning Features\")\n",
    "feature_count = 0\n",
    "\n",
    "def create_country_relative_bins(df, source_cols, country_col, date_col, feature_prefix,\n",
    "                                  created_features_list):\n",
    "    \"\"\"\n",
    "    Create bins relative to country-level distribution on same date.\n",
    "    \"\"\"\n",
    "    feat_count = 0\n",
    "\n",
    "    for source_col in source_cols:\n",
    "        risk_name = source_col.replace('climate_risk_cnt_locations_', '')\n",
    "        feat_name = f'{feature_prefix}_country_rel_bin_{risk_name}'\n",
    "\n",
    "        # Calculate country-date mean and std\n",
    "        country_mean = df.groupby([country_col, date_col])[source_col].transform('mean')\n",
    "        country_std = df.groupby([country_col, date_col])[source_col].transform('std')\n",
    "\n",
    "        # Relative deviation from country mean\n",
    "        relative_val = (df[source_col] - country_mean) / (country_std + 1e-6)\n",
    "\n",
    "        # Bin the relative values\n",
    "        bins = [-np.inf, -2, -1, 1, 2, np.inf]\n",
    "        df[feat_name] = pd.cut(relative_val, bins=bins, labels=[0, 1, 2, 3, 4])\n",
    "        df[feat_name] = df[feat_name].fillna(2).astype(int)\n",
    "        created_features_list.append(feat_name)\n",
    "        feat_count += 1\n",
    "\n",
    "    return feat_count\n",
    "\n",
    "# Country-relative bins for high-impact risks\n",
    "print(\"Creating country-relative bin features...\")\n",
    "feature_count += create_country_relative_bins(\n",
    "    df=merged_df,\n",
    "    source_cols=HIGH_IMPACT_RISK_COLS,\n",
    "    country_col='country_name',\n",
    "    date_col='date_on',\n",
    "    feature_prefix='climate_risk',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(f\"Created {feature_count} country-relative bin features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9075e446",
   "metadata": {
    "_cell_guid": "08aa3c94-b846-4202-a57a-64d114c9ecdb",
    "_uuid": "cf36d4e6-53c2-41bc-b1ea-76b085398f7e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:42.709582Z",
     "iopub.status.busy": "2026-01-30T16:52:42.709035Z",
     "iopub.status.idle": "2026-01-30T16:52:43.938308Z",
     "shell.execute_reply": "2026-01-30T16:52:43.937098Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.244135,
     "end_time": "2026-01-30T16:52:43.940458",
     "exception": false,
     "start_time": "2026-01-30T16:52:42.696323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Enhanced Country Time-Bin Std Features\n",
      "\n",
      " Enhanced Country Time-Bin Std Features\n",
      "Creating country-tertile std for drought/heat...\n",
      "Creating country-quartile std for drought/heat...\n",
      "Creating country-quintile std for drought/heat...\n",
      "Creating country-sextile std for drought/heat...\n",
      "Creating country-octile std for drought/heat...\n",
      "Creating country-decile std for drought/heat...\n",
      "Creating country-tredecile std for drought/heat...\n",
      "Creating country-vigintile std for drought/heat...\n",
      "Created 32 enhanced country time-bin std features\n"
     ]
    }
   ],
   "source": [
    "#  COUNTRY TIME-BIN STD FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n Enhanced Country Time-Bin Std Features\")\n",
    "feature_count = 0\n",
    "\n",
    "# Focus on drought and heat stress\n",
    "DROUGHT_HEAT_COLS = [\n",
    "    'climate_risk_cnt_locations_drought_risk_high',\n",
    "    'climate_risk_cnt_locations_drought_risk_medium',\n",
    "    'climate_risk_cnt_locations_heat_stress_risk_high',\n",
    "    'climate_risk_cnt_locations_heat_stress_risk_medium',\n",
    "]\n",
    "\n",
    "print(\"\\n Enhanced Country Time-Bin Std Features\")\n",
    "feature_count = 0\n",
    "\n",
    "for quantile_name, quantile_col in quantile_config.items():\n",
    "\n",
    "    print(f\"Creating country-{quantile_name} std for drought/heat...\")\n",
    "\n",
    "    feature_count += create_groupby_std_features(\n",
    "        df=merged_df,\n",
    "        source_cols=DROUGHT_HEAT_COLS,\n",
    "        groupby_cols=['country_name', quantile_col],\n",
    "        feature_prefix=f'climate_risk_country_{quantile_name}_std',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "print(f\"Created {feature_count} enhanced country time-bin std features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7cce448",
   "metadata": {
    "_cell_guid": "da810a00-38d5-4fba-8263-3fff786cc891",
    "_uuid": "4250a4ae-2765-4484-9b21-b2c274bff95b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:43.966421Z",
     "iopub.status.busy": "2026-01-30T16:52:43.966109Z",
     "iopub.status.idle": "2026-01-30T16:52:53.444029Z",
     "shell.execute_reply": "2026-01-30T16:52:53.442853Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 9.493441,
     "end_time": "2026-01-30T16:52:53.446217",
     "exception": false,
     "start_time": "2026-01-30T16:52:43.952776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Region-Weighted Risk Features\n",
      "Creating production-weighted risk features...\n",
      "Creating weighted aggregations by country-quintile...\n",
      "\n",
      "Quantile-Based Weighted Risk Aggregations\n",
      "Creating tertile weighted risk aggregation features...\n",
      "Creating quartile weighted risk aggregation features...\n",
      "Creating quintile weighted risk aggregation features...\n",
      "Creating sextile weighted risk aggregation features...\n",
      "Creating octile weighted risk aggregation features...\n",
      "Creating decile weighted risk aggregation features...\n",
      "Creating tredecile weighted risk aggregation features...\n",
      "Creating vigintile weighted risk aggregation features...\n",
      "Created 240 quantile-based weighted risk features\n"
     ]
    }
   ],
   "source": [
    "#  REGION-WEIGHTED RISK FEATURES\n",
    "# ============================================================================\n",
    "# Weight climate risk by regional production importance\n",
    "print(\"\\n Region-Weighted Risk Features\")\n",
    "feature_count = 0\n",
    "\n",
    "def create_production_weighted_features(df, source_cols, weight_col, feature_prefix,\n",
    "                                        created_features_list):\n",
    "    \"\"\"\n",
    "    Create features weighted by regional production importance.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame - Input dataframe (modified in place)\n",
    "    source_cols : list - Source columns to weight\n",
    "    weight_col : str - Column containing weights (e.g., percent_country_production)\n",
    "    feature_prefix : str - Prefix for feature names\n",
    "    created_features_list : list - List to append created feature names to\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    int - Number of features created\n",
    "    \"\"\"\n",
    "    feat_count = 0\n",
    "\n",
    "    for source_col in source_cols:\n",
    "        risk_name = source_col.replace('climate_risk_cnt_locations_', '')\n",
    "\n",
    "        # Production-weighted risk\n",
    "        feat_name = f'{feature_prefix}_weighted_{risk_name}'\n",
    "        df[feat_name] = df[source_col] * (df[weight_col] / 100)\n",
    "        df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "        created_features_list.append(feat_name)\n",
    "        feat_count += 1\n",
    "\n",
    "    return feat_count\n",
    "\n",
    "# Create production-weighted features for high-impact risks\n",
    "print(\"Creating production-weighted risk features...\")\n",
    "feature_count += create_production_weighted_features(\n",
    "    df=merged_df,\n",
    "    source_cols=HIGH_IMPACT_RISK_COLS,\n",
    "    weight_col='percent_country_production',\n",
    "    feature_prefix='climate_risk',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "# Aggregate weighted features by country-time bin\n",
    "print(\"Creating weighted aggregations by country-quintile...\")\n",
    "weighted_cols = [f'climate_risk_weighted_{c.replace(\"climate_risk_cnt_locations_\", \"\")}'\n",
    "                 for c in HIGH_IMPACT_RISK_COLS]\n",
    "\n",
    "print(\"\\nQuantile-Based Weighted Risk Aggregations\")\n",
    "feature_count = 0\n",
    "\n",
    "valid_weighted_cols = [c for c in weighted_cols if c in merged_df.columns]\n",
    "\n",
    "for quantile_name, quantile_col in quantile_config.items():\n",
    "\n",
    "    print(f\"Creating {quantile_name} weighted risk aggregation features...\")\n",
    "\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=valid_weighted_cols,\n",
    "        groupby_cols=['country_name', quantile_col],\n",
    "        agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        feature_prefix=f'climate_risk_{quantile_name}_weighted_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "print(f\"Created {feature_count} quantile-based weighted risk features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3faaef02",
   "metadata": {
    "_cell_guid": "e503e5ce-1bb1-4b3f-aaa1-63607fe930e1",
    "_uuid": "6efddde6-f0cd-4ad7-b35c-e686802b9c59",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:53.472469Z",
     "iopub.status.busy": "2026-01-30T16:52:53.471462Z",
     "iopub.status.idle": "2026-01-30T16:52:55.299617Z",
     "shell.execute_reply": "2026-01-30T16:52:55.298374Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.843739,
     "end_time": "2026-01-30T16:52:55.302152",
     "exception": false,
     "start_time": "2026-01-30T16:52:53.458413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Seasonal Aggregation Features\n",
      "Creating month-country aggregations...\n",
      "Creating quarter-country aggregations...\n",
      "Created 48 seasonal aggregation features\n"
     ]
    }
   ],
   "source": [
    "#  SEASONAL AGGREGATION FEATURES\n",
    "# ============================================================================\n",
    "# Capture seasonal patterns in climate risk (no lagging, just groupby month/quarter)\n",
    "print(\"\\n Seasonal Aggregation Features\")\n",
    "feature_count = 0\n",
    "\n",
    "# Month-based aggregations for drought/heat (seasonal patterns)\n",
    "print(\"Creating month-country aggregations...\")\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=DROUGHT_HEAT_COLS,\n",
    "    groupby_cols=['country_name', 'month'],\n",
    "    agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "    feature_prefix='climate_risk_monthly_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "# Quarter-based aggregations\n",
    "print(\"Creating quarter-country aggregations...\")\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=DROUGHT_HEAT_COLS,\n",
    "    groupby_cols=['country_name', 'quarter'],\n",
    "    agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "    feature_prefix='climate_risk_quarterly_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Created {feature_count} seasonal aggregation features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bb5ae22",
   "metadata": {
    "_cell_guid": "220f7f09-fe4d-43db-8acc-3121c7d98d2e",
    "_uuid": "4149c7c2-8254-4c4c-92fd-a71aca88cf03",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:52:55.333004Z",
     "iopub.status.busy": "2026-01-30T16:52:55.332627Z",
     "iopub.status.idle": "2026-01-30T16:53:10.747880Z",
     "shell.execute_reply": "2026-01-30T16:53:10.745781Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 15.432232,
     "end_time": "2026-01-30T16:53:10.750228",
     "exception": false,
     "start_time": "2026-01-30T16:52:55.317996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Risk Ratio and Proportion Features\n",
      "Creating risk ratio features...\n",
      "\n",
      "Quantile-Based Risk Ratio Aggregations\n",
      "Aggregating 8 ratio features by country-tertile...\n",
      "Aggregating 8 ratio features by country-quartile...\n",
      "Aggregating 8 ratio features by country-quintile...\n",
      "Aggregating 8 ratio features by country-sextile...\n",
      "Aggregating 8 ratio features by country-octile...\n",
      "Aggregating 8 ratio features by country-decile...\n",
      "Aggregating 8 ratio features by country-tredecile...\n",
      "Aggregating 8 ratio features by country-vigintile...\n",
      "Created 384 quantile-based risk ratio features\n"
     ]
    }
   ],
   "source": [
    "# RISK RATIO AND PROPORTION FEATURES\n",
    "# ============================================================================\n",
    "# Capture relative intensity of different risk levels\n",
    "print(\"\\n Risk Ratio and Proportion Features\")\n",
    "feature_count = 0\n",
    "\n",
    "def create_risk_ratio_features(df, risk_categories, feature_prefix, created_features_list):\n",
    "    \"\"\"\n",
    "    Create ratio features between different risk levels.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame - Input dataframe (modified in place)\n",
    "    risk_categories : list - Risk category names\n",
    "    feature_prefix : str - Prefix for feature names\n",
    "    created_features_list : list - List to append created feature names to\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    int - Number of features created\n",
    "    \"\"\"\n",
    "    feat_count = 0\n",
    "\n",
    "    for risk_type in risk_categories:\n",
    "        low_col = f'climate_risk_cnt_locations_{risk_type}_risk_low'\n",
    "        med_col = f'climate_risk_cnt_locations_{risk_type}_risk_medium'\n",
    "        high_col = f'climate_risk_cnt_locations_{risk_type}_risk_high'\n",
    "\n",
    "        total = df[low_col] + df[med_col] + df[high_col] + 1e-6\n",
    "\n",
    "        # High to medium ratio\n",
    "        feat_name = f'{feature_prefix}_{risk_type}_high_med_ratio'\n",
    "        df[feat_name] = df[high_col] / (df[med_col] + 1e-6)\n",
    "        df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0).clip(0, 100)\n",
    "        created_features_list.append(feat_name)\n",
    "        feat_count += 1\n",
    "\n",
    "        # High proportion of total\n",
    "        feat_name = f'{feature_prefix}_{risk_type}_high_proportion'\n",
    "        df[feat_name] = df[high_col] / total\n",
    "        df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "        created_features_list.append(feat_name)\n",
    "        feat_count += 1\n",
    "\n",
    "        # Medium + High proportion (elevated risk)\n",
    "        feat_name = f'{feature_prefix}_{risk_type}_elevated_proportion'\n",
    "        df[feat_name] = (df[med_col] + df[high_col]) / total\n",
    "        df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "        created_features_list.append(feat_name)\n",
    "        feat_count += 1\n",
    "\n",
    "        # High dominance (high vs low+med)\n",
    "        feat_name = f'{feature_prefix}_{risk_type}_high_dominance'\n",
    "        df[feat_name] = df[high_col] / (df[low_col] + df[med_col] + 1e-6)\n",
    "        df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0).clip(0, 100)\n",
    "        created_features_list.append(feat_name)\n",
    "        feat_count += 1\n",
    "\n",
    "    return feat_count\n",
    "\n",
    "# Create risk ratio features for all categories\n",
    "print(\"Creating risk ratio features...\")\n",
    "feature_count += create_risk_ratio_features(\n",
    "    df=merged_df,\n",
    "    risk_categories=RISK_CATEGORIES,\n",
    "    feature_prefix='climate_risk_ratio',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "# Aggregate ratio features by time bins\n",
    "RATIO_COLS = [c for c in merged_df.columns if 'ratio' in c and c.startswith('climate_risk_ratio')]\n",
    "# Focus on top drought / heat stress ratios\n",
    "RATIO_COLS_FOCUSED = RATIO_COLS[:8]\n",
    "\n",
    "print(\"\\nQuantile-Based Risk Ratio Aggregations\")\n",
    "feature_count = 0\n",
    "\n",
    "for quantile_name, quantile_col in quantile_config.items():\n",
    "\n",
    "    print(f\"Aggregating {len(RATIO_COLS_FOCUSED)} ratio features by country-{quantile_name}...\")\n",
    "\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=RATIO_COLS_FOCUSED,\n",
    "        groupby_cols=['country_name', quantile_col],\n",
    "        agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        feature_prefix=f'climate_risk_{quantile_name}_ratio_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "print(f\"Created {feature_count} quantile-based risk ratio features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd36890a",
   "metadata": {
    "_cell_guid": "fcc574ef-2c8e-43e0-829c-87799605b4c6",
    "_uuid": "8f8d92fb-71b5-4143-b3d1-bd2e9cb27586",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:53:10.777258Z",
     "iopub.status.busy": "2026-01-30T16:53:10.776489Z",
     "iopub.status.idle": "2026-01-30T16:53:13.006434Z",
     "shell.execute_reply": "2026-01-30T16:53:13.005061Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.246161,
     "end_time": "2026-01-30T16:53:13.008666",
     "exception": false,
     "start_time": "2026-01-30T16:53:10.762505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Drought-Heat Compound Stress Features\n",
      "Creating drought-heat compound features...\n",
      "Aggregating compound features by quartile...\n",
      "Aggregating compound features by quintile...\n",
      "Aggregating compound features by sextile...\n",
      "Created 60 drought-heat compound stress features\n"
     ]
    }
   ],
   "source": [
    "#  DROUGHT-HEAT COMPOUND STRESS FEATURES\n",
    "# ============================================================================\n",
    "# Specific focus on drought + heat interactions\n",
    "print(\"\\n Drought-Heat Compound Stress Features\")\n",
    "feature_count = 0\n",
    "\n",
    "def create_compound_drought_heat_features(df, feature_prefix, created_features_list):\n",
    "    \"\"\"\n",
    "    Create specialized compound features for drought + heat stress.\n",
    "    \"\"\"\n",
    "    feat_count = 0\n",
    "\n",
    "    drought_high = df['climate_risk_cnt_locations_drought_risk_high']\n",
    "    drought_med = df['climate_risk_cnt_locations_drought_risk_medium']\n",
    "    heat_high = df['climate_risk_cnt_locations_heat_stress_risk_high']\n",
    "    heat_med = df['climate_risk_cnt_locations_heat_stress_risk_medium']\n",
    "\n",
    "    # Combined high stress (drought_high * heat_high)\n",
    "    feat_name = f'{feature_prefix}_drought_heat_high_product'\n",
    "    df[feat_name] = drought_high * heat_high\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Combined elevated stress (med+high for both)\n",
    "    feat_name = f'{feature_prefix}_drought_heat_elevated_sum'\n",
    "    df[feat_name] = (drought_high + drought_med) + (heat_high + heat_med)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Max of drought/heat high\n",
    "    feat_name = f'{feature_prefix}_drought_heat_high_max'\n",
    "    df[feat_name] = np.maximum(drought_high, heat_high)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Min of drought/heat high (both present = severe)\n",
    "    feat_name = f'{feature_prefix}_drought_heat_high_min'\n",
    "    df[feat_name] = np.minimum(drought_high, heat_high)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Geometric mean of high risks\n",
    "    feat_name = f'{feature_prefix}_drought_heat_high_geomean'\n",
    "    df[feat_name] = np.sqrt(drought_high * heat_high + 1e-6)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Drought dominance ratio\n",
    "    feat_name = f'{feature_prefix}_drought_vs_heat_ratio'\n",
    "    df[feat_name] = drought_high / (heat_high + 1e-6)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0).clip(0, 100)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    return feat_count\n",
    "\n",
    "print(\"Creating drought-heat compound features...\")\n",
    "feature_count += create_compound_drought_heat_features(\n",
    "    df=merged_df,\n",
    "    feature_prefix='climate_risk_compound',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "# Aggregate compound features by time bins\n",
    "COMPOUND_COLS = [c for c in merged_df.columns if c.startswith('climate_risk_compound_')]\n",
    "\n",
    "SELECTED_QUANTILES = [\"quartile\", \"quintile\", \"sextile\"]\n",
    "\n",
    "for q in SELECTED_QUANTILES:\n",
    "    print(f\"Aggregating compound features by {q}...\")\n",
    "\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=COMPOUND_COLS,\n",
    "        groupby_cols=['country_name', quantile_config[q]],\n",
    "        agg_funcs=['mean', 'max', 'std'],   # drop min/var/sum for stability\n",
    "        feature_prefix=f'climate_risk_compound_{q}_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "    \n",
    "print(f\"Created {feature_count} drought-heat compound stress features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d35e5e9",
   "metadata": {
    "_cell_guid": "54ae2e3d-36db-4229-b9c8-aa3f34bc9c20",
    "_uuid": "ffc0f67a-a703-4b81-9aea-3a9cbae8f9e3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:53:13.037883Z",
     "iopub.status.busy": "2026-01-30T16:53:13.037467Z",
     "iopub.status.idle": "2026-01-30T16:53:15.166935Z",
     "shell.execute_reply": "2026-01-30T16:53:15.165687Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.147171,
     "end_time": "2026-01-30T16:53:15.168991",
     "exception": false,
     "start_time": "2026-01-30T16:53:13.021820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Weighted + Quartile-Country-Month Aggregation\n",
      "Creating weighted quartile-country-month aggregations...\n",
      "Creating weighted sextile-country-month aggregations...\n",
      "Created 48 weighted quartile-country-month features\n"
     ]
    }
   ],
   "source": [
    "#  WEIGHTED FEATURES WITH QUARTILE-COUNTRY-MONTH AGG\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n Weighted + Quartile-Country-Month Aggregation\")\n",
    "feature_count = 0\n",
    "\n",
    "# First ensure weighted features exist for key risk types\n",
    "WEIGHTED_MEDIUM_COLS = [\n",
    "    'climate_risk_weighted_drought_risk_medium',\n",
    "    'climate_risk_weighted_excess_precip_risk_medium',\n",
    "    'climate_risk_weighted_heat_stress_risk_medium',\n",
    "    'climate_risk_weighted_drought_risk_high',\n",
    "    'climate_risk_weighted_heat_stress_risk_high',\n",
    "]\n",
    "\n",
    "# Check which exist, create if needed\n",
    "for col in WEIGHTED_MEDIUM_COLS:\n",
    "    base_col = col.replace('climate_risk_weighted_', 'climate_risk_cnt_locations_')\n",
    "    if col not in merged_df.columns and base_col in merged_df.columns:\n",
    "        merged_df[col] = merged_df[base_col] * (merged_df['percent_country_production'] / 100)\n",
    "        merged_df[col] = merged_df[col].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "        ALL_NEW_FEATURES.append(col)\n",
    "        feature_count += 1\n",
    "\n",
    "EXISTING_WEIGHTED_COLS = [c for c in WEIGHTED_MEDIUM_COLS if c in merged_df.columns]\n",
    "\n",
    "# Aggregate weighted features by quartile-country-month\n",
    "print(\"Creating weighted quartile-country-month aggregations...\")\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=EXISTING_WEIGHTED_COLS,\n",
    "    groupby_cols=['climate_risk_time_bin_quartile', 'country_name', 'month'],\n",
    "    agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "    feature_prefix='climate_risk_weighted_quartile_country_month_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "# Also try sextile-country-month for weighted\n",
    "print(\"Creating weighted sextile-country-month aggregations...\")\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=EXISTING_WEIGHTED_COLS[:3],  # Focus on medium risks\n",
    "    groupby_cols=['climate_risk_time_bin_sextile', 'country_name', 'month'],\n",
    "    agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "    feature_prefix='climate_risk_weighted_sextile_country_month_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(f\"Created {feature_count} weighted quartile-country-month features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2c05e23",
   "metadata": {
    "_cell_guid": "2302d44d-3aab-46e9-b77c-2fcaf6939b9c",
    "_uuid": "72ab9d56-6928-4323-8efc-a5cf32ed6a9d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:53:15.197005Z",
     "iopub.status.busy": "2026-01-30T16:53:15.196309Z",
     "iopub.status.idle": "2026-01-30T16:53:19.477392Z",
     "shell.execute_reply": "2026-01-30T16:53:19.476215Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.297528,
     "end_time": "2026-01-30T16:53:19.479429",
     "exception": false,
     "start_time": "2026-01-30T16:53:15.181901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Medium Risk Compound Features\n",
      "Creating medium risk compound features...\n",
      "Aggregating medium compounds by quintile...\n",
      "Aggregating medium compounds by sextile...\n",
      "Created 120 medium risk compound features\n"
     ]
    }
   ],
   "source": [
    "#  MEDIUM RISK COMPOUND FEATURES\n",
    "# ============================================================================\n",
    "# Focus on medium risk level compounds\n",
    "print(\"\\n Medium Risk Compound Features\")\n",
    "feature_count = 0\n",
    "\n",
    "def create_medium_risk_compounds(df, feature_prefix, created_features_list):\n",
    "    \"\"\"\n",
    "    Create compound features for medium risk levels.\n",
    "    \"\"\"\n",
    "    feat_count = 0\n",
    "\n",
    "    drought_med = df['climate_risk_cnt_locations_drought_risk_medium']\n",
    "    heat_med = df['climate_risk_cnt_locations_heat_stress_risk_medium']\n",
    "    excess_med = df['climate_risk_cnt_locations_excess_precip_risk_medium']\n",
    "    cold_med = df['climate_risk_cnt_locations_unseasonably_cold_risk_medium']\n",
    "\n",
    "    # Drought × Heat medium\n",
    "    feat_name = f'{feature_prefix}_drought_heat_med_product'\n",
    "    df[feat_name] = drought_med * heat_med\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_heat_med_sum'\n",
    "    df[feat_name] = drought_med + heat_med\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_heat_med_max'\n",
    "    df[feat_name] = np.maximum(drought_med, heat_med)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_heat_med_min'\n",
    "    df[feat_name] = np.minimum(drought_med, heat_med)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_heat_med_geomean'\n",
    "    df[feat_name] = np.sqrt(drought_med * heat_med + 1e-6)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Drought × Excess Precip medium\n",
    "    feat_name = f'{feature_prefix}_drought_excess_med_product'\n",
    "    df[feat_name] = drought_med * excess_med\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_excess_med_sum'\n",
    "    df[feat_name] = drought_med + excess_med\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_excess_med_geomean'\n",
    "    df[feat_name] = np.sqrt(drought_med * excess_med + 1e-6)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Heat × Excess Precip medium\n",
    "    feat_name = f'{feature_prefix}_heat_excess_med_product'\n",
    "    df[feat_name] = heat_med * excess_med\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_heat_excess_med_sum'\n",
    "    df[feat_name] = heat_med + excess_med\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # All medium combined\n",
    "    feat_name = f'{feature_prefix}_all_med_sum'\n",
    "    df[feat_name] = drought_med + heat_med + excess_med + cold_med\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_all_med_max'\n",
    "    df[feat_name] = df[['climate_risk_cnt_locations_drought_risk_medium',\n",
    "                        'climate_risk_cnt_locations_heat_stress_risk_medium',\n",
    "                        'climate_risk_cnt_locations_excess_precip_risk_medium',\n",
    "                        'climate_risk_cnt_locations_unseasonably_cold_risk_medium']].max(axis=1)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    return feat_count\n",
    "\n",
    "print(\"Creating medium risk compound features...\")\n",
    "feature_count += create_medium_risk_compounds(\n",
    "    df=merged_df,\n",
    "    feature_prefix='climate_risk_compound_med',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "# Aggregate medium compounds by quintile\n",
    "COMPOUND_MED_COLS = [c for c in merged_df.columns if c.startswith('climate_risk_compound_med_')]\n",
    "\n",
    "print(\"Aggregating medium compounds by quintile...\")\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=COMPOUND_MED_COLS,\n",
    "    groupby_cols=['country_name', 'climate_risk_time_bin_quintile'],\n",
    "    agg_funcs=['mean', 'max', 'sum'],\n",
    "    feature_prefix='climate_risk_compound_med_quintile_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(\"Aggregating medium compounds by sextile...\")\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=COMPOUND_MED_COLS,\n",
    "    groupby_cols=['country_name', 'climate_risk_time_bin_sextile'],\n",
    "    agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "    feature_prefix='climate_risk_compound_med_sextile_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(f\"Created {feature_count} medium risk compound features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de9d619d",
   "metadata": {
    "_cell_guid": "6e3cab91-0cf9-4fc4-aa9f-cb125b61b3f8",
    "_uuid": "857f2974-d8f5-4359-9d1b-a45edc59b00d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:53:19.506951Z",
     "iopub.status.busy": "2026-01-30T16:53:19.506533Z",
     "iopub.status.idle": "2026-01-30T16:53:21.680749Z",
     "shell.execute_reply": "2026-01-30T16:53:21.679381Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.190674,
     "end_time": "2026-01-30T16:53:21.683109",
     "exception": false,
     "start_time": "2026-01-30T16:53:19.492435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Ratio + Quartile-Country-Month Aggregation\n",
      "Found 16 ratio columns\n",
      "Creating ratio quartile-country-month aggregations...\n",
      "Creating ratio sextile-country-month aggregations...\n",
      "Created 48 ratio quartile-country-month features\n"
     ]
    }
   ],
   "source": [
    "#  RATIO FEATURES WITH QUARTILE-COUNTRY-MONTH AGG\n",
    "# ============================================================================\n",
    "print(\"\\n Ratio + Quartile-Country-Month Aggregation\")\n",
    "feature_count = 0\n",
    "\n",
    "# Get existing ratio columns\n",
    "RATIO_COLS = [c for c in merged_df.columns if c.startswith('climate_risk_ratio_')]\n",
    "\n",
    "quantile_config_2 = {\n",
    "    \"quartile\": \"climate_risk_time_bin_quartile\",\n",
    "    \"sextile\": \"climate_risk_time_bin_sextile\",\n",
    "}\n",
    "\n",
    "if RATIO_COLS:\n",
    "    print(f\"Found {len(RATIO_COLS)} ratio columns\")\n",
    "\n",
    "    for quantile_name, quantile_col in quantile_config_2.items():\n",
    "\n",
    "        print(f\"Creating ratio {quantile_name}-country-month aggregations...\")\n",
    "\n",
    "        feature_count += create_groupby_agg_features(\n",
    "            df=merged_df,\n",
    "            source_cols=RATIO_COLS[:8],  # focus on top ratios\n",
    "            groupby_cols=[quantile_col, 'country_name', 'month'],\n",
    "            agg_funcs=['mean', 'max', 'std'],  # ❗ safer for ratios\n",
    "            feature_prefix=f'climate_risk_ratio_{quantile_name}_country_month_agg',\n",
    "            created_features_list=ALL_NEW_FEATURES\n",
    "        )\n",
    "\n",
    "print(f\"Created {feature_count} ratio quartile-country-month features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5149871",
   "metadata": {
    "_cell_guid": "0e4afb00-35bb-4bba-bb37-0ebaa7b14371",
    "_uuid": "5120ff40-5810-4031-b9a9-9032449b5f07",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:53:21.712339Z",
     "iopub.status.busy": "2026-01-30T16:53:21.711760Z",
     "iopub.status.idle": "2026-01-30T16:53:24.098474Z",
     "shell.execute_reply": "2026-01-30T16:53:24.096879Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.403913,
     "end_time": "2026-01-30T16:53:24.100869",
     "exception": false,
     "start_time": "2026-01-30T16:53:21.696956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Cross-Level Compound Features\n",
      "Creating cross-level compound features...\n",
      "Aggregating cross-level compounds by quintile...\n",
      "Aggregating cross-level compounds by quartile-country-month...\n",
      "Created 66 cross-level compound features\n"
     ]
    }
   ],
   "source": [
    "#  CROSS-LEVEL COMPOUND FEATURES\n",
    "# ============================================================================\n",
    "# Combine high and medium risk levels (high × medium interactions)\n",
    "print(\"\\n Cross-Level Compound Features\")\n",
    "feature_count = 0\n",
    "\n",
    "def create_cross_level_compounds(df, feature_prefix, created_features_list):\n",
    "    \"\"\"\n",
    "    Create compound features combining high and medium risk levels.\n",
    "    \"\"\"\n",
    "    feat_count = 0\n",
    "\n",
    "    drought_high = df['climate_risk_cnt_locations_drought_risk_high']\n",
    "    drought_med = df['climate_risk_cnt_locations_drought_risk_medium']\n",
    "    heat_high = df['climate_risk_cnt_locations_heat_stress_risk_high']\n",
    "    heat_med = df['climate_risk_cnt_locations_heat_stress_risk_medium']\n",
    "    excess_high = df['climate_risk_cnt_locations_excess_precip_risk_high']\n",
    "    excess_med = df['climate_risk_cnt_locations_excess_precip_risk_medium']\n",
    "\n",
    "    # Drought high × Heat medium\n",
    "    feat_name = f'{feature_prefix}_drought_high_heat_med_product'\n",
    "    df[feat_name] = drought_high * heat_med\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Heat high × Drought medium\n",
    "    feat_name = f'{feature_prefix}_heat_high_drought_med_product'\n",
    "    df[feat_name] = heat_high * drought_med\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Drought high × Excess medium\n",
    "    feat_name = f'{feature_prefix}_drought_high_excess_med_product'\n",
    "    df[feat_name] = drought_high * excess_med\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Excess high × Drought medium\n",
    "    feat_name = f'{feature_prefix}_excess_high_drought_med_product'\n",
    "    df[feat_name] = excess_high * drought_med\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Heat high × Excess medium\n",
    "    feat_name = f'{feature_prefix}_heat_high_excess_med_product'\n",
    "    df[feat_name] = heat_high * excess_med\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Combined elevated risk (high + medium for each type)\n",
    "    feat_name = f'{feature_prefix}_drought_elevated'\n",
    "    df[feat_name] = drought_high + drought_med\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_heat_elevated'\n",
    "    df[feat_name] = heat_high + heat_med\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_excess_elevated'\n",
    "    df[feat_name] = excess_high + excess_med\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Elevated × Elevated\n",
    "    feat_name = f'{feature_prefix}_drought_heat_elevated_product'\n",
    "    df[feat_name] = (drought_high + drought_med) * (heat_high + heat_med)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    return feat_count\n",
    "\n",
    "print(\"Creating cross-level compound features...\")\n",
    "feature_count += create_cross_level_compounds(\n",
    "    df=merged_df,\n",
    "    feature_prefix='climate_risk_crosslevel',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "# Aggregate cross-level compounds\n",
    "CROSSLEVEL_COLS = [c for c in merged_df.columns if c.startswith('climate_risk_crosslevel_')]\n",
    "\n",
    "print(\"Aggregating cross-level compounds by quintile...\")\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=CROSSLEVEL_COLS,\n",
    "    groupby_cols=['country_name', 'climate_risk_time_bin_quintile'],\n",
    "    agg_funcs=['mean', 'max', 'sum'],\n",
    "    feature_prefix='climate_risk_crosslevel_quintile_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(\"Aggregating cross-level compounds by quartile-country-month...\")\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=CROSSLEVEL_COLS[:5],\n",
    "    groupby_cols=['climate_risk_time_bin_quartile', 'country_name', 'month'],\n",
    "    agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "    feature_prefix='climate_risk_crosslevel_quartile_month_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(f\"Created {feature_count} cross-level compound features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d609c99",
   "metadata": {
    "_cell_guid": "48182e89-04f0-4219-b2f0-46fa6373f041",
    "_uuid": "84d9757c-b6a2-4d4c-b387-974e70251345",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:53:24.130279Z",
     "iopub.status.busy": "2026-01-30T16:53:24.129901Z",
     "iopub.status.idle": "2026-01-30T16:53:26.261420Z",
     "shell.execute_reply": "2026-01-30T16:53:26.260348Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.149008,
     "end_time": "2026-01-30T16:53:26.263742",
     "exception": false,
     "start_time": "2026-01-30T16:53:24.114734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Weighted Compound Features\n",
      "Creating weighted compound features...\n",
      "Aggregating weighted compounds by quintile...\n",
      "Aggregating weighted compounds by quartile-country-month...\n",
      "Created 56 weighted compound features\n"
     ]
    }
   ],
   "source": [
    "#  WEIGHTED COMPOUND FEATURES\n",
    "# ============================================================================\n",
    "# Apply production weighting to compound features\n",
    "print(\"\\n Weighted Compound Features\")\n",
    "feature_count = 0\n",
    "\n",
    "def create_weighted_compounds(df, feature_prefix, created_features_list):\n",
    "    \"\"\"\n",
    "    Create compound features using production-weighted risk values.\n",
    "    \"\"\"\n",
    "    feat_count = 0\n",
    "\n",
    "    weight = df['percent_country_production'] / 100\n",
    "\n",
    "    drought_high_w = df['climate_risk_cnt_locations_drought_risk_high'] * weight\n",
    "    drought_med_w = df['climate_risk_cnt_locations_drought_risk_medium'] * weight\n",
    "    heat_high_w = df['climate_risk_cnt_locations_heat_stress_risk_high'] * weight\n",
    "    heat_med_w = df['climate_risk_cnt_locations_heat_stress_risk_medium'] * weight\n",
    "    excess_med_w = df['climate_risk_cnt_locations_excess_precip_risk_medium'] * weight\n",
    "\n",
    "    # Weighted drought × heat high\n",
    "    feat_name = f'{feature_prefix}_w_drought_heat_high_product'\n",
    "    df[feat_name] = drought_high_w * heat_high_w\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_w_drought_heat_high_geomean'\n",
    "    df[feat_name] = np.sqrt(drought_high_w * heat_high_w + 1e-6)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_w_drought_heat_high_min'\n",
    "    df[feat_name] = np.minimum(drought_high_w, heat_high_w)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_w_drought_heat_high_max'\n",
    "    df[feat_name] = np.maximum(drought_high_w, heat_high_w)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Weighted drought × heat medium\n",
    "    feat_name = f'{feature_prefix}_w_drought_heat_med_product'\n",
    "    df[feat_name] = drought_med_w * heat_med_w\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_w_drought_heat_med_geomean'\n",
    "    df[feat_name] = np.sqrt(drought_med_w * heat_med_w + 1e-6)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Weighted drought × excess medium\n",
    "    feat_name = f'{feature_prefix}_w_drought_excess_med_product'\n",
    "    df[feat_name] = drought_med_w * excess_med_w\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_w_drought_excess_med_geomean'\n",
    "    df[feat_name] = np.sqrt(drought_med_w * excess_med_w + 1e-6)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    return feat_count\n",
    "\n",
    "print(\"Creating weighted compound features...\")\n",
    "feature_count += create_weighted_compounds(\n",
    "    df=merged_df,\n",
    "    feature_prefix='climate_risk_wcompound',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "# Aggregate weighted compounds\n",
    "WCOMPOUND_COLS = [c for c in merged_df.columns if c.startswith('climate_risk_wcompound_')]\n",
    "\n",
    "print(\"Aggregating weighted compounds by quintile...\")\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=WCOMPOUND_COLS,\n",
    "    groupby_cols=['country_name', 'climate_risk_time_bin_quintile'],\n",
    "    agg_funcs=['mean', 'max', 'sum'],\n",
    "    feature_prefix='climate_risk_wcompound_quintile_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "MONTH_QUANTILES = {\n",
    "    \"quartile\": \"climate_risk_time_bin_quartile\",\n",
    "}\n",
    "\n",
    "for q_name, q_col in MONTH_QUANTILES.items():\n",
    "    print(f\"Aggregating weighted compounds by {q_name}-country-month...\")\n",
    "\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=WCOMPOUND_COLS,\n",
    "        groupby_cols=[q_col, 'country_name', 'month'],\n",
    "        agg_funcs=['mean', 'max', 'std'],  # ❗ drop min/var/sum\n",
    "        feature_prefix=f'climate_risk_wcompound_{q_name}_country_month_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "    \n",
    "print(f\"Created {feature_count} weighted compound features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96e3f6b7",
   "metadata": {
    "_cell_guid": "4fd9b922-13c3-45a5-880c-e4f67e16c07d",
    "_uuid": "b42034ad-a0d0-46b1-9dd9-035686898e29",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:53:26.293323Z",
     "iopub.status.busy": "2026-01-30T16:53:26.292516Z",
     "iopub.status.idle": "2026-01-30T16:53:26.436373Z",
     "shell.execute_reply": "2026-01-30T16:53:26.435180Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.161145,
     "end_time": "2026-01-30T16:53:26.438472",
     "exception": false,
     "start_time": "2026-01-30T16:53:26.277327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Crossbin for Weighted Features\n",
      "Creating weighted crossbin features...\n",
      "Created 8 weighted crossbin features\n"
     ]
    }
   ],
   "source": [
    "#  CROSSBIN FOR WEIGHTED FEATURES\n",
    "# ============================================================================\n",
    "# Apply crossbin pattern to weighted features\n",
    "print(\"\\n Crossbin for Weighted Features\")\n",
    "feature_count = 0\n",
    "\n",
    "def create_weighted_crossbin_features(df, source_cols, timebin_pairs, feature_prefix, created_features_list):\n",
    "    \"\"\"\n",
    "    Create crossbin deviation features for weighted columns.\n",
    "    \"\"\"\n",
    "    feat_count = 0\n",
    "\n",
    "    for coarse_bin, fine_bin in timebin_pairs:\n",
    "        coarse_name = coarse_bin.replace('climate_risk_time_bin_', '')\n",
    "        fine_name = fine_bin.replace('climate_risk_time_bin_', '')\n",
    "\n",
    "        for source_col in source_cols:\n",
    "            if source_col not in df.columns:\n",
    "                continue\n",
    "            risk_name = source_col.replace('climate_risk_weighted_', '')\n",
    "\n",
    "            # Coarse bin mean\n",
    "            coarse_mean = df.groupby(coarse_bin)[source_col].transform('mean')\n",
    "\n",
    "            # Deviation from coarse bin mean\n",
    "            feat_name = f'{feature_prefix}_{coarse_name}_{fine_name}_dev_{risk_name}'\n",
    "            df[feat_name] = df[source_col] - coarse_mean\n",
    "            df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "            created_features_list.append(feat_name)\n",
    "            feat_count += 1\n",
    "\n",
    "    return feat_count\n",
    "\n",
    "WEIGHTED_CROSSBIN_COLS = [\n",
    "    'climate_risk_weighted_drought_risk_medium',\n",
    "    'climate_risk_weighted_drought_risk_high',\n",
    "    'climate_risk_weighted_heat_stress_risk_high',\n",
    "    'climate_risk_weighted_excess_precip_risk_medium',\n",
    "]\n",
    "\n",
    "CROSSBIN_PAIRS = [\n",
    "    ('climate_risk_time_bin_sextile', 'climate_risk_time_bin_tredecile'),\n",
    "    ('climate_risk_time_bin_quartile', 'climate_risk_time_bin_decile'),\n",
    "]\n",
    "\n",
    "print(\"Creating weighted crossbin features...\")\n",
    "feature_count += create_weighted_crossbin_features(\n",
    "    df=merged_df,\n",
    "    source_cols=WEIGHTED_CROSSBIN_COLS,\n",
    "    timebin_pairs=CROSSBIN_PAIRS,\n",
    "    feature_prefix='climate_risk_wcrossbin',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(f\"Created {feature_count} weighted crossbin features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b532c536",
   "metadata": {
    "_cell_guid": "1d856350-a896-476c-a962-abbce5ab2c60",
    "_uuid": "2a38a6c7-7cde-4e84-abcf-28b124763e70",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:53:26.469377Z",
     "iopub.status.busy": "2026-01-30T16:53:26.468503Z",
     "iopub.status.idle": "2026-01-30T16:53:29.098245Z",
     "shell.execute_reply": "2026-01-30T16:53:29.096867Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.648117,
     "end_time": "2026-01-30T16:53:29.100630",
     "exception": false,
     "start_time": "2026-01-30T16:53:26.452513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Compound + Quartile-Country-Month\n",
      "Found 10 compound base columns\n",
      "Creating compound quartile-country-month aggregations...\n",
      "Created 60 compound quartile-country-month features\n"
     ]
    }
   ],
   "source": [
    "#  COMPOUND FEATURES WITH QUARTILE-COUNTRY-MONTH\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n Compound + Quartile-Country-Month\")\n",
    "feature_count = 0\n",
    "\n",
    "# Get all compound columns\n",
    "ALL_COMPOUND_COLS = [c for c in merged_df.columns if 'compound' in c and not '_agg_' in c]\n",
    "ALL_COMPOUND_COLS = ALL_COMPOUND_COLS[:10]\n",
    "\n",
    "if ALL_COMPOUND_COLS:\n",
    "    print(f\"Found {len(ALL_COMPOUND_COLS)} compound base columns\")\n",
    "\n",
    "    print(\"Creating compound quartile-country-month aggregations...\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=ALL_COMPOUND_COLS,\n",
    "        groupby_cols=['climate_risk_time_bin_quartile', 'country_name', 'month'],\n",
    "        agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        feature_prefix='climate_risk_compound_quartile_month_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "print(f\"Created {feature_count} compound quartile-country-month features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "572fd069",
   "metadata": {
    "_cell_guid": "78832eaf-c208-4dc9-a05d-d3b2b4f124da",
    "_uuid": "a0f9122e-d201-4fb2-bbc6-0d99f121ecb7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:53:29.130671Z",
     "iopub.status.busy": "2026-01-30T16:53:29.130355Z",
     "iopub.status.idle": "2026-01-30T16:53:34.516675Z",
     "shell.execute_reply": "2026-01-30T16:53:34.515629Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 5.405191,
     "end_time": "2026-01-30T16:53:34.519443",
     "exception": false,
     "start_time": "2026-01-30T16:53:29.114252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Expanded Drought-Excess Compound Features\n",
      "Creating expanded drought-excess compound features...\n",
      "Aggregating drought-excess compounds by quintile...\n",
      "Aggregating drought-excess compounds by sextile...\n",
      "Aggregating drought-excess compounds by quartile-country-month...\n",
      "Created 139 expanded drought-excess compound features\n"
     ]
    }
   ],
   "source": [
    "#  DROUGHT-EXCESS COMPOUND FEATURES - TWO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n Expanded Drought-Excess Compound Features\")\n",
    "feature_count = 0\n",
    "\n",
    "def create_drought_excess_compounds(df, feature_prefix, created_features_list):\n",
    "    \"\"\"\n",
    "    Create expanded drought × excess precip compound features.\n",
    "    \"\"\"\n",
    "    feat_count = 0\n",
    "\n",
    "    drought_high = df['climate_risk_cnt_locations_drought_risk_high']\n",
    "    drought_med = df['climate_risk_cnt_locations_drought_risk_medium']\n",
    "    drought_low = df['climate_risk_cnt_locations_drought_risk_low']\n",
    "    excess_high = df['climate_risk_cnt_locations_excess_precip_risk_high']\n",
    "    excess_med = df['climate_risk_cnt_locations_excess_precip_risk_medium']\n",
    "    excess_low = df['climate_risk_cnt_locations_excess_precip_risk_low']\n",
    "    weight = df['percent_country_production'] / 100\n",
    "\n",
    "    # High × High\n",
    "    feat_name = f'{feature_prefix}_drought_excess_high_product'\n",
    "    df[feat_name] = drought_high * excess_high\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_excess_high_geomean'\n",
    "    df[feat_name] = np.sqrt(drought_high * excess_high + 1e-6)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_excess_high_min'\n",
    "    df[feat_name] = np.minimum(drought_high, excess_high)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_excess_high_max'\n",
    "    df[feat_name] = np.maximum(drought_high, excess_high)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Medium × Medium\n",
    "    feat_name = f'{feature_prefix}_drought_excess_med_min'\n",
    "    df[feat_name] = np.minimum(drought_med, excess_med)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_excess_med_max'\n",
    "    df[feat_name] = np.maximum(drought_med, excess_med)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Cross level: High × Medium\n",
    "    feat_name = f'{feature_prefix}_drought_high_excess_med_geomean'\n",
    "    df[feat_name] = np.sqrt(drought_high * excess_med + 1e-6)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_med_excess_high_geomean'\n",
    "    df[feat_name] = np.sqrt(drought_med * excess_high + 1e-6)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Combined elevated (high + med)\n",
    "    drought_elevated = drought_high + drought_med\n",
    "    excess_elevated = excess_high + excess_med\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_excess_elevated_product'\n",
    "    df[feat_name] = drought_elevated * excess_elevated\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_excess_elevated_geomean'\n",
    "    df[feat_name] = np.sqrt(drought_elevated * excess_elevated + 1e-6)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Weighted versions\n",
    "    feat_name = f'{feature_prefix}_w_drought_excess_med_min'\n",
    "    df[feat_name] = np.minimum(drought_med * weight, excess_med * weight)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_w_drought_excess_med_max'\n",
    "    df[feat_name] = np.maximum(drought_med * weight, excess_med * weight)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_w_drought_excess_elevated_geomean'\n",
    "    df[feat_name] = np.sqrt((drought_elevated * weight) * (excess_elevated * weight) + 1e-6)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    return feat_count\n",
    "\n",
    "print(\"Creating expanded drought-excess compound features...\")\n",
    "feature_count += create_drought_excess_compounds(\n",
    "    df=merged_df,\n",
    "    feature_prefix='climate_risk_de_compound',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "# Aggregate drought-excess compounds\n",
    "DE_COMPOUND_COLS = [c for c in merged_df.columns if c.startswith('climate_risk_de_compound_')]\n",
    "\n",
    "print(\"Aggregating drought-excess compounds by quintile...\")\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=DE_COMPOUND_COLS,\n",
    "    groupby_cols=['country_name', 'climate_risk_time_bin_quintile'],\n",
    "    agg_funcs=['mean', 'max', 'sum'],\n",
    "    feature_prefix='climate_risk_de_compound_quintile_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(\"Aggregating drought-excess compounds by sextile...\")\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=DE_COMPOUND_COLS,\n",
    "    groupby_cols=['country_name', 'climate_risk_time_bin_sextile'],\n",
    "    agg_funcs=['mean', 'max', 'sum'],\n",
    "    feature_prefix='climate_risk_de_compound_sextile_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(\"Aggregating drought-excess compounds by quartile-country-month...\")\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=DE_COMPOUND_COLS[:8],\n",
    "    groupby_cols=['climate_risk_time_bin_quartile', 'country_name', 'month'],\n",
    "    agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "    feature_prefix='climate_risk_de_compound_quartile_month_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(f\"Created {feature_count} expanded drought-excess compound features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83520d09",
   "metadata": {
    "_cell_guid": "defab6dd-ac4f-48c6-be68-31b2f9833aba",
    "_uuid": "9ee68684-1e1f-4bf3-ba19-1a5c8604722f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:53:34.550748Z",
     "iopub.status.busy": "2026-01-30T16:53:34.550380Z",
     "iopub.status.idle": "2026-01-30T16:53:37.553414Z",
     "shell.execute_reply": "2026-01-30T16:53:37.552428Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.020448,
     "end_time": "2026-01-30T16:53:37.555649",
     "exception": false,
     "start_time": "2026-01-30T16:53:34.535201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Expanded All-Risk Max Features\n",
      "Creating all-risk max features...\n",
      "Aggregating all-risk features by quintile...\n",
      "Aggregating all-risk features by sextile...\n",
      "Created 77 expanded all-risk max features\n"
     ]
    }
   ],
   "source": [
    "#  EXPLORE ALL-RISK MAX FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n Expanded All-Risk Max Features\")\n",
    "feature_count = 0\n",
    "\n",
    "def create_all_risk_max_features(df, feature_prefix, created_features_list):\n",
    "    \"\"\"\n",
    "    Create all-risk max features at different levels.\n",
    "    \"\"\"\n",
    "    feat_count = 0\n",
    "\n",
    "    # High risk columns\n",
    "    high_cols = [\n",
    "        'climate_risk_cnt_locations_drought_risk_high',\n",
    "        'climate_risk_cnt_locations_heat_stress_risk_high',\n",
    "        'climate_risk_cnt_locations_excess_precip_risk_high',\n",
    "        'climate_risk_cnt_locations_unseasonably_cold_risk_high',\n",
    "    ]\n",
    "\n",
    "    # Medium risk columns\n",
    "    med_cols = [\n",
    "        'climate_risk_cnt_locations_drought_risk_medium',\n",
    "        'climate_risk_cnt_locations_heat_stress_risk_medium',\n",
    "        'climate_risk_cnt_locations_excess_precip_risk_medium',\n",
    "        'climate_risk_cnt_locations_unseasonably_cold_risk_medium',\n",
    "    ]\n",
    "\n",
    "    weight = df['percent_country_production'] / 100\n",
    "\n",
    "    # All high max\n",
    "    feat_name = f'{feature_prefix}_all_high_max'\n",
    "    df[feat_name] = df[high_cols].max(axis=1)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_all_high_sum'\n",
    "    df[feat_name] = df[high_cols].sum(axis=1)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_all_high_mean'\n",
    "    df[feat_name] = df[high_cols].mean(axis=1)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # All medium min (complement to max)\n",
    "    feat_name = f'{feature_prefix}_all_med_min'\n",
    "    df[feat_name] = df[med_cols].min(axis=1)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_all_med_mean'\n",
    "    df[feat_name] = df[med_cols].mean(axis=1)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Weighted versions\n",
    "    feat_name = f'{feature_prefix}_w_all_med_max'\n",
    "    df[feat_name] = (df[med_cols].values * weight.values.reshape(-1, 1)).max(axis=1)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_w_all_med_sum'\n",
    "    df[feat_name] = (df[med_cols].values * weight.values.reshape(-1, 1)).sum(axis=1)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_w_all_high_max'\n",
    "    df[feat_name] = (df[high_cols].values * weight.values.reshape(-1, 1)).max(axis=1)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Combined elevated (high + med) for each risk, then max\n",
    "    drought_elev = df['climate_risk_cnt_locations_drought_risk_high'] + df['climate_risk_cnt_locations_drought_risk_medium']\n",
    "    heat_elev = df['climate_risk_cnt_locations_heat_stress_risk_high'] + df['climate_risk_cnt_locations_heat_stress_risk_medium']\n",
    "    excess_elev = df['climate_risk_cnt_locations_excess_precip_risk_high'] + df['climate_risk_cnt_locations_excess_precip_risk_medium']\n",
    "    cold_elev = df['climate_risk_cnt_locations_unseasonably_cold_risk_high'] + df['climate_risk_cnt_locations_unseasonably_cold_risk_medium']\n",
    "\n",
    "    feat_name = f'{feature_prefix}_all_elevated_max'\n",
    "    df[feat_name] = pd.concat([drought_elev, heat_elev, excess_elev, cold_elev], axis=1).max(axis=1)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_all_elevated_sum'\n",
    "    df[feat_name] = drought_elev + heat_elev + excess_elev + cold_elev\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Geomean of all mediums\n",
    "    feat_name = f'{feature_prefix}_all_med_geomean'\n",
    "    df[feat_name] = (df[med_cols].prod(axis=1) + 1e-6) ** 0.25  # 4th root for 4 columns\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    return feat_count\n",
    "\n",
    "print(\"Creating all-risk max features...\")\n",
    "feature_count += create_all_risk_max_features(\n",
    "    df=merged_df,\n",
    "    feature_prefix='climate_risk_allrisk',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "# Aggregate all-risk features\n",
    "ALLRISK_COLS = [c for c in merged_df.columns if c.startswith('climate_risk_allrisk_')]\n",
    "\n",
    "print(\"Aggregating all-risk features by quintile...\")\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=ALLRISK_COLS,\n",
    "    groupby_cols=['country_name', 'climate_risk_time_bin_quintile'],\n",
    "    agg_funcs=['mean', 'max', 'sum'],\n",
    "    feature_prefix='climate_risk_allrisk_quintile_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(\"Aggregating all-risk features by sextile...\")\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=ALLRISK_COLS,\n",
    "    groupby_cols=['country_name', 'climate_risk_time_bin_sextile'],\n",
    "    agg_funcs=['mean', 'max', 'sum'],\n",
    "    feature_prefix='climate_risk_allrisk_sextile_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(f\"Created {feature_count} expanded all-risk max features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3cd35271",
   "metadata": {
    "_cell_guid": "ba659276-4568-45d2-8656-cb835a5a63f6",
    "_uuid": "f1e211f4-390f-4001-8e8d-1142220ce559",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:53:37.586558Z",
     "iopub.status.busy": "2026-01-30T16:53:37.585335Z",
     "iopub.status.idle": "2026-01-30T16:53:44.088348Z",
     "shell.execute_reply": "2026-01-30T16:53:44.087119Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 6.520594,
     "end_time": "2026-01-30T16:53:44.090422",
     "exception": false,
     "start_time": "2026-01-30T16:53:37.569828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Geomean Focus Features\n",
      "Creating geomean focus features...\n",
      "Aggregating geomean features by quintile...\n",
      "Aggregating geomean features by sextile...\n",
      "Aggregating geomean features by quartile-country-month...\n",
      "Created 160 geomean focus features\n"
     ]
    }
   ],
   "source": [
    "#  GEOMEAN FOCUS FEATURES\n",
    "# ============================================================================\n",
    "# Geomean is very effective - create more geomean-based features\n",
    "print(\"\\n Geomean Focus Features\")\n",
    "feature_count = 0\n",
    "\n",
    "def create_geomean_features(df, feature_prefix, created_features_list):\n",
    "    \"\"\"\n",
    "    Create geomean-based compound features for various risk combinations.\n",
    "    \"\"\"\n",
    "    feat_count = 0\n",
    "\n",
    "    drought_high = df['climate_risk_cnt_locations_drought_risk_high']\n",
    "    drought_med = df['climate_risk_cnt_locations_drought_risk_medium']\n",
    "    heat_high = df['climate_risk_cnt_locations_heat_stress_risk_high']\n",
    "    heat_med = df['climate_risk_cnt_locations_heat_stress_risk_medium']\n",
    "    excess_high = df['climate_risk_cnt_locations_excess_precip_risk_high']\n",
    "    excess_med = df['climate_risk_cnt_locations_excess_precip_risk_medium']\n",
    "    cold_high = df['climate_risk_cnt_locations_unseasonably_cold_risk_high']\n",
    "    cold_med = df['climate_risk_cnt_locations_unseasonably_cold_risk_medium']\n",
    "    weight = df['percent_country_production'] / 100\n",
    "\n",
    "    # Heat × Excess geomean (not yet tried much)\n",
    "    feat_name = f'{feature_prefix}_heat_excess_med_geomean'\n",
    "    df[feat_name] = np.sqrt(heat_med * excess_med + 1e-6)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_heat_excess_high_geomean'\n",
    "    df[feat_name] = np.sqrt(heat_high * excess_high + 1e-6)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Cold × Drought geomean\n",
    "    feat_name = f'{feature_prefix}_cold_drought_med_geomean'\n",
    "    df[feat_name] = np.sqrt(cold_med * drought_med + 1e-6)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Triple geomean: drought × heat × excess\n",
    "    feat_name = f'{feature_prefix}_drought_heat_excess_med_geomean'\n",
    "    df[feat_name] = (drought_med * heat_med * excess_med + 1e-6) ** (1/3)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_heat_excess_high_geomean'\n",
    "    df[feat_name] = (drought_high * heat_high * excess_high + 1e-6) ** (1/3)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Weighted geomeans\n",
    "    feat_name = f'{feature_prefix}_w_heat_excess_med_geomean'\n",
    "    df[feat_name] = np.sqrt((heat_med * weight) * (excess_med * weight) + 1e-6)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_w_drought_heat_excess_med_geomean'\n",
    "    df[feat_name] = ((drought_med * weight) * (heat_med * weight) * (excess_med * weight) + 1e-6) ** (1/3)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Elevated geomeans\n",
    "    drought_elev = drought_high + drought_med\n",
    "    heat_elev = heat_high + heat_med\n",
    "    excess_elev = excess_high + excess_med\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_heat_elevated_geomean'\n",
    "    df[feat_name] = np.sqrt(drought_elev * heat_elev + 1e-6)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_excess_elevated_geomean'\n",
    "    df[feat_name] = np.sqrt(drought_elev * excess_elev + 1e-6)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_heat_excess_elevated_geomean'\n",
    "    df[feat_name] = np.sqrt(heat_elev * excess_elev + 1e-6)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    return feat_count\n",
    "\n",
    "print(\"Creating geomean focus features...\")\n",
    "feature_count += create_geomean_features(\n",
    "    df=merged_df,\n",
    "    feature_prefix='climate_risk_geomean',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "# Aggregate geomean features\n",
    "GEOMEAN_COLS = [c for c in merged_df.columns if c.startswith('climate_risk_geomean_')]\n",
    "\n",
    "print(\"Aggregating geomean features by quintile...\")\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=GEOMEAN_COLS,\n",
    "    groupby_cols=['country_name', 'climate_risk_time_bin_quintile'],\n",
    "    agg_funcs=['mean', 'max', 'sum'],\n",
    "    feature_prefix='climate_risk_geomean_quintile_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(\"Aggregating geomean features by sextile...\")\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=GEOMEAN_COLS,\n",
    "    groupby_cols=['country_name', 'climate_risk_time_bin_sextile'],\n",
    "    agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "    feature_prefix='climate_risk_geomean_sextile_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(\"Aggregating geomean features by quartile-country-month...\")\n",
    "feature_count += create_groupby_agg_features(\n",
    "    df=merged_df,\n",
    "    source_cols=GEOMEAN_COLS,\n",
    "    groupby_cols=['climate_risk_time_bin_quartile', 'country_name', 'month'],\n",
    "    agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "    feature_prefix='climate_risk_geomean_quartile_month_agg',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "print(f\"Created {feature_count} geomean focus features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fa7d108",
   "metadata": {
    "_cell_guid": "d5bbca7b-f8bc-4aee-906b-aa92a39d490b",
    "_uuid": "b1878cc6-3358-4f97-8e6e-d0bb50d2c775",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:53:44.123395Z",
     "iopub.status.busy": "2026-01-30T16:53:44.122897Z",
     "iopub.status.idle": "2026-01-30T16:53:47.647163Z",
     "shell.execute_reply": "2026-01-30T16:53:47.646140Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.543339,
     "end_time": "2026-01-30T16:53:47.649312",
     "exception": false,
     "start_time": "2026-01-30T16:53:44.105973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Medium Compound Expanded Aggregations\n",
      "Found 12 medium compound base columns\n",
      "Aggregating medium compounds by quartile...\n",
      "Aggregating medium compounds by quartile-country-month...\n",
      "Created 84 medium compound expanded aggregation features\n"
     ]
    }
   ],
   "source": [
    "#  MEDIUM COMPOUND EXPANDED AGGREGATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n Medium Compound Expanded Aggregations\")\n",
    "feature_count = 0\n",
    "\n",
    "# Get medium compound columns\n",
    "MED_COMPOUND_BASE_COLS = [c for c in merged_df.columns if c.startswith('climate_risk_compound_med_') and '_agg_' not in c]\n",
    "\n",
    "if MED_COMPOUND_BASE_COLS:\n",
    "    print(f\"Found {len(MED_COMPOUND_BASE_COLS)} medium compound base columns\")\n",
    "\n",
    "    # Aggregate by quartile (different from quintile/sextile already done)\n",
    "    print(\"Aggregating medium compounds by quartile...\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=MED_COMPOUND_BASE_COLS,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_quartile'],\n",
    "        agg_funcs=['mean', 'max', 'sum'],\n",
    "        feature_prefix='climate_risk_compound_med_quartile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "    # Aggregate by quartile-country-month\n",
    "    print(\"Aggregating medium compounds by quartile-country-month...\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=MED_COMPOUND_BASE_COLS[:8],\n",
    "        groupby_cols=['climate_risk_time_bin_quartile', 'country_name', 'month'],\n",
    "        agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        feature_prefix='climate_risk_compound_med_quartile_month_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "print(f\"Created {feature_count} medium compound expanded aggregation features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00ff942e",
   "metadata": {
    "_cell_guid": "f4b402d1-021f-432b-8894-59d03bf3191f",
    "_uuid": "f5be4789-9e16-4408-be76-f1411d499407",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:53:47.679386Z",
     "iopub.status.busy": "2026-01-30T16:53:47.678884Z",
     "iopub.status.idle": "2026-01-30T16:53:55.200043Z",
     "shell.execute_reply": "2026-01-30T16:53:55.198918Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 7.538806,
     "end_time": "2026-01-30T16:53:55.202225",
     "exception": false,
     "start_time": "2026-01-30T16:53:47.663419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tertile Aggregations\n",
      "Found 12 compound_med base columns\n",
      "Found 11 allrisk base columns\n",
      "Found 8 wcompound base columns\n",
      "Created 186 tertile aggregation features\n"
     ]
    }
   ],
   "source": [
    "#  TERTILE AGGREGATIONS\n",
    "# ============================================================================\n",
    "# Tertile aggregation for compound_med and allrisk (expanding time bins)\n",
    "print(\"\\n Tertile Aggregations\")\n",
    "feature_count = 0\n",
    "\n",
    "# Get compound med columns (base, not aggregated)\n",
    "COMPOUND_MED_BASE = [c for c in merged_df.columns if c.startswith('climate_risk_compound_med_') and '_agg_' not in c]\n",
    "ALLRISK_BASE = [c for c in merged_df.columns if c.startswith('climate_risk_allrisk_') and '_agg_' not in c]\n",
    "WCOMPOUND_BASE = [c for c in merged_df.columns if c.startswith('climate_risk_wcompound_') and '_agg_' not in c]\n",
    "\n",
    "if COMPOUND_MED_BASE:\n",
    "    print(f\"Found {len(COMPOUND_MED_BASE)} compound_med base columns\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=COMPOUND_MED_BASE,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_tertile'],\n",
    "        agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        feature_prefix='climate_risk_compound_med_tertile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "if ALLRISK_BASE:\n",
    "    print(f\"Found {len(ALLRISK_BASE)} allrisk base columns\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=ALLRISK_BASE,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_tertile'],\n",
    "        agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        feature_prefix='climate_risk_allrisk_tertile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "if WCOMPOUND_BASE:\n",
    "    print(f\"Found {len(WCOMPOUND_BASE)} wcompound base columns\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=WCOMPOUND_BASE,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_tertile'],\n",
    "        agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        feature_prefix='climate_risk_wcompound_tertile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "print(f\"Created {feature_count} tertile aggregation features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06b20983",
   "metadata": {
    "_cell_guid": "ddb8f356-5e39-4f6c-9d41-693251825ec2",
    "_uuid": "23dffa37-0947-47ae-8256-187c796d70b0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:53:55.234838Z",
     "iopub.status.busy": "2026-01-30T16:53:55.233477Z",
     "iopub.status.idle": "2026-01-30T16:53:59.996414Z",
     "shell.execute_reply": "2026-01-30T16:53:59.994964Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.781822,
     "end_time": "2026-01-30T16:53:59.998520",
     "exception": false,
     "start_time": "2026-01-30T16:53:55.216698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Octile Aggregations\n",
      "Created 120 octile aggregation features\n"
     ]
    }
   ],
   "source": [
    "#  OCTILE AGGREGATIONS\n",
    "# ============================================================================\n",
    "print(\"\\n Octile Aggregations\")\n",
    "feature_count = 0\n",
    "\n",
    "if COMPOUND_MED_BASE:\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=COMPOUND_MED_BASE[:12],\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_octile'],\n",
    "        agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        feature_prefix='climate_risk_compound_med_octile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "if ALLRISK_BASE:\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=ALLRISK_BASE[:8],\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_octile'],\n",
    "        agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        feature_prefix='climate_risk_allrisk_octile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "print(f\"Created {feature_count} octile aggregation features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aab98a30",
   "metadata": {
    "_cell_guid": "4a63e41e-28ed-4e42-af7d-114a69501495",
    "_uuid": "3fe8e8ba-2afa-4dcb-a606-c33775805321",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:54:00.030274Z",
     "iopub.status.busy": "2026-01-30T16:54:00.029971Z",
     "iopub.status.idle": "2026-01-30T16:54:06.015071Z",
     "shell.execute_reply": "2026-01-30T16:54:06.014014Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 6.0034,
     "end_time": "2026-01-30T16:54:06.017350",
     "exception": false,
     "start_time": "2026-01-30T16:54:00.013950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Product-Based Compound Features\n",
      "Creating product compounds...\n",
      "Aggregating 12 product features by quartile...\n",
      "Aggregating product features by quintile...\n",
      "Created 156 product-based features\n"
     ]
    }
   ],
   "source": [
    "#  PRODUCT-BASED COMPOUND FEATURES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n Product-Based Compound Features\")\n",
    "feature_count = 0\n",
    "\n",
    "def create_product_compounds(df, feature_prefix, created_features_list):\n",
    "    \"\"\"\n",
    "    Create product-based compound features (multiplication of risk levels).\n",
    "    \"\"\"\n",
    "    feat_count = 0\n",
    "\n",
    "    drought_med = df['climate_risk_cnt_locations_drought_risk_medium']\n",
    "    heat_med = df['climate_risk_cnt_locations_heat_stress_risk_medium']\n",
    "    excess_med = df['climate_risk_cnt_locations_excess_precip_risk_medium']\n",
    "    cold_med = df['climate_risk_cnt_locations_unseasonably_cold_risk_medium']\n",
    "    drought_high = df['climate_risk_cnt_locations_drought_risk_high']\n",
    "    heat_high = df['climate_risk_cnt_locations_heat_stress_risk_high']\n",
    "    excess_high = df['climate_risk_cnt_locations_excess_precip_risk_high']\n",
    "    cold_high = df['climate_risk_cnt_locations_unseasonably_cold_risk_high']\n",
    "    weight = df['percent_country_production'] / 100\n",
    "\n",
    "    # Product of medium risks (scaled)\n",
    "    feat_name = f'{feature_prefix}_drought_heat_med_product'\n",
    "    df[feat_name] = drought_med * heat_med / 100\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_excess_med_product'\n",
    "    df[feat_name] = drought_med * excess_med / 100\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_heat_excess_med_product'\n",
    "    df[feat_name] = heat_med * excess_med / 100\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_cold_med_product'\n",
    "    df[feat_name] = drought_med * cold_med / 100\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Triple products (scaled more)\n",
    "    feat_name = f'{feature_prefix}_drought_heat_excess_med_product'\n",
    "    df[feat_name] = drought_med * heat_med * excess_med / 10000\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Weighted products\n",
    "    feat_name = f'{feature_prefix}_w_drought_heat_med_product'\n",
    "    df[feat_name] = (drought_med * weight) * (heat_med * weight)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_w_drought_excess_med_product'\n",
    "    df[feat_name] = (drought_med * weight) * (excess_med * weight)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_w_heat_excess_med_product'\n",
    "    df[feat_name] = (heat_med * weight) * (excess_med * weight)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # High risk products (scaled)\n",
    "    feat_name = f'{feature_prefix}_drought_heat_high_product'\n",
    "    df[feat_name] = drought_high * heat_high / 100\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_excess_high_product'\n",
    "    df[feat_name] = drought_high * excess_high / 100\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Mixed high-med products\n",
    "    feat_name = f'{feature_prefix}_drought_high_heat_med_product'\n",
    "    df[feat_name] = drought_high * heat_med / 100\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    feat_name = f'{feature_prefix}_drought_med_excess_high_product'\n",
    "    df[feat_name] = drought_med * excess_high / 100\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    return feat_count\n",
    "\n",
    "print(\"Creating product compounds...\")\n",
    "feature_count += create_product_compounds(\n",
    "    df=merged_df,\n",
    "    feature_prefix='climate_risk_product',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "# Aggregate products by quartile \n",
    "PRODUCT_COLS = [c for c in merged_df.columns if c.startswith('climate_risk_product_')]\n",
    "if PRODUCT_COLS:\n",
    "    print(f\"Aggregating {len(PRODUCT_COLS)} product features by quartile...\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=PRODUCT_COLS,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_quartile'],\n",
    "        agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        feature_prefix='climate_risk_product_quartile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "    print(f\"Aggregating product features by quintile...\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=PRODUCT_COLS,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_quintile'],\n",
    "        agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        feature_prefix='climate_risk_product_quintile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "print(f\"Created {feature_count} product-based features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb44740e",
   "metadata": {
    "_cell_guid": "4f78e916-e372-4b2e-b422-66a22eded650",
    "_uuid": "07bacc11-5e77-49a4-8e8b-1b0df76b6a5e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:54:06.048775Z",
     "iopub.status.busy": "2026-01-30T16:54:06.048473Z",
     "iopub.status.idle": "2026-01-30T16:54:10.367997Z",
     "shell.execute_reply": "2026-01-30T16:54:10.367017Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.33773,
     "end_time": "2026-01-30T16:54:10.369975",
     "exception": false,
     "start_time": "2026-01-30T16:54:06.032245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Decile Aggregations\n",
      "Created 108 decile aggregation features\n"
     ]
    }
   ],
   "source": [
    "#  DECILE AGGREGATIONS\n",
    "# ============================================================================\n",
    "print(\"\\n Decile Aggregations\")\n",
    "feature_count = 0\n",
    "\n",
    "if COMPOUND_MED_BASE:\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=COMPOUND_MED_BASE[:10],\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_decile'],\n",
    "        agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        feature_prefix='climate_risk_compound_med_decile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "if WCOMPOUND_BASE:\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=WCOMPOUND_BASE[:8],\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_decile'],\n",
    "        agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        feature_prefix='climate_risk_wcompound_decile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "print(f\"Created {feature_count} decile aggregation features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "046cb1f0",
   "metadata": {
    "_cell_guid": "0a62d8de-8356-44a3-beaa-18b715cb8196",
    "_uuid": "06f71cf7-b693-4c2c-9958-d35288dfa5a4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:54:10.402024Z",
     "iopub.status.busy": "2026-01-30T16:54:10.401591Z",
     "iopub.status.idle": "2026-01-30T16:54:14.378048Z",
     "shell.execute_reply": "2026-01-30T16:54:14.376919Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.99515,
     "end_time": "2026-01-30T16:54:14.380338",
     "exception": false,
     "start_time": "2026-01-30T16:54:10.385188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Quartile-Country-Week Aggregations\n",
      "Created 96 quartile-country-week features\n"
     ]
    }
   ],
   "source": [
    "#  QUARTILE-COUNTRY AGGREGATIONS\n",
    "# ============================================================================\n",
    "# Week-level aggregation for compound features\n",
    "print(\"\\n Quartile-Country-Week Aggregations\")\n",
    "feature_count = 0\n",
    "\n",
    "if COMPOUND_MED_BASE:\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=COMPOUND_MED_BASE[:10],\n",
    "        groupby_cols=['climate_risk_time_bin_quartile', 'country_name'],\n",
    "        agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        feature_prefix='climate_risk_compound_med_quartile_country_names_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "if ALLRISK_BASE:\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=ALLRISK_BASE[:6],\n",
    "        groupby_cols=['climate_risk_time_bin_quartile', 'country_name'],\n",
    "        agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        feature_prefix='climate_risk_allrisk_quartile_country_names_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "print(f\"Created {feature_count} quartile-country-week features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61c6500d",
   "metadata": {
    "_cell_guid": "4f2a38fe-c3dc-4fa6-b756-6bfc77450d13",
    "_uuid": "47400950-6070-41b2-b603-c381eae175a2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:54:14.413092Z",
     "iopub.status.busy": "2026-01-30T16:54:14.412547Z",
     "iopub.status.idle": "2026-01-30T16:54:19.236759Z",
     "shell.execute_reply": "2026-01-30T16:54:19.235872Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.842772,
     "end_time": "2026-01-30T16:54:19.238837",
     "exception": false,
     "start_time": "2026-01-30T16:54:14.396065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sextile-Country Aggregations with Sum\n",
      "Created 120 sextile-country sum features\n"
     ]
    }
   ],
   "source": [
    "#  SEXTILE-COUNTRY AGGREGATIONS WITH SUM\n",
    "# ============================================================================\n",
    "# Sextile with sum is performing well\n",
    "print(\"\\n Sextile-Country Aggregations with Sum\")\n",
    "feature_count = 0\n",
    "\n",
    "if COMPOUND_MED_BASE:\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=COMPOUND_MED_BASE,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_sextile'],\n",
    "        agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        feature_prefix='climate_risk_compound_med_sextile_sum_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "if WCOMPOUND_BASE:\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=WCOMPOUND_BASE,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_sextile'],\n",
    "        agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        feature_prefix='climate_risk_wcompound_sextile_sum_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "print(f\"Created {feature_count} sextile-country sum features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54007b7e",
   "metadata": {
    "_cell_guid": "480efa6c-3445-4ab4-8b67-5fcd24402a21",
    "_uuid": "3e00f9c4-faca-4a98-9261-8da408ab18bf",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:54:19.272845Z",
     "iopub.status.busy": "2026-01-30T16:54:19.272431Z",
     "iopub.status.idle": "2026-01-30T16:54:23.350743Z",
     "shell.execute_reply": "2026-01-30T16:54:23.349470Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.098588,
     "end_time": "2026-01-30T16:54:23.353097",
     "exception": false,
     "start_time": "2026-01-30T16:54:19.254509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Weighted Sum Compound Features\n",
      "Creating weighted sum features...\n",
      "Aggregating 8 weighted sum features by quartile...\n",
      "Aggregating weighted sum features by quintile...\n",
      "Created 104 weighted sum features\n"
     ]
    }
   ],
   "source": [
    "#  WEIGHTED SUM COMPOUND FEATURES\n",
    "# ============================================================================\n",
    "# Create weighted sum features (weight * sum of risks)\n",
    "print(\"\\n Weighted Sum Compound Features\")\n",
    "feature_count = 0\n",
    "\n",
    "def create_weighted_sum_features(df, feature_prefix, created_features_list):\n",
    "    \"\"\"\n",
    "    Create features that are weighted sums of multiple risk types.\n",
    "    \"\"\"\n",
    "    feat_count = 0\n",
    "\n",
    "    drought_med = df['climate_risk_cnt_locations_drought_risk_medium']\n",
    "    heat_med = df['climate_risk_cnt_locations_heat_stress_risk_medium']\n",
    "    excess_med = df['climate_risk_cnt_locations_excess_precip_risk_medium']\n",
    "    cold_med = df['climate_risk_cnt_locations_unseasonably_cold_risk_medium']\n",
    "    drought_high = df['climate_risk_cnt_locations_drought_risk_high']\n",
    "    heat_high = df['climate_risk_cnt_locations_heat_stress_risk_high']\n",
    "    excess_high = df['climate_risk_cnt_locations_excess_precip_risk_high']\n",
    "    cold_high = df['climate_risk_cnt_locations_unseasonably_cold_risk_high']\n",
    "    weight = df['percent_country_production'] / 100\n",
    "\n",
    "    # Weighted sum of all medium risks\n",
    "    feat_name = f'{feature_prefix}_w_all_med_sum'\n",
    "    df[feat_name] = (drought_med + heat_med + excess_med + cold_med) * weight\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Weighted sum of all high risks\n",
    "    feat_name = f'{feature_prefix}_w_all_high_sum'\n",
    "    df[feat_name] = (drought_high + heat_high + excess_high + cold_high) * weight\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Weighted drought+heat (common pairing)\n",
    "    feat_name = f'{feature_prefix}_w_drought_heat_med_sum'\n",
    "    df[feat_name] = (drought_med + heat_med) * weight\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Weighted drought+excess\n",
    "    feat_name = f'{feature_prefix}_w_drought_excess_med_sum'\n",
    "    df[feat_name] = (drought_med + excess_med) * weight\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Weighted heat+excess+cold (non-drought)\n",
    "    feat_name = f'{feature_prefix}_w_non_drought_med_sum'\n",
    "    df[feat_name] = (heat_med + excess_med + cold_med) * weight\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Double weighted (weight squared)\n",
    "    feat_name = f'{feature_prefix}_w2_all_med_sum'\n",
    "    df[feat_name] = (drought_med + heat_med + excess_med + cold_med) * (weight ** 2)\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Combined high+med weighted\n",
    "    feat_name = f'{feature_prefix}_w_all_combined_sum'\n",
    "    df[feat_name] = (drought_med + drought_high + heat_med + heat_high + excess_med + excess_high) * weight\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    # Weighted max of medium risks\n",
    "    feat_name = f'{feature_prefix}_w_max_med'\n",
    "    df[feat_name] = df[['climate_risk_cnt_locations_drought_risk_medium',\n",
    "                        'climate_risk_cnt_locations_heat_stress_risk_medium',\n",
    "                        'climate_risk_cnt_locations_excess_precip_risk_medium',\n",
    "                        'climate_risk_cnt_locations_unseasonably_cold_risk_medium']].max(axis=1) * weight\n",
    "    df[feat_name] = df[feat_name].replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    created_features_list.append(feat_name)\n",
    "    feat_count += 1\n",
    "\n",
    "    return feat_count\n",
    "\n",
    "print(\"Creating weighted sum features...\")\n",
    "feature_count += create_weighted_sum_features(\n",
    "    df=merged_df,\n",
    "    feature_prefix='climate_risk_wsum',\n",
    "    created_features_list=ALL_NEW_FEATURES\n",
    ")\n",
    "\n",
    "# Aggregate weighted sum features\n",
    "WSUM_COLS = [c for c in merged_df.columns if c.startswith('climate_risk_wsum_')]\n",
    "if WSUM_COLS:\n",
    "    print(f\"Aggregating {len(WSUM_COLS)} weighted sum features by quartile...\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=WSUM_COLS,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_quartile'],\n",
    "        agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        feature_prefix='climate_risk_wsum_quartile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "    print(f\"Aggregating weighted sum features by quintile...\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=WSUM_COLS,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_quintile'],\n",
    "        agg_funcs=['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        feature_prefix='climate_risk_wsum_quintile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "print(f\"Created {feature_count} weighted sum features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ccfa9aba",
   "metadata": {
    "_cell_guid": "00fc86a2-cb07-42bd-94b0-197171d52d31",
    "_uuid": "2832cb5a-5b55-4d63-8fd5-d69d5672d616",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:54:23.385646Z",
     "iopub.status.busy": "2026-01-30T16:54:23.385307Z",
     "iopub.status.idle": "2026-01-30T16:54:49.338544Z",
     "shell.execute_reply": "2026-01-30T16:54:49.336746Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 25.972347,
     "end_time": "2026-01-30T16:54:49.340920",
     "exception": false,
     "start_time": "2026-01-30T16:54:23.368573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Missing Time-Bin Aggregations\n",
      "Adding allrisk + quartile aggregations...\n",
      "Adding allrisk + sextile aggregations...\n",
      "Adding allrisk + tertile aggregations...\n",
      "Adding compound_med + quartile aggregations...\n",
      "Adding wsum + sextile aggregations...\n",
      "Adding wsum + tertile aggregations...\n",
      "Adding de_compound + quartile aggregations...\n",
      "Adding de_compound + quintile aggregations...\n",
      "Adding wcompound + quartile aggregations...\n",
      "Adding wcompound + quintile aggregations...\n",
      "Adding product + quintile aggregations...\n",
      "Adding product + sextile aggregations...\n",
      "Created 661 missing time-bin aggregation features\n"
     ]
    }
   ],
   "source": [
    "#  MISSING TIME-BIN AGGREGATIONS FOR TOP PERFORMERS (FEATURES)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n Missing Time-Bin Aggregations\")\n",
    "feature_count = 0\n",
    "\n",
    "# --- allrisk: missing quartile, sextile, tertile ---\n",
    "ALLRISK_BASE = [c for c in merged_df.columns if c.startswith('climate_risk_allrisk_') and '_agg_' not in c]\n",
    "if ALLRISK_BASE:\n",
    "    print(\"Adding allrisk + quartile aggregations...\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=ALLRISK_BASE,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_quartile'],\n",
    "        agg_funcs=['sum', 'mean', 'max', 'std', 'var'],\n",
    "        feature_prefix='climate_risk_allrisk_quartile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "    print(\"Adding allrisk + sextile aggregations...\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=ALLRISK_BASE,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_sextile'],\n",
    "        agg_funcs=['sum', 'mean', 'max', 'std', 'var'],\n",
    "        feature_prefix='climate_risk_allrisk_sextile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "    print(\"Adding allrisk + tertile aggregations...\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=ALLRISK_BASE,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_tertile'],\n",
    "        agg_funcs=['sum', 'mean', 'max', 'std', 'var'],\n",
    "        feature_prefix='climate_risk_allrisk_tertile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "# --- compound_med: missing quartile ---\n",
    "COMPOUND_MED_BASE = [c for c in merged_df.columns if c.startswith('climate_risk_compound_med_') and '_agg_' not in c]\n",
    "if COMPOUND_MED_BASE:\n",
    "    print(\"Adding compound_med + quartile aggregations...\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=COMPOUND_MED_BASE,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_quartile'],\n",
    "        agg_funcs=['sum', 'mean', 'max', 'std', 'var'],\n",
    "        feature_prefix='climate_risk_compound_med_quartile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "# --- wsum: missing sextile, tertile ---\n",
    "WSUM_BASE = [c for c in merged_df.columns if c.startswith('climate_risk_wsum_') and '_agg_' not in c]\n",
    "if WSUM_BASE:\n",
    "    print(\"Adding wsum + sextile aggregations...\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=WSUM_BASE,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_sextile'],\n",
    "        agg_funcs=['sum', 'mean', 'max', 'std', 'var'],\n",
    "        feature_prefix='climate_risk_wsum_sextile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "    print(\"Adding wsum + tertile aggregations...\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=WSUM_BASE,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_tertile'],\n",
    "        agg_funcs=['sum', 'mean', 'max', 'std', 'var'],\n",
    "        feature_prefix='climate_risk_wsum_tertile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "# --- de_compound: missing quartile, quintile ---\n",
    "DE_COMPOUND_BASE = [c for c in merged_df.columns if c.startswith('climate_risk_de_compound_') and '_agg_' not in c]\n",
    "if DE_COMPOUND_BASE:\n",
    "    print(\"Adding de_compound + quartile aggregations...\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=DE_COMPOUND_BASE,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_quartile'],\n",
    "        agg_funcs=['sum', 'mean', 'max', 'min', 'std', 'var'],\n",
    "        feature_prefix='climate_risk_de_compound_quartile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "    print(\"Adding de_compound + quintile aggregations...\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=DE_COMPOUND_BASE,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_quintile'],\n",
    "        agg_funcs=['sum', 'mean', 'max', 'min', 'std', 'var'],\n",
    "        feature_prefix='climate_risk_de_compound_quintile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "# --- wcompound: missing quartile, quintile ---\n",
    "WCOMPOUND_BASE = [c for c in merged_df.columns if c.startswith('climate_risk_wcompound_') and '_agg_' not in c]\n",
    "if WCOMPOUND_BASE:\n",
    "    print(\"Adding wcompound + quartile aggregations...\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=WCOMPOUND_BASE,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_quartile'],\n",
    "        agg_funcs=['sum', 'mean', 'max', 'std', 'var'],\n",
    "        feature_prefix='climate_risk_wcompound_quartile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "    print(\"Adding wcompound + quintile aggregations...\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=WCOMPOUND_BASE,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_quintile'],\n",
    "        agg_funcs=['sum', 'mean', 'max', 'std', 'var'],\n",
    "        feature_prefix='climate_risk_wcompound_quintile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "# --- product: missing quintile, sextile ---\n",
    "PRODUCT_BASE = [c for c in merged_df.columns if c.startswith('climate_risk_product_') and '_agg_' not in c]\n",
    "if PRODUCT_BASE:\n",
    "    print(\"Adding product + quintile aggregations...\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=PRODUCT_BASE,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_quintile'],\n",
    "        agg_funcs=['sum', 'mean', 'max', 'std', 'var'],\n",
    "        feature_prefix='climate_risk_product_quintile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "    print(\"Adding product + sextile aggregations...\")\n",
    "    feature_count += create_groupby_agg_features(\n",
    "        df=merged_df,\n",
    "        source_cols=PRODUCT_BASE,\n",
    "        groupby_cols=['country_name', 'climate_risk_time_bin_sextile'],\n",
    "        agg_funcs=['sum', 'mean', 'max', 'std', 'var'],\n",
    "        feature_prefix='climate_risk_product_sextile_agg',\n",
    "        created_features_list=ALL_NEW_FEATURES\n",
    "    )\n",
    "\n",
    "print(f\"Created {feature_count} missing time-bin aggregation features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0f80363",
   "metadata": {
    "_cell_guid": "36d45788-0c83-4c17-b3f4-a7e9fa9dc4d4",
    "_uuid": "0aa7362c-b0c3-4bb7-9ec2-011eab8ac10f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:54:49.377735Z",
     "iopub.status.busy": "2026-01-30T16:54:49.377436Z",
     "iopub.status.idle": "2026-01-30T16:54:49.384392Z",
     "shell.execute_reply": "2026-01-30T16:54:49.383219Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.028186,
     "end_time": "2026-01-30T16:54:49.386717",
     "exception": false,
     "start_time": "2026-01-30T16:54:49.358531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FEATURE ENGINEERING SUMMARY\n",
      "================================================================================\n",
      "Total new features created: 3480\n",
      "Original climate risk columns: 12\n",
      "Grand total climate features: 3492\n"
     ]
    }
   ],
   "source": [
    "# SUMMARY OF FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total new features created: {len(ALL_NEW_FEATURES)}\")\n",
    "print(f\"Original climate risk columns: {len(climate_cols)}\")\n",
    "print(f\"Grand total climate features: {len(climate_cols) + len(ALL_NEW_FEATURES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31dfdbba",
   "metadata": {
    "_cell_guid": "e1e2f0e4-da85-40fb-abe9-603839ff9f37",
    "_uuid": "977d9f24-374b-487b-b07a-2296ea6d045b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:54:49.422737Z",
     "iopub.status.busy": "2026-01-30T16:54:49.422426Z",
     "iopub.status.idle": "2026-01-30T16:55:35.631332Z",
     "shell.execute_reply": "2026-01-30T16:55:35.630288Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 46.229927,
     "end_time": "2026-01-30T16:55:35.633521",
     "exception": false,
     "start_time": "2026-01-30T16:54:49.403594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "REMOVING HIGHLY CORRELATED FEATURES\n",
      "================================================================================\n",
      "Total climate features before removal: 3206\n",
      "\n",
      "  Removing FEATURES_TO_REMOVE features and their correlated counterparts (>= 70%)...\n",
      "FEATURES_TO_REMOVE features: 3\n",
      "Found in dataframe: 3\n",
      "Computing correlations for FEATURES_TO_REMOVE features.\n",
      "Total features to remove (including 70% correlated): 972\n",
      "\n",
      "  Additional correlated features being removed:\n",
      "- climate_risk_compound_med_tertile_agg_climate_risk_compound_med_drought_excess_med_product_mean\n",
      "- climate_risk_compound_med_quartile_agg_climate_risk_compound_med_drought_heat_med_geomean_sum\n",
      "- climate_risk_compound_med_octile_agg_climate_risk_compound_med_drought_heat_med_min_mean\n",
      "- climate_risk_compound_med_tertile_agg_climate_risk_compound_med_drought_excess_med_geomean_var\n",
      "- climate_risk_compound_med_quartile_agg_climate_risk_compound_med_all_med_sum_var\n",
      "- climate_risk_de_compound_quartile_month_agg_climate_risk_de_compound_drought_excess_med_max_mean\n",
      "- climate_risk_compound_med_tertile_agg_climate_risk_compound_med_drought_excess_med_sum_std\n",
      "- climate_risk_compound_med_octile_agg_climate_risk_compound_med_drought_heat_med_max_mean\n",
      "- climate_risk_tertile_agg_heat_stress_risk_medium_std\n",
      "- climate_risk_compound_med_quartile_country_names_agg_climate_risk_compound_med_heat_excess_med_sum_std\n",
      "- climate_risk_allrisk_octile_agg_climate_risk_allrisk_all_high_sum_mean\n",
      "- climate_risk_geomean_sextile_agg_climate_risk_geomean_drought_heat_elevated_geomean_var\n",
      "- climate_risk_tredecile_country_weekly_agg_excess_precip_risk_medium_mean\n",
      "- climate_risk_allrisk_quintile_agg_climate_risk_allrisk_all_high_sum_max\n",
      "- climate_risk_compound_med_tertile_agg_climate_risk_compound_med_drought_heat_med_min_mean\n",
      "- climate_risk_compound_med_quartile_country_names_agg_climate_risk_compound_med_drought_excess_med_sum_sum\n",
      "- climate_risk_de_compound_quintile_agg_climate_risk_de_compound_drought_excess_med_max_mean\n",
      "- climate_risk_compound_med_quintile_agg_climate_risk_compound_med_drought_excess_med_sum_max\n",
      "- climate_risk_tertile_agg_excess_precip_risk_medium_std\n",
      "- climate_risk_crosslevel_quintile_agg_climate_risk_crosslevel_heat_elevated_mean\n",
      "... and 949 more\n",
      "\n",
      "  Dropped 972 features from dataframe\n",
      "Remaining climate features: 2234\n",
      "\n",
      "  Now removing remaining features with >= 98% correlation...\n",
      "Calculating correlation matrix for 2234 features\n",
      "Computing correlations...\n",
      "Features to drop (>= 98% correlation): 789\n",
      "Features to keep: 1445\n",
      "\n",
      "  Sample highly correlated pairs (showing first 10):\n",
      "climate_risk_cnt_locations_heat_stress_risk_low    <-> climate_risk_decile_region_agg_unseasonably_cold_r : 0.9827\n",
      "climate_risk_cnt_locations_heat_stress_risk_low    <-> climate_risk_decile_region_agg_heat_stress_risk_lo : 0.9827\n",
      "climate_risk_cnt_locations_heat_stress_risk_low    <-> climate_risk_decile_region_agg_heat_stress_risk_lo : 0.9855\n",
      "climate_risk_cnt_locations_heat_stress_risk_low    <-> climate_risk_decile_region_agg_drought_risk_low_ma : 0.9827\n",
      "climate_risk_cnt_locations_heat_stress_risk_low    <-> climate_risk_decile_region_agg_excess_precip_risk_ : 0.9827\n",
      "climate_risk_cnt_locations_excess_precip_risk_medi <-> climate_risk_interaction_heat_stress_excess_precip : 0.9815\n",
      "climate_risk_cnt_locations_drought_risk_medium     <-> climate_risk_interaction_heat_stress_drought_mediu : 0.9923\n",
      "climate_risk_cnt_locations_drought_risk_medium     <-> climate_risk_interaction_heat_stress_drought_mediu : 0.9980\n",
      "climate_risk_cnt_locations_drought_risk_medium     <-> climate_risk_compound_med_drought_heat_med_sum     : 0.9923\n",
      "climate_risk_cnt_locations_drought_risk_medium     <-> climate_risk_compound_med_drought_heat_med_max     : 0.9980\n",
      "\n",
      "  Dropped 789 highly correlated features from dataframe\n",
      "Remaining climate features: 1445\n"
     ]
    }
   ],
   "source": [
    "# REMOVE HIGHLY CORRELATED FEATURES (>= 99% correlation)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REMOVING HIGHLY CORRELATED FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def remove_highly_correlated_features(df, feature_cols, threshold=0.99):\n",
    "    \"\"\"\n",
    "    Remove features that have >= threshold correlation with other features.\n",
    "    Keeps the first feature encountered, removes subsequent correlated features.\n",
    "    \"\"\"\n",
    "    n_features = len(feature_cols)\n",
    "    print(f\"Calculating correlation matrix for {n_features} features\")\n",
    "\n",
    "    # Sample rows if too many (correlation is stable with ~50k samples)\n",
    "    if len(df) > 50000:\n",
    "        sample_df = df[feature_cols].sample(n=100000, random_state=42)\n",
    "    else:\n",
    "        sample_df = df[feature_cols]\n",
    "\n",
    "    # Convert to numpy float32 (faster and less memory)\n",
    "    data = sample_df.values.astype(np.float32)\n",
    "\n",
    "    # Handle NaN values\n",
    "    data = np.nan_to_num(data, nan=0.0)\n",
    "\n",
    "    # Standardize columns (required for correlation via dot product)\n",
    "    means = np.mean(data, axis=0)\n",
    "    stds = np.std(data, axis=0)\n",
    "    stds[stds == 0] = 1  # Avoid division by zero\n",
    "\n",
    "    data_norm = (data - means) / stds\n",
    "\n",
    "    # Compute correlation matrix using matrix multiplication (much faster)\n",
    "    print(f\"Computing correlations...\")\n",
    "    corr_matrix = (data_norm.T @ data_norm) / len(data_norm)\n",
    "\n",
    "    # Take absolute values\n",
    "    corr_matrix = np.abs(corr_matrix)\n",
    "\n",
    "    # Find features to drop using vectorized operations\n",
    "    features_to_drop = set()\n",
    "    correlation_pairs = []\n",
    "\n",
    "    # Process upper triangle only\n",
    "    for i in range(n_features):\n",
    "        if i in features_to_drop:\n",
    "            continue\n",
    "        for j in range(i + 1, n_features):\n",
    "            if j in features_to_drop:\n",
    "                continue\n",
    "            if corr_matrix[i, j] >= threshold:\n",
    "                features_to_drop.add(j)\n",
    "                correlation_pairs.append((feature_cols[i], feature_cols[j], corr_matrix[i, j]))\n",
    "\n",
    "    features_to_drop_names = [feature_cols[i] for i in features_to_drop]\n",
    "    features_to_keep = [f for f in feature_cols if f not in features_to_drop_names]\n",
    "\n",
    "    return features_to_keep, features_to_drop_names, correlation_pairs\n",
    "\n",
    "# Get all climate risk features (original + engineered)\n",
    "all_climate_features = [c for c in merged_df.columns if c.startswith('climate_risk_')]\n",
    "print(f\"Total climate features before removal: {len(all_climate_features)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Remove FEATURES_TO_REMOVE features and their highly correlated counterparts\n",
    "# ============================================================================\n",
    "# Find features with >= CORRELATION_THRESHOLD_SPECIFIC correlation with FEATURES_TO_REMOVE features\n",
    "print(f\"\\n  Removing FEATURES_TO_REMOVE features and their correlated counterparts (>= {CORRELATION_THRESHOLD_SPECIFIC*100:.0f}%)...\")\n",
    "print(f\"FEATURES_TO_REMOVE features: {len(FEATURES_TO_REMOVE)}\")\n",
    "\n",
    "# Check which FEATURES_TO_REMOVE features exist in the dataframe\n",
    "existing_features_to_remove = [f for f in FEATURES_TO_REMOVE if f in merged_df.columns]\n",
    "print(f\"Found in dataframe: {len(existing_features_to_remove)}\")\n",
    "\n",
    "features_to_remove_with_correlated = set(existing_features_to_remove)\n",
    "\n",
    "if existing_features_to_remove:\n",
    "    # Only compute correlations for FEATURES_TO_REMOVE vs all features\n",
    "    print(\"Computing correlations for FEATURES_TO_REMOVE features.\")\n",
    "\n",
    "    # Sample rows if too many\n",
    "    if len(merged_df) > 50000:\n",
    "        sample_df = merged_df.sample(n=100000, random_state=42)\n",
    "    else:\n",
    "        sample_df = merged_df\n",
    "\n",
    "    # Get data for all features and FEATURES_TO_REMOVE features\n",
    "    # all_data = sample_df[all_climate_features].values.astype(np.float32)\n",
    "    all_data = sample_df[all_climate_features].copy()\n",
    "    all_data = np.nan_to_num(all_data, nan=0.0)\n",
    "\n",
    "    # Standardize\n",
    "    means = np.mean(all_data, axis=0)\n",
    "    stds = np.std(all_data, axis=0)\n",
    "    stds[stds == 0] = 1\n",
    "    all_data_norm = (all_data - means) / stds\n",
    "\n",
    "    # For each FEATURES_TO_REMOVE feature, find correlated features\n",
    "    for target_feat in existing_features_to_remove:\n",
    "        if target_feat in all_climate_features:\n",
    "            target_idx = all_climate_features.index(target_feat)\n",
    "            target_col = all_data_norm[:, target_idx]\n",
    "\n",
    "            # Compute correlation with all features\n",
    "            corrs = (all_data_norm.T @ target_col) / len(target_col)\n",
    "            corrs = np.abs(corrs)\n",
    "\n",
    "            # Find features with >= threshold correlation\n",
    "            for i, corr_val in enumerate(corrs):\n",
    "                if corr_val >= CORRELATION_THRESHOLD_SPECIFIC and all_climate_features[i] != target_feat:\n",
    "                    features_to_remove_with_correlated.add(all_climate_features[i])\n",
    "\n",
    "print(f\"Total features to remove (including {CORRELATION_THRESHOLD_SPECIFIC*100:.0f}% correlated): {len(features_to_remove_with_correlated)}\")\n",
    "\n",
    "# Show what's being removed\n",
    "if len(features_to_remove_with_correlated) > len(existing_features_to_remove):\n",
    "    print(f\"\\n  Additional correlated features being removed:\")\n",
    "    additional = features_to_remove_with_correlated - set(existing_features_to_remove)\n",
    "    for feat in list(additional)[:20]:  # Show first 20\n",
    "        print(f\"- {feat}\")\n",
    "    if len(additional) > 20:\n",
    "        print(f\"... and {len(additional) - 20} more\")\n",
    "\n",
    "# Remove from dataframe\n",
    "features_to_remove_list = [f for f in features_to_remove_with_correlated if f in merged_df.columns]\n",
    "if features_to_remove_list:\n",
    "    merged_df = merged_df.drop(columns=features_to_remove_list)\n",
    "    ALL_NEW_FEATURES = [f for f in ALL_NEW_FEATURES if f not in features_to_remove_with_correlated]\n",
    "    print(f\"\\n  Dropped {len(features_to_remove_list)} features from dataframe\")\n",
    "\n",
    "# Update all_climate_features list\n",
    "all_climate_features = [c for c in merged_df.columns if c.startswith('climate_risk_')]\n",
    "print(f\"Remaining climate features: {len(all_climate_features)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Remove remaining highly correlated features\n",
    "# ============================================================================\n",
    "print(f\"\\n  Now removing remaining features with >= {CORRELATION_THRESHOLD_GENERAL*100:.0f}% correlation...\")\n",
    "\n",
    "# Remove highly correlated features\n",
    "features_to_keep, features_to_drop, correlation_pairs = remove_highly_correlated_features(\n",
    "    merged_df,\n",
    "    all_climate_features,\n",
    "    threshold=CORRELATION_THRESHOLD_GENERAL\n",
    ")\n",
    "\n",
    "print(f\"Features to drop (>= {CORRELATION_THRESHOLD_GENERAL*100:.0f}% correlation): {len(features_to_drop)}\")\n",
    "print(f\"Features to keep: {len(features_to_keep)}\")\n",
    "\n",
    "# Show some examples of dropped correlations\n",
    "if len(correlation_pairs) > 0:\n",
    "    print(f\"\\n  Sample highly correlated pairs (showing first 10):\")\n",
    "    for feat1, feat2, corr_val in correlation_pairs[:10]:\n",
    "        print(f\"{feat1[:50]:50s} <-> {feat2[:50]:50s} : {corr_val:.4f}\")\n",
    "\n",
    "# Drop the highly correlated features from the dataframe\n",
    "if features_to_drop:\n",
    "    merged_df = merged_df.drop(columns=features_to_drop)\n",
    "    # Also remove from ALL_NEW_FEATURES list\n",
    "    ALL_NEW_FEATURES = [f for f in ALL_NEW_FEATURES if f not in features_to_drop]\n",
    "    print(f\"\\n  Dropped {len(features_to_drop)} highly correlated features from dataframe\")\n",
    "\n",
    "# Update climate_cols to reflect removed features\n",
    "climate_cols = [c for c in merged_df.columns if c.startswith('climate_risk_cnt_locations_')]\n",
    "print(f\"Remaining climate features: {len([c for c in merged_df.columns if c.startswith('climate_risk_')])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0e117ff",
   "metadata": {
    "_cell_guid": "f65ee4bb-dc75-4690-a79a-1948c8e04596",
    "_uuid": "12c739ac-d590-4270-bc02-d923e4daf723",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:55:35.670517Z",
     "iopub.status.busy": "2026-01-30T16:55:35.670001Z",
     "iopub.status.idle": "2026-01-30T16:59:35.044750Z",
     "shell.execute_reply": "2026-01-30T16:59:35.043440Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 239.41474,
     "end_time": "2026-01-30T16:59:35.065485",
     "exception": false,
     "start_time": "2026-01-30T16:55:35.650745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " FEATURE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Identifying valid IDs (matching sample submission approach)...\n",
      "Valid IDs from sample submission approach: 219,161\n",
      "\n",
      "Baseline dataset: 219,161 rows\n",
      "\n",
      "Analyzing feature contributions...\n",
      "Climate features to analyze (before removal): 1445\n",
      "\n",
      "Removing 12 auxiliary features...\n",
      "Found 8 features to drop from dataframe\n",
      "Climate features to analyze (after removal): 1437\n",
      "Grouping data by country and month...\n",
      "Processing 132 groups...\n",
      "Progress: 132/132 groups processed\n",
      "\n",
      "TOP 50 Features by Significant Correlation Count:\n",
      "================================================================================\n",
      "                                                                                          feature  sig_count  total_count  max_corr  avg_sig_corr\n",
      "                      climate_risk_wsum_quartile_agg_climate_risk_wsum_w_non_drought_med_sum_mean        904         2244    0.9711        0.7414\n",
      "                       climate_risk_wsum_quartile_agg_climate_risk_wsum_w_non_drought_med_sum_sum        848         2244    0.9433        0.7337\n",
      "                             climate_risk_wsum_quartile_agg_climate_risk_wsum_w2_all_med_sum_mean        829         2244    0.9590        0.7183\n",
      "   climate_risk_compound_med_sextile_agg_climate_risk_compound_med_drought_excess_med_product_sum        801         2244    0.9404        0.7164\n",
      "      climate_risk_de_compound_quartile_agg_climate_risk_de_compound_w_drought_excess_med_min_max        800         2244    0.9694        0.7587\n",
      "                              climate_risk_wsum_quartile_agg_climate_risk_wsum_w2_all_med_sum_sum        792         2244    0.9589        0.7211\n",
      "                        climate_risk_allrisk_quintile_agg_climate_risk_allrisk_w_all_med_sum_mean        790         2244    0.8822        0.6921\n",
      "                         climate_risk_allrisk_quintile_agg_climate_risk_allrisk_w_all_med_max_sum        784         2244    0.8931        0.6975\n",
      "                              climate_risk_wsum_quartile_agg_climate_risk_wsum_w2_all_med_sum_var        782         2244    0.9528        0.7386\n",
      "                 climate_risk_compound_med_quintile_agg_climate_risk_compound_med_all_med_sum_sum        778         2244    0.8812        0.6956\n",
      "               climate_risk_quartile_weighted_agg_climate_risk_weighted_heat_stress_risk_high_max        757         2244    0.9468        0.7579\n",
      "       climate_risk_de_compound_sextile_agg_climate_risk_de_compound_w_drought_excess_med_min_sum        734         2244    0.9524        0.7166\n",
      "            climate_risk_product_quartile_agg_climate_risk_product_w_drought_heat_med_product_max        726         2040    0.9552        0.7200\n",
      "                              climate_risk_wsum_quartile_agg_climate_risk_wsum_w_all_high_sum_sum        724         2244    0.9678        0.7237\n",
      "climate_risk_de_compound_sextile_agg_climate_risk_de_compound_drought_excess_elevated_geomean_sum        707         2244    0.9137        0.7275\n",
      "                climate_risk_quartile_ratio_agg_climate_risk_ratio_heat_stress_high_dominance_std        703         2244    0.9477        0.7494\n",
      "   climate_risk_wcompound_sextile_sum_agg_climate_risk_wcompound_w_drought_excess_med_product_sum        700         2244    0.9580        0.7197\n",
      "        climate_risk_wcompound_quartile_agg_climate_risk_wcompound_w_drought_heat_med_geomean_max        684         2244    0.9670        0.7171\n",
      "                       climate_risk_wsum_quartile_agg_climate_risk_wsum_w_non_drought_med_sum_var        672         2244    0.9692        0.7746\n",
      "          climate_risk_quartile_weighted_agg_climate_risk_weighted_excess_precip_risk_medium_mean        672         2244    0.9667        0.7411\n",
      "                       climate_risk_wsum_quartile_agg_climate_risk_wsum_w_non_drought_med_sum_std        661         2244    0.9678        0.7725\n",
      "             climate_risk_quartile_weighted_agg_climate_risk_weighted_heat_stress_risk_medium_max        653         2040    0.9645        0.7584\n",
      "  climate_risk_de_compound_quartile_month_agg_climate_risk_de_compound_drought_excess_med_max_sum        653         2244    0.9643        0.7908\n",
      "          climate_risk_product_quartile_agg_climate_risk_product_w_drought_excess_med_product_var        652         2244    0.9432        0.7592\n",
      "               climate_risk_quartile_ratio_agg_climate_risk_ratio_heat_stress_high_dominance_mean        649         2244    0.9520        0.7582\n",
      "  climate_risk_compound_med_sextile_agg_climate_risk_compound_med_drought_excess_med_product_mean        642         2244    0.9300        0.7338\n",
      "           climate_risk_compound_quartile_agg_climate_risk_compound_drought_heat_high_product_max        624         2040    0.9634        0.7931\n",
      "           climate_risk_compound_quartile_agg_climate_risk_compound_drought_heat_high_geomean_max        621         2244    0.9668        0.7856\n",
      "             climate_risk_product_quartile_agg_climate_risk_product_w_heat_excess_med_product_var        621         1836    0.9597        0.7967\n",
      "             climate_risk_product_quartile_agg_climate_risk_product_drought_cold_med_product_mean        620         2040    0.9557        0.7297\n",
      "       climate_risk_wcompound_quartile_agg_climate_risk_wcompound_w_drought_heat_high_geomean_max        615         2244    0.9670        0.7745\n",
      " climate_risk_de_compound_quartile_month_agg_climate_risk_de_compound_drought_excess_med_min_mean        614         2244    0.9646        0.7525\n",
      "                              climate_risk_wsum_quartile_agg_climate_risk_wsum_w_all_high_sum_max        613         2244    0.9630        0.7659\n",
      "              climate_risk_product_quartile_agg_climate_risk_product_drought_cold_med_product_sum        612         2040    0.9562        0.7322\n",
      "      climate_risk_compound_quartile_month_agg_climate_risk_compound_med_drought_heat_med_sum_sum        607         2244    0.9540        0.7791\n",
      "               climate_risk_quartile_ratio_agg_climate_risk_ratio_heat_stress_high_proportion_max        607         2244    0.9459        0.7787\n",
      "              climate_risk_product_quartile_agg_climate_risk_product_drought_cold_med_product_var        602         2040    0.9519        0.7688\n",
      "  climate_risk_de_compound_quartile_month_agg_climate_risk_de_compound_drought_excess_med_min_sum        601         2244    0.9576        0.8004\n",
      "  climate_risk_de_compound_quartile_month_agg_climate_risk_de_compound_drought_excess_med_min_var        600         2244    0.9602        0.7569\n",
      "           climate_risk_product_quartile_agg_climate_risk_product_w_drought_heat_med_product_mean        593         2040    0.9645        0.7755\n",
      "            climate_risk_product_quartile_agg_climate_risk_product_w_heat_excess_med_product_mean        593         1836    0.9636        0.8002\n",
      "  climate_risk_de_compound_quartile_month_agg_climate_risk_de_compound_drought_excess_med_min_std        591         2244    0.9606        0.7491\n",
      "      climate_risk_geomean_sextile_agg_climate_risk_geomean_w_drought_heat_excess_med_geomean_std        590         1836    0.9568        0.7478\n",
      "   climate_risk_weighted_quartile_country_month_agg_climate_risk_weighted_drought_risk_medium_sum        581         2244    0.9491        0.7799\n",
      "   climate_risk_wcompound_sextile_sum_agg_climate_risk_wcompound_w_drought_excess_med_product_var        580         2244    0.9650        0.7318\n",
      "                   climate_risk_quartile_weighted_agg_climate_risk_weighted_drought_risk_high_sum        580         2244    0.9468        0.7510\n",
      "            climate_risk_product_quartile_agg_climate_risk_product_w_drought_heat_med_product_var        577         2040    0.9647        0.7763\n",
      "          climate_risk_quintile_weighted_agg_climate_risk_weighted_excess_precip_risk_medium_mean        575         2244    0.9436        0.7234\n",
      "   climate_risk_compound_med_sextile_agg_climate_risk_compound_med_drought_excess_med_product_var        572         2244    0.9544        0.7281\n",
      "       climate_risk_wcompound_quartile_agg_climate_risk_wcompound_w_drought_heat_high_product_max        571         2040    0.9484        0.7799\n"
     ]
    }
   ],
   "source": [
    "# FEATURE ANALYSIS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" FEATURE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def analyze_feature_contributions(df, climate_cols, futures_cols):\n",
    "    \"\"\"Analyze which climate features have significant correlations with futures.\"\"\"\n",
    "\n",
    "    # Initialize stats for all features\n",
    "    feature_stats = {col: {'sig_count': 0, 'total_count': 0, 'max_corr': 0, 'sig_corrs': []}\n",
    "                     for col in climate_cols}\n",
    "\n",
    "    # Pre-group data once (much faster than filtering repeatedly)\n",
    "    print(\"Grouping data by country and month...\")\n",
    "    grouped = df.groupby(['country_name', 'date_on_month'])\n",
    "\n",
    "    total_groups = len(grouped)\n",
    "    print(f\"Processing {total_groups} groups...\")\n",
    "\n",
    "    # Process each group once\n",
    "    for group_idx, ((country, month), group_df) in enumerate(grouped):\n",
    "        if group_idx % 100 == 0:\n",
    "            print(f\"Progress: {group_idx}/{total_groups} groups processed\", end='\\r')\n",
    "\n",
    "        if len(group_df) < 2:\n",
    "            continue\n",
    "\n",
    "        # Convert to numpy arrays for faster computation\n",
    "        climate_data = group_df[climate_cols].values\n",
    "        futures_data = group_df[futures_cols].values\n",
    "\n",
    "        # Pre-compute standard deviations for all columns\n",
    "        climate_std = np.std(climate_data, axis=0)\n",
    "        futures_std = np.std(futures_data, axis=0)\n",
    "\n",
    "        # Find which columns have variance\n",
    "        valid_climate = climate_std > 0\n",
    "        valid_futures = futures_std > 0\n",
    "\n",
    "        # For each valid climate feature\n",
    "        for i, clim_col in enumerate(climate_cols):\n",
    "            if not valid_climate[i]:\n",
    "                continue\n",
    "\n",
    "            # For each valid futures column\n",
    "            for j, fut_col in enumerate(futures_cols):\n",
    "                if not valid_futures[j]:\n",
    "                    continue\n",
    "\n",
    "                # Compute correlation using numpy (faster than pandas)\n",
    "                corr = np.corrcoef(climate_data[:, i], futures_data[:, j])[0, 1]\n",
    "\n",
    "                if not np.isnan(corr):\n",
    "                    abs_corr = abs(corr)\n",
    "                    feature_stats[clim_col]['total_count'] += 1\n",
    "                    feature_stats[clim_col]['max_corr'] = max(feature_stats[clim_col]['max_corr'], abs_corr)\n",
    "\n",
    "                    if abs_corr >= SIGNIFICANCE_THRESHOLD:\n",
    "                        feature_stats[clim_col]['sig_count'] += 1\n",
    "                        feature_stats[clim_col]['sig_corrs'].append(abs_corr)\n",
    "\n",
    "    print(f\"Progress: {total_groups}/{total_groups} groups processed\")\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    results = []\n",
    "    for clim_col in climate_cols:\n",
    "        stats = feature_stats[clim_col]\n",
    "        avg_sig_corr = np.mean(stats['sig_corrs']) if stats['sig_corrs'] else 0\n",
    "        results.append({\n",
    "            'feature': clim_col,\n",
    "            'sig_count': stats['sig_count'],\n",
    "            'total_count': stats['total_count'],\n",
    "            'max_corr': round(stats['max_corr'], 4),\n",
    "            'avg_sig_corr': round(avg_sig_corr, 4)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results).sort_values('sig_count', ascending=False)\n",
    "\n",
    "# Prepare baseline dataset\n",
    "futures_cols = [c for c in merged_df.columns if c.startswith('futures_')]\n",
    "baseline_df = merged_df.dropna(subset=futures_cols)\n",
    "\n",
    "# Filter to valid rows (Recreate ALL features in temp_df)\n",
    "print(\"\\nIdentifying valid IDs (matching sample submission approach)...\")\n",
    "temp_df = pd.read_csv(f'{DATA_PATH}corn_climate_risk_futures_daily_master.csv')\n",
    "temp_df['date_on'] = pd.to_datetime(temp_df['date_on'])\n",
    "\n",
    "# Add basic features\n",
    "temp_df['day_of_year'] = temp_df['date_on'].dt.dayofyear\n",
    "temp_df['quarter'] = temp_df['date_on'].dt.quarter\n",
    "\n",
    "# Merge market share\n",
    "temp_df = temp_df.merge(\n",
    "    market_share_df[['region_id', 'percent_country_production']],\n",
    "    on='region_id', how='left'\n",
    ")\n",
    "temp_df['percent_country_production'] = temp_df['percent_country_production'].fillna(1.0)\n",
    "\n",
    "# Create base risk scores\n",
    "for risk_type in RISK_CATEGORIES:\n",
    "    low_col = f'climate_risk_cnt_locations_{risk_type}_risk_low'\n",
    "    med_col = f'climate_risk_cnt_locations_{risk_type}_risk_medium'\n",
    "    high_col = f'climate_risk_cnt_locations_{risk_type}_risk_high'\n",
    "\n",
    "    total = temp_df[low_col] + temp_df[med_col] + temp_df[high_col]\n",
    "    risk_score = (temp_df[med_col] + 2 * temp_df[high_col]) / (total + 1e-6)\n",
    "    weighted = risk_score * (temp_df['percent_country_production'] / 100)\n",
    "\n",
    "    temp_df[f'climate_risk_{risk_type}_score'] = risk_score\n",
    "    temp_df[f'climate_risk_{risk_type}_weighted'] = weighted\n",
    "\n",
    "# Create composite indices\n",
    "score_cols = [f'climate_risk_{r}_score' for r in RISK_CATEGORIES]\n",
    "temp_df['climate_risk_temperature_stress'] = temp_df[['climate_risk_heat_stress_score', 'climate_risk_unseasonably_cold_score']].max(axis=1)\n",
    "temp_df['climate_risk_precipitation_stress'] = temp_df[['climate_risk_excess_precip_score', 'climate_risk_drought_score']].max(axis=1)\n",
    "temp_df['climate_risk_overall_stress'] = temp_df[score_cols].max(axis=1)\n",
    "temp_df['climate_risk_combined_stress'] = temp_df[score_cols].mean(axis=1)\n",
    "\n",
    "# Sort for rolling operations\n",
    "temp_df = temp_df.sort_values(['region_id', 'date_on'])\n",
    "\n",
    "# Create rolling features (7, 14, 30 days)\n",
    "for window in [7, 14, 30]:\n",
    "    for risk_type in RISK_CATEGORIES:\n",
    "        score_col = f'climate_risk_{risk_type}_score'\n",
    "        temp_df[f'climate_risk_{risk_type}_ma_{window}d'] = (\n",
    "            temp_df.groupby('region_id')[score_col]\n",
    "            .transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "        )\n",
    "        temp_df[f'climate_risk_{risk_type}_max_{window}d'] = (\n",
    "            temp_df.groupby('region_id')[score_col]\n",
    "            .transform(lambda x: x.rolling(window, min_periods=1).max())\n",
    "        )\n",
    "\n",
    "# Create momentum features\n",
    "for risk_type in RISK_CATEGORIES:\n",
    "    score_col = f'climate_risk_{risk_type}_score'\n",
    "    temp_df[f'climate_risk_{risk_type}_change_1d'] = temp_df.groupby('region_id')[score_col].diff(1)\n",
    "    temp_df[f'climate_risk_{risk_type}_change_7d'] = temp_df.groupby('region_id')[score_col].diff(7)\n",
    "    temp_df[f'climate_risk_{risk_type}_acceleration'] = temp_df.groupby('region_id')[f'climate_risk_{risk_type}_change_1d'].diff(1)\n",
    "\n",
    "# Create country aggregations\n",
    "for risk_type in RISK_CATEGORIES:\n",
    "    score_col = f'climate_risk_{risk_type}_score'\n",
    "    weighted_col = f'climate_risk_{risk_type}_weighted'\n",
    "\n",
    "    country_agg = temp_df.groupby(['country_name', 'date_on']).agg({\n",
    "        score_col: ['mean', 'max', 'min', 'std', 'var', 'sum'],\n",
    "        weighted_col: 'sum',\n",
    "        'percent_country_production': 'sum'\n",
    "    }).round(4)\n",
    "\n",
    "    country_agg.columns = [f'country_{risk_type}_{\"_\".join(col).strip()}' for col in country_agg.columns]\n",
    "    country_agg = country_agg.reset_index()\n",
    "\n",
    "    temp_df = temp_df.merge(country_agg, on=['country_name', 'date_on'], how='left')\n",
    "\n",
    "# Get valid IDs\n",
    "valid_ids = temp_df.dropna()['ID'].tolist()\n",
    "print(f\"Valid IDs from sample submission approach: {len(valid_ids):,}\")\n",
    "\n",
    "# Clean up\n",
    "del temp_df\n",
    "\n",
    "# Filter baseline_df to valid IDs\n",
    "baseline_df = baseline_df[baseline_df['ID'].isin(valid_ids)]\n",
    "\n",
    "print(f\"\\nBaseline dataset: {len(baseline_df):,} rows\")\n",
    "\n",
    "# Analyze features\n",
    "print(\"\\nAnalyzing feature contributions...\")\n",
    "climate_features = [c for c in baseline_df.columns if c.startswith('climate_risk_')]\n",
    "print(f\"Climate features to analyze (before removal): {len(climate_features)}\")\n",
    "\n",
    "# Time bin columns are auxiliary (used for grouping, not as direct features)\n",
    "AUXILIARY_FEATURES_TO_REMOVE = [\n",
    "    \"climate_risk_time_bin_tertile\",\n",
    "    \"climate_risk_time_bin_quartile\",\n",
    "    \"climate_risk_time_bin_quintile\",\n",
    "    \"climate_risk_time_bin_sextile\",\n",
    "    \"climate_risk_time_bin_octile\",\n",
    "    \"climate_risk_time_bin_decile\",\n",
    "    \"climate_risk_time_bin_tredecile\",\n",
    "    \"climate_risk_time_bin_vigintile\",\n",
    "\n",
    "    \"climate_risk_quartile_agg_heat_stress_risk_high_max\",\n",
    "    \"climate_risk_tertile_agg_heat_stress_risk_high_max\",\n",
    "    \"climate_risk_country_sextile_std_drought_risk_high\",\n",
    "    \"climate_risk_quartile_agg_drought_risk_high_mean\"\n",
    "]\n",
    "\n",
    "print(f\"\\nRemoving {len(AUXILIARY_FEATURES_TO_REMOVE)} auxiliary features...\")\n",
    "features_to_drop = [f for f in AUXILIARY_FEATURES_TO_REMOVE if f in baseline_df.columns]\n",
    "print(f\"Found {len(features_to_drop)} features to drop from dataframe\")\n",
    "baseline_df = baseline_df.drop(columns=features_to_drop)\n",
    "\n",
    "# Update climate_features list\n",
    "climate_features = [c for c in baseline_df.columns if c.startswith('climate_risk_')]\n",
    "print(f\"Climate features to analyze (after removal): {len(climate_features)}\")\n",
    "\n",
    "feature_analysis = analyze_feature_contributions(baseline_df, climate_features, futures_cols)\n",
    "\n",
    "# Show top features\n",
    "print(\"\\nTOP 50 Features by Significant Correlation Count:\")\n",
    "print(\"=\"*80)\n",
    "print(feature_analysis.head(50).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2146491",
   "metadata": {
    "_cell_guid": "a152c2cf-3627-463b-9858-92c94d545c60",
    "_uuid": "a8bb941a-e02f-4657-b9d5-1acda1e83c27",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:59:35.102270Z",
     "iopub.status.busy": "2026-01-30T16:59:35.101912Z",
     "iopub.status.idle": "2026-01-30T16:59:35.126876Z",
     "shell.execute_reply": "2026-01-30T16:59:35.125429Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.048239,
     "end_time": "2026-01-30T16:59:35.131408",
     "exception": false,
     "start_time": "2026-01-30T16:59:35.083169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bottom 300 Features by Significant Correlation Count:\n",
      "================================================================================\n",
      "                                                                                                    feature  sig_count  total_count  max_corr  avg_sig_corr\n",
      "climate_risk_compound_med_quartile_country_names_agg_climate_risk_compound_med_drought_heat_med_product_min          0            0    0.0000           0.0\n",
      "                                                                       climate_risk_wsum_w_all_combined_sum          0         2244    0.2725           0.0\n",
      "                                         climate_risk_wsum_quartile_agg_climate_risk_wsum_w_all_med_sum_min          0            0    0.0000           0.0\n",
      "                                        climate_risk_wsum_quartile_agg_climate_risk_wsum_w_all_high_sum_min          0            0    0.0000           0.0\n",
      "                                climate_risk_wsum_quartile_agg_climate_risk_wsum_w_drought_heat_med_sum_min          0            0    0.0000           0.0\n",
      "                              climate_risk_wsum_quartile_agg_climate_risk_wsum_w_drought_excess_med_sum_min          0            0    0.0000           0.0\n",
      "             climate_risk_compound_med_sextile_agg_climate_risk_compound_med_drought_excess_med_geomean_min          0         1904    0.0000           0.0\n",
      "                climate_risk_compound_med_sextile_agg_climate_risk_compound_med_heat_excess_med_product_min          0            0    0.0000           0.0\n",
      "                                                           climate_risk_country_daily_drought_risk_high_sum          0         2244    0.5303           0.0\n",
      "                            climate_risk_compound_med_sextile_agg_climate_risk_compound_med_all_med_sum_min          0            0    0.0000           0.0\n",
      "                            climate_risk_compound_med_sextile_agg_climate_risk_compound_med_all_med_max_min          0            0    0.0000           0.0\n",
      "                     climate_risk_decile_ratio_agg_climate_risk_ratio_unseasonably_cold_high_proportion_min          0            0    0.0000           0.0\n",
      "                                               climate_risk_low_severity_spatial_std_excess_precip_risk_low          0         2244    0.4209           0.0\n",
      "                                                  climate_risk_interaction_heat_stress_drought_high_product          0         1258    0.2789           0.0\n",
      "                                                      climate_risk_interaction_heat_stress_drought_high_sum          0         2244    0.3940           0.0\n",
      "                                                climate_risk_interaction_heat_stress_drought_medium_product          0         1156    0.2662           0.0\n",
      "                                            climate_risk_interaction_heat_stress_excess_precip_high_product          0         1020    0.1317           0.0\n",
      "                    climate_risk_compound_med_sextile_agg_climate_risk_compound_med_heat_excess_med_sum_min          0            0    0.0000           0.0\n",
      "                                                    climate_risk_country_daily_excess_precip_risk_high_mean          0         2244    0.5917           0.0\n",
      "                                                     climate_risk_country_daily_excess_precip_risk_high_max          0         2244    0.5935           0.0\n",
      "                                                     climate_risk_country_daily_excess_precip_risk_high_sum          0         2244    0.5917           0.0\n",
      "                                                climate_risk_country_daily_unseasonably_cold_risk_high_mean          0         1547    0.4847           0.0\n",
      "            climate_risk_compound_med_sextile_sum_agg_climate_risk_compound_med_heat_excess_med_product_min          0            0    0.0000           0.0\n",
      "                climate_risk_compound_med_sextile_sum_agg_climate_risk_compound_med_heat_excess_med_sum_min          0            0    0.0000           0.0\n",
      "                                          climate_risk_interaction_unseasonably_cold_excess_precip_high_sum          0         2244    0.3481           0.0\n",
      "                                                                           climate_risk_wsum_w2_all_med_sum          0         2244    0.1668           0.0\n",
      "                                        climate_risk_interaction_unseasonably_cold_excess_precip_medium_sum          0         2244    0.4174           0.0\n",
      "                                                      climate_risk_country_daily_heat_stress_risk_high_mean          0         1377    0.5322           0.0\n",
      "                                                       climate_risk_country_daily_heat_stress_risk_high_max          0         1377    0.5113           0.0\n",
      "                                                 climate_risk_country_daily_unseasonably_cold_risk_high_max          0         1547    0.4606           0.0\n",
      "                                                 climate_risk_country_daily_unseasonably_cold_risk_high_sum          0         1547    0.4847           0.0\n",
      "             climate_risk_wcompound_sextile_sum_agg_climate_risk_wcompound_w_drought_excess_med_product_min          0            0    0.0000           0.0\n",
      "             climate_risk_wcompound_sextile_sum_agg_climate_risk_wcompound_w_drought_excess_med_geomean_min          0         1904    0.0000           0.0\n",
      "                                                                    climate_risk_wsum_w_non_drought_med_sum          0         2244    0.3978           0.0\n",
      "                                    climate_risk_interaction_unseasonably_cold_excess_precip_medium_product          0         1275    0.3643           0.0\n",
      "                                                                  climate_risk_ratio_drought_high_dominance          0         2244    0.2893           0.0\n",
      "                                                             climate_risk_ratio_drought_elevated_proportion          0         2244    0.4915           0.0\n",
      "                                                                  climate_risk_ratio_drought_high_med_ratio          0         2244    0.2500           0.0\n",
      "                                                            climate_risk_ratio_excess_precip_high_dominance          0         2244    0.2824           0.0\n",
      "                                                       climate_risk_ratio_excess_precip_elevated_proportion          0         2244    0.4821           0.0\n",
      "                                                     climate_risk_quarterly_agg_heat_stress_risk_medium_std          0          986    0.0000           0.0\n",
      "                                                     climate_risk_quarterly_agg_heat_stress_risk_medium_min          0            0    0.0000           0.0\n",
      "                                                     climate_risk_quarterly_agg_heat_stress_risk_medium_max          0            0    0.0000           0.0\n",
      "                                                    climate_risk_quarterly_agg_heat_stress_risk_medium_mean          0         1088    0.0000           0.0\n",
      "                  climate_risk_geomean_sextile_agg_climate_risk_geomean_drought_heat_excess_med_geomean_min          0         1700    0.0000           0.0\n",
      "                         climate_risk_geomean_sextile_agg_climate_risk_geomean_cold_drought_med_geomean_min          0         1904    0.0000           0.0\n",
      "                                                           climate_risk_quarterly_agg_drought_risk_high_min          0            0    0.0000           0.0\n",
      "                                                          climate_risk_quarterly_agg_drought_risk_high_mean          0         1598    0.0000           0.0\n",
      "                                                       climate_risk_monthly_agg_heat_stress_risk_medium_var          0          833    0.0000           0.0\n",
      "                                                       climate_risk_monthly_agg_heat_stress_risk_medium_std          0          935    0.0000           0.0\n",
      "                        climate_risk_product_quartile_agg_climate_risk_product_drought_cold_med_product_min          0            0    0.0000           0.0\n",
      "                         climate_risk_geomean_sextile_agg_climate_risk_geomean_heat_excess_high_geomean_min          0         1904    0.0000           0.0\n",
      "                                                             climate_risk_monthly_agg_drought_risk_high_var          0         1326    0.0000           0.0\n",
      "                                                             climate_risk_monthly_agg_drought_risk_high_sum          0            0    0.0000           0.0\n",
      "                                                           climate_risk_monthly_agg_drought_risk_medium_min          0            0    0.0000           0.0\n",
      "                                                           climate_risk_monthly_agg_drought_risk_medium_sum          0            0    0.0000           0.0\n",
      "                                                              climate_risk_geomean_heat_excess_high_geomean          0         2040    0.1610           0.0\n",
      "                                                              climate_risk_geomean_cold_drought_med_geomean          0         2159    0.3044           0.0\n",
      "                                                       climate_risk_monthly_agg_heat_stress_risk_medium_min          0            0    0.0000           0.0\n",
      "               climate_risk_compound_quartile_month_agg_climate_risk_compound_drought_heat_high_geomean_min          0         1904    0.0000           0.0\n",
      "                   climate_risk_compound_quartile_month_agg_climate_risk_compound_drought_vs_heat_ratio_min          0            0    0.0000           0.0\n",
      "            climate_risk_compound_quartile_month_agg_climate_risk_compound_med_drought_heat_med_product_min          0            0    0.0000           0.0\n",
      "                                                         climate_risk_monthly_agg_heat_stress_risk_high_min          0            0    0.0000           0.0\n",
      "                                                         climate_risk_monthly_agg_heat_stress_risk_high_std          0          952    0.0000           0.0\n",
      "                                                         climate_risk_monthly_agg_heat_stress_risk_high_var          0          986    0.0000           0.0\n",
      "                                                      climate_risk_monthly_agg_heat_stress_risk_medium_mean          0          782    0.0000           0.0\n",
      "                                                       climate_risk_monthly_agg_heat_stress_risk_medium_max          0            0    0.0000           0.0\n",
      "                                                       climate_risk_geomean_drought_heat_excess_med_geomean          0         1887    0.1728           0.0\n",
      "                   climate_risk_geomean_quartile_month_agg_climate_risk_geomean_heat_excess_med_geomean_min          0         1904    0.0000           0.0\n",
      "                                                        climate_risk_wcompound_w_drought_excess_med_geomean          0         2244    0.2454           0.0\n",
      "                          climate_risk_quintile_ratio_agg_climate_risk_ratio_heat_stress_high_dominance_min          0            0    0.0000           0.0\n",
      "                     climate_risk_quintile_ratio_agg_climate_risk_ratio_heat_stress_elevated_proportion_min          0            0    0.0000           0.0\n",
      "                         climate_risk_quintile_ratio_agg_climate_risk_ratio_heat_stress_high_proportion_min          0            0    0.0000           0.0\n",
      "                          climate_risk_quintile_ratio_agg_climate_risk_ratio_heat_stress_high_med_ratio_min          0            0    0.0000           0.0\n",
      "               climate_risk_compound_quartile_month_agg_climate_risk_compound_drought_heat_high_product_min          0            0    0.0000           0.0\n",
      "                      climate_risk_sextile_ratio_agg_climate_risk_ratio_heat_stress_elevated_proportion_min          0            0    0.0000           0.0\n",
      "                          climate_risk_sextile_ratio_agg_climate_risk_ratio_heat_stress_high_proportion_min          0            0    0.0000           0.0\n",
      "                           climate_risk_sextile_ratio_agg_climate_risk_ratio_heat_stress_high_med_ratio_min          0            0    0.0000           0.0\n",
      "                                                            climate_risk_ratio_excess_precip_high_med_ratio          0         2244    0.2530           0.0\n",
      "                                                        climate_risk_ratio_unseasonably_cold_high_dominance          0         1547    0.2712           0.0\n",
      "                                                   climate_risk_ratio_unseasonably_cold_elevated_proportion          0         1547    0.2671           0.0\n",
      "                                                        climate_risk_ratio_unseasonably_cold_high_med_ratio          0         1547    0.2638           0.0\n",
      "           climate_risk_de_compound_quartile_month_agg_climate_risk_de_compound_drought_excess_high_max_min          0            0    0.0000           0.0\n",
      "               climate_risk_quartile_ratio_agg_climate_risk_ratio_unseasonably_cold_elevated_proportion_min          0            0    0.0000           0.0\n",
      "                   climate_risk_quintile_ratio_agg_climate_risk_ratio_unseasonably_cold_high_proportion_min          0            0    0.0000           0.0\n",
      "                  climate_risk_geomean_sextile_agg_climate_risk_geomean_drought_excess_elevated_geomean_min          0         1904    0.0000           0.0\n",
      "                     climate_risk_geomean_sextile_agg_climate_risk_geomean_heat_excess_elevated_geomean_min          0         1904    0.0000           0.0\n",
      "         climate_risk_weighted_quartile_country_month_agg_climate_risk_weighted_heat_stress_risk_medium_min          0            0    0.0000           0.0\n",
      "                    climate_risk_vigintile_ratio_agg_climate_risk_ratio_heat_stress_elevated_proportion_min          0            0    0.0000           0.0\n",
      "                         climate_risk_vigintile_ratio_agg_climate_risk_ratio_heat_stress_high_dominance_min          0            0    0.0000           0.0\n",
      "                   climate_risk_vigintile_ratio_agg_climate_risk_ratio_unseasonably_cold_high_med_ratio_min          0            0    0.0000           0.0\n",
      "           climate_risk_de_compound_quartile_month_agg_climate_risk_de_compound_drought_excess_high_min_min          0            0    0.0000           0.0\n",
      "                                                         climate_risk_monthly_agg_heat_stress_risk_high_max          0            0    0.0000           0.0\n",
      "                    climate_risk_geomean_sextile_agg_climate_risk_geomean_drought_heat_elevated_geomean_min          0         1904    0.0000           0.0\n",
      "                   climate_risk_compound_quartile_month_agg_climate_risk_compound_drought_heat_high_max_min          0            0    0.0000           0.0\n",
      "                   climate_risk_compound_quartile_month_agg_climate_risk_compound_drought_heat_high_min_min          0            0    0.0000           0.0\n",
      "                          climate_risk_quartile_ratio_agg_climate_risk_ratio_heat_stress_high_dominance_min          0            0    0.0000           0.0\n",
      "                    climate_risk_quartile_ratio_agg_climate_risk_ratio_unseasonably_cold_high_med_ratio_min          0            0    0.0000           0.0\n",
      "                   climate_risk_quartile_ratio_agg_climate_risk_ratio_unseasonably_cold_high_proportion_min          0            0    0.0000           0.0\n",
      "                                                               climate_risk_geomean_heat_excess_med_geomean          0         2108    0.1784           0.0\n",
      "                                                        climate_risk_monthly_agg_heat_stress_risk_high_mean          0          969    0.0000           0.0\n",
      "                                                         climate_risk_quarterly_agg_drought_risk_medium_sum          0            0    0.0000           0.0\n",
      "                                                         climate_risk_quarterly_agg_drought_risk_medium_min          0            0    0.0000           0.0\n",
      "                                                            climate_risk_cnt_locations_heat_stress_risk_low          0         2244    0.2314           0.0\n",
      "                                                             climate_risk_cnt_locations_drought_risk_medium          0         2244    0.3974           0.0\n",
      "                                                                climate_risk_cnt_locations_drought_risk_low          0         2244    0.3807           0.0\n",
      "                                                          climate_risk_cnt_locations_excess_precip_risk_low          0         2244    0.4186           0.0\n",
      "                                                                 climate_risk_spatial_std_drought_risk_high          0         2244    0.5560           0.0\n",
      "                                                             climate_risk_spatial_std_heat_stress_risk_high          0         2244    0.5612           0.0\n",
      "                                                               climate_risk_cnt_locations_drought_risk_high          0         2244    0.3893           0.0\n",
      "                  climate_risk_vigintile_ratio_agg_climate_risk_ratio_unseasonably_cold_high_proportion_min          0            0    0.0000           0.0\n",
      "                                                   climate_risk_de_compound_drought_med_excess_high_geomean          0         2244    0.3181           0.0\n",
      "                                                   climate_risk_de_compound_drought_high_excess_med_geomean          0         2244    0.2606           0.0\n",
      "                climate_risk_tertile_ratio_agg_climate_risk_ratio_unseasonably_cold_elevated_proportion_min          0            0    0.0000           0.0\n",
      "                                        climate_risk_tredecile_country_weekly_agg_heat_stress_risk_high_min          0            0    0.0000           0.0\n",
      "                                      climate_risk_tredecile_country_weekly_agg_heat_stress_risk_medium_min          0            0    0.0000           0.0\n",
      "                          climate_risk_geomean_sextile_agg_climate_risk_geomean_heat_excess_med_geomean_min          0         1904    0.0000           0.0\n",
      "                                          climate_risk_decile_region_agg_unseasonably_cold_risk_medium_mean          0         2040    0.5761           0.0\n",
      "         climate_risk_de_compound_quintile_agg_climate_risk_de_compound_drought_excess_elevated_geomean_min          0         1904    0.0000           0.0\n",
      "                                                       climate_risk_compound_med_drought_excess_med_geomean          0         2244    0.2978           0.0\n",
      "                         climate_risk_compound_quintile_agg_climate_risk_compound_drought_vs_heat_ratio_max          0            0    0.0000           0.0\n",
      "                          climate_risk_compound_sextile_agg_climate_risk_compound_drought_vs_heat_ratio_max          0            0    0.0000           0.0\n",
      "                                           climate_risk_decile_region_agg_unseasonably_cold_risk_medium_max          0         2040    0.3116           0.0\n",
      "                 climate_risk_de_compound_quintile_agg_climate_risk_de_compound_drought_excess_high_max_min          0            0    0.0000           0.0\n",
      "                  climate_risk_de_compound_quartile_agg_climate_risk_de_compound_drought_excess_med_min_min          0            0    0.0000           0.0\n",
      "                         climate_risk_compound_quartile_agg_climate_risk_compound_drought_vs_heat_ratio_max          0            0    0.0000           0.0\n",
      "                 climate_risk_de_compound_quartile_agg_climate_risk_de_compound_drought_excess_high_min_min          0            0    0.0000           0.0\n",
      "                climate_risk_de_compound_quintile_agg_climate_risk_de_compound_w_drought_excess_med_max_min          0            0    0.0000           0.0\n",
      "             climate_risk_de_compound_quintile_agg_climate_risk_de_compound_drought_excess_high_product_min          0            0    0.0000           0.0\n",
      "                                                         climate_risk_cnt_locations_excess_precip_risk_high          0         2244    0.4296           0.0\n",
      "                  climate_risk_de_compound_quintile_agg_climate_risk_de_compound_drought_excess_med_min_min          0            0    0.0000           0.0\n",
      "                                                       climate_risk_decile_region_agg_drought_risk_low_mean          0         2244    0.3573           0.0\n",
      "                 climate_risk_de_compound_quartile_agg_climate_risk_de_compound_drought_excess_high_max_min          0            0    0.0000           0.0\n",
      "             climate_risk_de_compound_quintile_agg_climate_risk_de_compound_drought_excess_high_geomean_min          0         1904    0.0000           0.0\n",
      "                                                          climate_risk_geomean_heat_excess_elevated_geomean          0         2108    0.1822           0.0\n",
      "                                                              climate_risk_ratio_heat_stress_high_dominance          0         1377    0.2503           0.0\n",
      "                                                              climate_risk_ratio_heat_stress_high_med_ratio          0         1377    0.2607           0.0\n",
      "                                                     climate_risk_quarterly_agg_heat_stress_risk_medium_var          0          969    0.0000           0.0\n",
      "                                                           climate_risk_quarterly_agg_drought_risk_high_sum          0            0    0.0000           0.0\n",
      "                                                           climate_risk_quarterly_agg_drought_risk_high_var          0         1445    0.0000           0.0\n",
      "                                                           climate_risk_quarterly_agg_drought_risk_high_std          0         1547    0.0000           0.0\n",
      "                                                         climate_risk_geomean_drought_heat_elevated_geomean          0         2125    0.3122           0.0\n",
      "                                                     climate_risk_geomean_w_drought_heat_excess_med_geomean          0         1887    0.1762           0.0\n",
      "                                                             climate_risk_geomean_w_heat_excess_med_geomean          0         2108    0.1702           0.0\n",
      "                                                      climate_risk_geomean_drought_heat_excess_high_geomean          0         1785    0.1506           0.0\n",
      "                    climate_risk_quintile_ratio_agg_climate_risk_ratio_unseasonably_cold_high_med_ratio_min          0            0    0.0000           0.0\n",
      "                                                            climate_risk_de_compound_drought_excess_med_max          0         2244    0.2905           0.0\n",
      "                                                            climate_risk_de_compound_drought_excess_med_min          0         2244    0.2896           0.0\n",
      "                                                           climate_risk_de_compound_drought_excess_high_max          0         2244    0.3388           0.0\n",
      "                                                      climate_risk_quarterly_agg_heat_stress_risk_high_mean          0         1071    0.0000           0.0\n",
      "                                                       climate_risk_quarterly_agg_heat_stress_risk_high_max          0            0    0.0000           0.0\n",
      "                                                       climate_risk_quarterly_agg_heat_stress_risk_high_min          0            0    0.0000           0.0\n",
      "                                                       climate_risk_quarterly_agg_heat_stress_risk_high_std          0         1122    0.0000           0.0\n",
      "   climate_risk_de_compound_quartile_month_agg_climate_risk_de_compound_drought_high_excess_med_geomean_min          0         1904    0.0000           0.0\n",
      "   climate_risk_de_compound_quartile_month_agg_climate_risk_de_compound_drought_med_excess_high_geomean_min          0         1904    0.0000           0.0\n",
      "                                                                          climate_risk_allrisk_all_high_max          0         2244    0.3474           0.0\n",
      "                                                                           climate_risk_allrisk_all_med_min          0           68    0.0959           0.0\n",
      "                                                           climate_risk_de_compound_drought_excess_high_min          0         2176    0.1969           0.0\n",
      "                                                                         climate_risk_allrisk_w_all_med_sum          0         2244    0.2042           0.0\n",
      "                                                                        climate_risk_allrisk_w_all_high_max          0         2244    0.3012           0.0\n",
      "                                                                      climate_risk_allrisk_all_elevated_max          0         2244    0.2774           0.0\n",
      "                                                                      climate_risk_allrisk_all_elevated_sum          0         2244    0.3103           0.0\n",
      "                                                                       climate_risk_allrisk_all_med_geomean          0         2227    0.0933           0.0\n",
      "                climate_risk_compound_quartile_month_agg_climate_risk_compound_med_drought_heat_med_min_min          0            0    0.0000           0.0\n",
      "                                                       climate_risk_de_compound_drought_excess_high_product          0         2176    0.1773           0.0\n",
      "                                                       climate_risk_de_compound_drought_excess_high_geomean          0         2227    0.2058           0.0\n",
      "                                                                         climate_risk_allrisk_w_all_med_max          0         2244    0.2143           0.0\n",
      "                  climate_risk_compound_med_octile_agg_climate_risk_compound_med_drought_excess_med_sum_min          0            0    0.0000           0.0\n",
      "              climate_risk_compound_med_octile_agg_climate_risk_compound_med_drought_excess_med_product_min          0            0    0.0000           0.0\n",
      "                climate_risk_compound_med_octile_agg_climate_risk_compound_med_drought_heat_med_geomean_min          0         1904    0.0000           0.0\n",
      "                    climate_risk_compound_med_octile_agg_climate_risk_compound_med_drought_heat_med_min_min          0            0    0.0000           0.0\n",
      "                               climate_risk_decile_weighted_agg_climate_risk_weighted_drought_risk_high_min          0            0    0.0000           0.0\n",
      "                           climate_risk_decile_weighted_agg_climate_risk_weighted_heat_stress_risk_high_min          0            0    0.0000           0.0\n",
      "                   climate_risk_vigintile_ratio_agg_climate_risk_ratio_unseasonably_cold_high_dominance_min          0            0    0.0000           0.0\n",
      "              climate_risk_vigintile_ratio_agg_climate_risk_ratio_unseasonably_cold_elevated_proportion_min          0            0    0.0000           0.0\n",
      "                      climate_risk_wcompound_tertile_agg_climate_risk_wcompound_w_drought_heat_high_max_min          0            0    0.0000           0.0\n",
      "                       climate_risk_octile_weighted_agg_climate_risk_weighted_excess_precip_risk_medium_min          0            0    0.0000           0.0\n",
      "                    climate_risk_compound_med_octile_agg_climate_risk_compound_med_drought_heat_med_max_min          0            0    0.0000           0.0\n",
      "                    climate_risk_compound_med_octile_agg_climate_risk_compound_med_drought_heat_med_sum_min          0            0    0.0000           0.0\n",
      "                climate_risk_compound_med_octile_agg_climate_risk_compound_med_drought_heat_med_product_min          0            0    0.0000           0.0\n",
      "                 climate_risk_wcompound_tertile_agg_climate_risk_wcompound_w_drought_excess_med_geomean_min          0         1904    0.0000           0.0\n",
      "                 climate_risk_wcompound_tertile_agg_climate_risk_wcompound_w_drought_excess_med_product_min          0            0    0.0000           0.0\n",
      "                  climate_risk_geomean_quartile_month_agg_climate_risk_geomean_heat_excess_high_geomean_min          0         1904    0.0000           0.0\n",
      "                                                            climate_risk_compound_drought_heat_high_geomean          0         2108    0.3026           0.0\n",
      "                                                                climate_risk_compound_drought_vs_heat_ratio          0         2244    0.3339           0.0\n",
      "                            climate_risk_tredecile_weighted_agg_climate_risk_weighted_drought_risk_high_min          0            0    0.0000           0.0\n",
      "                          climate_risk_tredecile_weighted_agg_climate_risk_weighted_drought_risk_medium_min          0            0    0.0000           0.0\n",
      "                                    climate_risk_allrisk_tertile_agg_climate_risk_allrisk_w_all_med_sum_min          0            0    0.0000           0.0\n",
      "                                                             climate_risk_wcompound_w_drought_heat_high_max          0         2244    0.3664           0.0\n",
      "                     climate_risk_sextile_ratio_agg_climate_risk_ratio_unseasonably_cold_high_dominance_min          0            0    0.0000           0.0\n",
      "                   climate_risk_wcompound_tertile_agg_climate_risk_wcompound_w_drought_heat_med_geomean_min          0         1904    0.0000           0.0\n",
      "                           climate_risk_octile_ratio_agg_climate_risk_ratio_heat_stress_high_proportion_min          0            0    0.0000           0.0\n",
      "                       climate_risk_octile_ratio_agg_climate_risk_ratio_heat_stress_elevated_proportion_min          0            0    0.0000           0.0\n",
      "                            climate_risk_octile_ratio_agg_climate_risk_ratio_heat_stress_high_dominance_min          0            0    0.0000           0.0\n",
      "                          climate_risk_quartile_ratio_agg_climate_risk_ratio_heat_stress_high_med_ratio_min          0            0    0.0000           0.0\n",
      "                         climate_risk_quartile_ratio_agg_climate_risk_ratio_heat_stress_high_proportion_min          0            0    0.0000           0.0\n",
      "              climate_risk_compound_med_octile_agg_climate_risk_compound_med_drought_excess_med_geomean_min          0         1904    0.0000           0.0\n",
      "       climate_risk_weighted_quartile_country_month_agg_climate_risk_weighted_excess_precip_risk_medium_min          0            0    0.0000           0.0\n",
      "                   climate_risk_wcompound_tertile_agg_climate_risk_wcompound_w_drought_heat_med_product_min          0            0    0.0000           0.0\n",
      "                            climate_risk_octile_ratio_agg_climate_risk_ratio_heat_stress_high_med_ratio_min          0            0    0.0000           0.0\n",
      "                                      climate_risk_allrisk_octile_agg_climate_risk_allrisk_all_high_max_min          0            0    0.0000           0.0\n",
      "                             climate_risk_compound_med_octile_agg_climate_risk_compound_med_all_med_max_min          0            0    0.0000           0.0\n",
      "                             climate_risk_compound_med_octile_agg_climate_risk_compound_med_all_med_sum_min          0            0    0.0000           0.0\n",
      "                     climate_risk_compound_med_octile_agg_climate_risk_compound_med_heat_excess_med_sum_min          0            0    0.0000           0.0\n",
      "                 climate_risk_compound_med_octile_agg_climate_risk_compound_med_heat_excess_med_product_min          0            0    0.0000           0.0\n",
      "                 climate_risk_product_quartile_agg_climate_risk_product_drought_heat_excess_med_product_min          0            0    0.0000           0.0\n",
      "                                             climate_risk_decile_region_agg_unseasonably_cold_risk_low_mean          0         2244    0.2206           0.0\n",
      "                      climate_risk_octile_ratio_agg_climate_risk_ratio_unseasonably_cold_high_med_ratio_min          0            0    0.0000           0.0\n",
      "        climate_risk_crosslevel_quartile_month_agg_climate_risk_crosslevel_heat_high_excess_med_product_min          0            0    0.0000           0.0\n",
      "                                                       climate_risk_compound_med_drought_excess_med_product          0         2244    0.2813           0.0\n",
      "                                                         climate_risk_compound_med_drought_heat_med_geomean          0         2108    0.3247           0.0\n",
      "                        climate_risk_vigintile_ratio_agg_climate_risk_ratio_heat_stress_high_proportion_min          0            0    0.0000           0.0\n",
      "                         climate_risk_vigintile_ratio_agg_climate_risk_ratio_heat_stress_high_med_ratio_min          0            0    0.0000           0.0\n",
      "                   climate_risk_tredecile_ratio_agg_climate_risk_ratio_unseasonably_cold_high_dominance_min          0            0    0.0000           0.0\n",
      "              climate_risk_tredecile_ratio_agg_climate_risk_ratio_unseasonably_cold_elevated_proportion_min          0            0    0.0000           0.0\n",
      "                           climate_risk_tertile_ratio_agg_climate_risk_ratio_heat_stress_high_med_ratio_min          0            0    0.0000           0.0\n",
      "                          climate_risk_tertile_ratio_agg_climate_risk_ratio_heat_stress_high_proportion_min          0            0    0.0000           0.0\n",
      "            climate_risk_de_compound_quartile_month_agg_climate_risk_de_compound_drought_excess_med_min_min          0            0    0.0000           0.0\n",
      "                      climate_risk_tertile_ratio_agg_climate_risk_ratio_heat_stress_elevated_proportion_min          0            0    0.0000           0.0\n",
      "                           climate_risk_tertile_ratio_agg_climate_risk_ratio_heat_stress_high_dominance_min          0            0    0.0000           0.0\n",
      "                     climate_risk_tertile_ratio_agg_climate_risk_ratio_unseasonably_cold_high_med_ratio_min          0            0    0.0000           0.0\n",
      "                    climate_risk_tertile_ratio_agg_climate_risk_ratio_unseasonably_cold_high_proportion_min          0            0    0.0000           0.0\n",
      "       climate_risk_de_compound_quartile_month_agg_climate_risk_de_compound_drought_excess_high_product_min          0            0    0.0000           0.0\n",
      "                  climate_risk_tredecile_ratio_agg_climate_risk_ratio_unseasonably_cold_high_proportion_min          0            0    0.0000           0.0\n",
      "                     climate_risk_tertile_ratio_agg_climate_risk_ratio_unseasonably_cold_high_dominance_min          0            0    0.0000           0.0\n",
      "                                    climate_risk_allrisk_octile_agg_climate_risk_allrisk_w_all_high_max_min          0            0    0.0000           0.0\n",
      "                        climate_risk_sextile_weighted_agg_climate_risk_weighted_heat_stress_risk_medium_min          0            0    0.0000           0.0\n",
      "                         climate_risk_octile_weighted_agg_climate_risk_weighted_heat_stress_risk_medium_min          0            0    0.0000           0.0\n",
      "                        climate_risk_tredecile_ratio_agg_climate_risk_ratio_heat_stress_high_proportion_min          0            0    0.0000           0.0\n",
      "                    climate_risk_tredecile_ratio_agg_climate_risk_ratio_heat_stress_elevated_proportion_min          0            0    0.0000           0.0\n",
      "                         climate_risk_tredecile_ratio_agg_climate_risk_ratio_heat_stress_high_dominance_min          0            0    0.0000           0.0\n",
      "                   climate_risk_tredecile_ratio_agg_climate_risk_ratio_unseasonably_cold_high_med_ratio_min          0            0    0.0000           0.0\n",
      "       climate_risk_de_compound_quartile_month_agg_climate_risk_de_compound_drought_excess_high_geomean_min          0         1904    0.0000           0.0\n",
      "                          climate_risk_vigintile_weighted_agg_climate_risk_weighted_drought_risk_medium_min          0            0    0.0000           0.0\n",
      "                            climate_risk_vigintile_weighted_agg_climate_risk_weighted_drought_risk_high_min          0            0    0.0000           0.0\n",
      "                        climate_risk_vigintile_weighted_agg_climate_risk_weighted_heat_stress_risk_high_min          0            0    0.0000           0.0\n",
      "                      climate_risk_tredecile_weighted_agg_climate_risk_weighted_heat_stress_risk_medium_min          0            0    0.0000           0.0\n",
      "                    climate_risk_tredecile_weighted_agg_climate_risk_weighted_excess_precip_risk_medium_min          0            0    0.0000           0.0\n",
      "             climate_risk_geomean_quartile_month_agg_climate_risk_geomean_drought_heat_elevated_geomean_min          0         1904    0.0000           0.0\n",
      "                            climate_risk_compound_med_tertile_agg_climate_risk_compound_med_all_med_max_min          0            0    0.0000           0.0\n",
      "                            climate_risk_compound_med_tertile_agg_climate_risk_compound_med_all_med_sum_min          0            0    0.0000           0.0\n",
      "                    climate_risk_compound_med_tertile_agg_climate_risk_compound_med_heat_excess_med_sum_min          0            0    0.0000           0.0\n",
      "                climate_risk_compound_med_tertile_agg_climate_risk_compound_med_heat_excess_med_product_min          0            0    0.0000           0.0\n",
      "             climate_risk_compound_med_tertile_agg_climate_risk_compound_med_drought_excess_med_geomean_min          0         1904    0.0000           0.0\n",
      "                 climate_risk_compound_med_tertile_agg_climate_risk_compound_med_drought_excess_med_sum_min          0            0    0.0000           0.0\n",
      "             climate_risk_compound_med_tertile_agg_climate_risk_compound_med_drought_excess_med_product_min          0            0    0.0000           0.0\n",
      "                    climate_risk_quintile_ratio_agg_climate_risk_ratio_unseasonably_cold_high_dominance_min          0            0    0.0000           0.0\n",
      "               climate_risk_quintile_ratio_agg_climate_risk_ratio_unseasonably_cold_elevated_proportion_min          0            0    0.0000           0.0\n",
      "                                                                climate_risk_compound_drought_heat_high_min          0         1258    0.2910           0.0\n",
      "                  climate_risk_geomean_quartile_month_agg_climate_risk_geomean_cold_drought_med_geomean_min          0         1904    0.0000           0.0\n",
      "                    climate_risk_vigintile_weighted_agg_climate_risk_weighted_excess_precip_risk_medium_min          0            0    0.0000           0.0\n",
      "                        climate_risk_geomean_sextile_agg_climate_risk_geomean_w_heat_excess_med_geomean_min          0         1904    0.0000           0.0\n",
      "            climate_risk_compound_med_quartile_month_agg_climate_risk_compound_med_drought_heat_med_min_min          0            0    0.0000           0.0\n",
      "                           climate_risk_sextile_ratio_agg_climate_risk_ratio_heat_stress_high_dominance_min          0            0    0.0000           0.0\n",
      "                     climate_risk_sextile_ratio_agg_climate_risk_ratio_unseasonably_cold_high_med_ratio_min          0            0    0.0000           0.0\n",
      "                    climate_risk_sextile_ratio_agg_climate_risk_ratio_unseasonably_cold_high_proportion_min          0            0    0.0000           0.0\n",
      "                 climate_risk_geomean_quartile_month_agg_climate_risk_geomean_w_heat_excess_med_geomean_min          0         1904    0.0000           0.0\n",
      "                                                         climate_risk_wcompound_w_drought_heat_high_product          0         1258    0.1916           0.0\n",
      "                                                         climate_risk_wcompound_w_drought_heat_high_geomean          0         2108    0.2555           0.0\n",
      "                                                             climate_risk_wcompound_w_drought_heat_high_min          0         1258    0.2475           0.0\n",
      "                      climate_risk_vigintile_weighted_agg_climate_risk_weighted_heat_stress_risk_medium_min          0            0    0.0000           0.0\n",
      "                                                            climate_risk_monthly_agg_drought_risk_high_mean          0         1479    0.0000           0.0\n",
      "                                                             climate_risk_monthly_agg_drought_risk_high_max          0            0    0.0000           0.0\n",
      "                                                             climate_risk_monthly_agg_drought_risk_high_min          0            0    0.0000           0.0\n",
      "                                                             climate_risk_monthly_agg_drought_risk_high_std          0         1326    0.0000           0.0\n",
      "                climate_risk_sextile_ratio_agg_climate_risk_ratio_unseasonably_cold_elevated_proportion_min          0            0    0.0000           0.0\n",
      "                                                          climate_risk_wcompound_w_drought_heat_med_product          0         1156    0.1888           0.0\n",
      "                                                          climate_risk_wcompound_w_drought_heat_med_geomean          0         2108    0.2518           0.0\n",
      "                                                        climate_risk_wcompound_w_drought_excess_med_product          0         2244    0.2322           0.0\n",
      "                                                             climate_risk_compound_med_drought_heat_med_min          0         1156    0.3225           0.0\n",
      "                         climate_risk_tredecile_ratio_agg_climate_risk_ratio_heat_stress_high_med_ratio_min          0            0    0.0000           0.0\n",
      "                                   climate_risk_allrisk_tertile_agg_climate_risk_allrisk_w_all_high_max_min          0            0    0.0000           0.0\n",
      "                                 climate_risk_allrisk_tertile_agg_climate_risk_allrisk_all_elevated_max_min          0            0    0.0000           0.0\n",
      "           climate_risk_geomean_quartile_month_agg_climate_risk_geomean_drought_excess_elevated_geomean_min          0         1904    0.0000           0.0\n",
      "                  climate_risk_wcompound_tertile_agg_climate_risk_wcompound_w_drought_heat_high_product_min          0            0    0.0000           0.0\n",
      "                  climate_risk_wcompound_tertile_agg_climate_risk_wcompound_w_drought_heat_high_geomean_min          0         1904    0.0000           0.0\n",
      "                      climate_risk_wcompound_tertile_agg_climate_risk_wcompound_w_drought_heat_high_min_min          0            0    0.0000           0.0\n",
      "                                     climate_risk_allrisk_tertile_agg_climate_risk_allrisk_all_high_max_min          0            0    0.0000           0.0\n",
      "                                     climate_risk_allrisk_tertile_agg_climate_risk_allrisk_all_high_sum_min          0            0    0.0000           0.0\n",
      "                                    climate_risk_allrisk_tertile_agg_climate_risk_allrisk_all_high_mean_min          0            0    0.0000           0.0\n",
      "                                      climate_risk_allrisk_tertile_agg_climate_risk_allrisk_all_med_min_max          0            0    0.0000           0.0\n",
      "                                                            climate_risk_compound_drought_heat_elevated_sum          0         2244    0.4438           0.0\n",
      "                                 climate_risk_allrisk_tertile_agg_climate_risk_allrisk_all_elevated_sum_min          0            0    0.0000           0.0\n",
      "              climate_risk_geomean_quartile_month_agg_climate_risk_geomean_heat_excess_elevated_geomean_min          0         1904    0.0000           0.0\n",
      "        climate_risk_compound_med_quartile_month_agg_climate_risk_compound_med_drought_heat_med_product_min          0            0    0.0000           0.0\n",
      "                                      climate_risk_allrisk_tertile_agg_climate_risk_allrisk_all_med_min_min          0            0    0.0000           0.0\n",
      "                                     climate_risk_allrisk_tertile_agg_climate_risk_allrisk_all_med_mean_min          0            0    0.0000           0.0\n",
      "                                    climate_risk_allrisk_tertile_agg_climate_risk_allrisk_w_all_med_max_min          0            0    0.0000           0.0\n",
      "                             climate_risk_decile_weighted_agg_climate_risk_weighted_drought_risk_medium_min          0            0    0.0000           0.0\n",
      "                       climate_risk_decile_weighted_agg_climate_risk_weighted_excess_precip_risk_medium_min          0            0    0.0000           0.0\n",
      "               climate_risk_compound_med_tertile_agg_climate_risk_compound_med_drought_heat_med_geomean_min          0         1904    0.0000           0.0\n",
      "                        climate_risk_tredecile_weighted_agg_climate_risk_weighted_heat_stress_risk_high_min          0            0    0.0000           0.0\n",
      "        climate_risk_compound_med_quartile_month_agg_climate_risk_compound_med_drought_heat_med_geomean_min          0         1904    0.0000           0.0\n",
      "      climate_risk_compound_med_quartile_month_agg_climate_risk_compound_med_drought_excess_med_product_min          0            0    0.0000           0.0\n",
      "      climate_risk_compound_med_quartile_month_agg_climate_risk_compound_med_drought_excess_med_geomean_min          0         1904    0.0000           0.0\n",
      "               climate_risk_compound_med_tertile_agg_climate_risk_compound_med_drought_heat_med_product_min          0            0    0.0000           0.0\n",
      "                   climate_risk_compound_med_tertile_agg_climate_risk_compound_med_drought_heat_med_sum_min          0            0    0.0000           0.0\n",
      "                   climate_risk_compound_med_tertile_agg_climate_risk_compound_med_drought_heat_med_max_min          0            0    0.0000           0.0\n",
      "                   climate_risk_compound_med_tertile_agg_climate_risk_compound_med_drought_heat_med_min_min          0            0    0.0000           0.0\n",
      "                         climate_risk_decile_weighted_agg_climate_risk_weighted_heat_stress_risk_medium_min          0            0    0.0000           0.0\n"
     ]
    }
   ],
   "source": [
    "# Show top features\n",
    "print(\"\\nBottom 300 Features by Significant Correlation Count:\")\n",
    "print(\"=\"*80)\n",
    "print(feature_analysis.tail(300).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "857dfbe0",
   "metadata": {
    "_cell_guid": "27248cae-0cc5-4ebd-9ba8-4cabe5a17147",
    "_uuid": "ea638cbf-7225-421e-a2c0-5ce3049fad71",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:59:35.172511Z",
     "iopub.status.busy": "2026-01-30T16:59:35.172128Z",
     "iopub.status.idle": "2026-01-30T16:59:38.781536Z",
     "shell.execute_reply": "2026-01-30T16:59:38.780190Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.633569,
     "end_time": "2026-01-30T16:59:38.784125",
     "exception": false,
     "start_time": "2026-01-30T16:59:35.150556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " SCORING WITH TOP 5 FEATURES\n",
      "================================================================================\n",
      "\n",
      "Feature selection strategy: sig_count\n",
      "\n",
      "Selected top 5 features:\n",
      " 1. climate_risk_wsum_quartile_agg_climate_risk_wsum_w_non_drought_med_sum_mean\n",
      "  sig_count: 904, max_corr: 0.9711, avg_sig_corr: 0.7414\n",
      " 2. climate_risk_wsum_quartile_agg_climate_risk_wsum_w_non_drought_med_sum_sum\n",
      "  sig_count: 848, max_corr: 0.9433, avg_sig_corr: 0.7337\n",
      " 3. climate_risk_wsum_quartile_agg_climate_risk_wsum_w2_all_med_sum_mean\n",
      "  sig_count: 829, max_corr: 0.9590, avg_sig_corr: 0.7183\n",
      " 4. climate_risk_compound_med_sextile_agg_climate_risk_compound_med_drought_excess_med_product_sum\n",
      "  sig_count: 801, max_corr: 0.9404, avg_sig_corr: 0.7164\n",
      " 5. climate_risk_de_compound_quartile_agg_climate_risk_de_compound_w_drought_excess_med_min_max\n",
      "  sig_count: 800, max_corr: 0.9694, avg_sig_corr: 0.7587\n",
      "\n",
      "CFCS Score (Top 5 features):\n",
      " CFCS: 0.73272\n",
      " Avg Sig Corr: 0.733689\n",
      " Max Corr: 0.971102\n",
      " Sig Count: 4182/11220 (37.27%)\n",
      " Features: 5\n"
     ]
    }
   ],
   "source": [
    "# SCORING WITH TOP 10 FEATURES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\" SCORING WITH TOP {TOP_N_FEATURES} FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nFeature selection strategy: {FEATURE_SELECTION_STRATEGY}\")\n",
    "\n",
    "if FEATURE_SELECTION_STRATEGY == 'sig_count':\n",
    "    top_features = feature_analysis.nlargest(TOP_N_FEATURES, 'sig_count')['feature'].tolist()\n",
    "elif FEATURE_SELECTION_STRATEGY == 'max_corr':\n",
    "    top_features = feature_analysis.nlargest(TOP_N_FEATURES, 'max_corr')['feature'].tolist()\n",
    "elif FEATURE_SELECTION_STRATEGY == 'avg_sig_corr':\n",
    "    top_features = feature_analysis.nlargest(TOP_N_FEATURES, 'avg_sig_corr')['feature'].tolist()\n",
    "elif FEATURE_SELECTION_STRATEGY == 'weighted':\n",
    "    # Weighted combination: normalize each metric and combine\n",
    "    fa = feature_analysis.copy()\n",
    "    # Normalize each metric to [0, 1]\n",
    "    fa['sig_count_norm'] = fa['sig_count'] / (fa['sig_count'].max() + 1e-6)\n",
    "    fa['max_corr_norm'] = fa['max_corr'] / (fa['max_corr'].max() + 1e-6)\n",
    "    fa['avg_sig_corr_norm'] = fa['avg_sig_corr'] / (fa['avg_sig_corr'].max() + 1e-6)\n",
    "    # Weighted score (adjust weights as needed)\n",
    "    fa['combined_score'] = (0.4 * fa['sig_count_norm'] +\n",
    "                            0.3 * fa['max_corr_norm'] +\n",
    "                            0.3 * fa['avg_sig_corr_norm'])\n",
    "    top_features = fa.nlargest(TOP_N_FEATURES, 'combined_score')['feature'].tolist()\n",
    "    print(f\"\\nWeighted scoring (sig_count: 0.4, max_corr: 0.3, avg_sig_corr: 0.3)\")\n",
    "else:\n",
    "    # Default to sig_count\n",
    "    top_features = feature_analysis.nlargest(TOP_N_FEATURES, 'sig_count')['feature'].tolist()\n",
    "\n",
    "print(f\"\\nSelected top {TOP_N_FEATURES} features:\")\n",
    "for i, feat in enumerate(top_features, 1):\n",
    "    row = feature_analysis[feature_analysis['feature'] == feat].iloc[0]\n",
    "    print(f\" {i}. {feat}\")\n",
    "    print(f\"  sig_count: {row['sig_count']}, max_corr: {row['max_corr']:.4f}, avg_sig_corr: {row['avg_sig_corr']:.4f}\")\n",
    "\n",
    "# Compute CFCS score\n",
    "def compute_cfcs(df, climate_cols=None):\n",
    "    \"\"\"Compute CFCS score.\"\"\"\n",
    "    if climate_cols is None:\n",
    "        climate_cols = [c for c in df.columns if c.startswith('climate_risk_')]\n",
    "\n",
    "    futures_cols = [c for c in df.columns if c.startswith('futures_')]\n",
    "\n",
    "    feature_stats = {col: {'sig_count': 0, 'total': 0, 'max_corr': 0, 'sig_corrs': []}\n",
    "                     for col in climate_cols}\n",
    "\n",
    "    # Pre-group data once\n",
    "    grouped = df.groupby(['country_name', 'date_on_month'])\n",
    "\n",
    "    # Process each group once\n",
    "    for (country, month), group_df in grouped:\n",
    "        if len(group_df) < 2:\n",
    "            continue\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        climate_data = group_df[climate_cols].values\n",
    "        futures_data = group_df[futures_cols].values\n",
    "\n",
    "        # Pre-compute standard deviations\n",
    "        climate_std = np.std(climate_data, axis=0)\n",
    "        futures_std = np.std(futures_data, axis=0)\n",
    "\n",
    "        valid_climate = climate_std > 0\n",
    "        valid_futures = futures_std > 0\n",
    "\n",
    "        # For each valid climate feature\n",
    "        for i, clim_col in enumerate(climate_cols):\n",
    "            if not valid_climate[i]:\n",
    "                continue\n",
    "\n",
    "            for j in range(len(futures_cols)):\n",
    "                if not valid_futures[j]:\n",
    "                    continue\n",
    "\n",
    "                # Compute correlation using numpy\n",
    "                corr = np.corrcoef(climate_data[:, i], futures_data[:, j])[0, 1]\n",
    "\n",
    "                if not np.isnan(corr):\n",
    "                    abs_corr = abs(corr)\n",
    "                    feature_stats[clim_col]['total'] += 1\n",
    "                    feature_stats[clim_col]['max_corr'] = max(feature_stats[clim_col]['max_corr'], abs_corr)\n",
    "\n",
    "                    if abs_corr >= SIGNIFICANCE_THRESHOLD:\n",
    "                        feature_stats[clim_col]['sig_count'] += 1\n",
    "                        feature_stats[clim_col]['sig_corrs'].append(abs_corr)\n",
    "\n",
    "    avg_sig_corr = np.mean([np.mean(stats['sig_corrs']) if stats['sig_corrs'] else 0\n",
    "                             for stats in feature_stats.values()])\n",
    "\n",
    "    total_sig_count = sum(stats['sig_count'] for stats in feature_stats.values())\n",
    "    total_correlations = sum(stats['total'] for stats in feature_stats.values())\n",
    "    sig_pct = (total_sig_count / total_correlations * 100) if total_correlations > 0 else 0\n",
    "\n",
    "    max_corr = max(stats['max_corr'] for stats in feature_stats.values()) if feature_stats else 0\n",
    "\n",
    "    cfcs = (0.5 * avg_sig_corr) + (0.3 * max_corr) + (0.2 * sig_pct / 100)\n",
    "\n",
    "    return {\n",
    "        'cfcs': round(cfcs, 6),\n",
    "        'avg_sig_corr': round(avg_sig_corr, 6),\n",
    "        'max_corr': round(max_corr, 6),\n",
    "        'sig_count': total_sig_count,\n",
    "        'total': total_correlations,\n",
    "        'sig_pct': round(sig_pct, 4),\n",
    "        'n_features': len(climate_cols)\n",
    "    }\n",
    "\n",
    "# Compute score with top features only\n",
    "top_features_score = compute_cfcs(baseline_df, top_features)\n",
    "\n",
    "print(f\"\\nCFCS Score (Top {TOP_N_FEATURES} features):\")\n",
    "print(f\" CFCS: {top_features_score['cfcs']}\")\n",
    "print(f\" Avg Sig Corr: {top_features_score['avg_sig_corr']}\")\n",
    "print(f\" Max Corr: {top_features_score['max_corr']}\")\n",
    "print(f\" Sig Count: {top_features_score['sig_count']}/{top_features_score['total']} ({top_features_score['sig_pct']:.2f}%)\")\n",
    "print(f\" Features: {top_features_score['n_features']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3ab9fd3",
   "metadata": {
    "_cell_guid": "21e05dce-6bca-4751-aa09-669e0d4e1e58",
    "_uuid": "12195868-ecb6-4610-855b-65fa4dd57d7a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-30T16:59:38.821912Z",
     "iopub.status.busy": "2026-01-30T16:59:38.821416Z",
     "iopub.status.idle": "2026-01-30T16:59:46.198239Z",
     "shell.execute_reply": "2026-01-30T16:59:46.196780Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 7.398903,
     "end_time": "2026-01-30T16:59:46.200930",
     "exception": false,
     "start_time": "2026-01-30T16:59:38.802027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " CREATING SUBMISSION\n",
      "================================================================================\n",
      "\n",
      "Submission saved: /kaggle/working/submission.csv\n",
      " Rows: 219,161\n",
      " Columns: 26\n",
      " Climate features: 5\n",
      " Futures columns: 17\n",
      "\n",
      "================================================================================\n",
      " COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Summary:\n",
      " Total features created: 1494\n",
      " Top 5 features selected for submission\n",
      " CFCS Score: 0.73272\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# CREATE SUBMISSION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" CREATING SUBMISSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get futures columns\n",
    "futures_cols = [c for c in baseline_df.columns if c.startswith('futures_')]\n",
    "\n",
    "# Filter to only include top N features (not all climate_risk features)\n",
    "required_cols = ['ID', 'date_on', 'country_name', 'region_name'] + futures_cols + top_features\n",
    "submission = baseline_df[required_cols].copy()\n",
    "\n",
    "# Fill any remaining nulls with 0\n",
    "if submission.isnull().sum().sum() > 0:\n",
    "    submission = submission.fillna(0)\n",
    "\n",
    "# Save submission\n",
    "import os\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "output_file = f'{OUTPUT_PATH}submission.csv'\n",
    "submission.to_csv(output_file, index=False)\n",
    "\n",
    "climate_cols = [c for c in submission.columns if c.startswith('climate_risk_')]\n",
    "futures_cols = [c for c in submission.columns if c.startswith('futures_')]\n",
    "\n",
    "print(f\"\\nSubmission saved: {output_file}\")\n",
    "print(f\" Rows: {len(submission):,}\")\n",
    "print(f\" Columns: {len(submission.columns)}\")\n",
    "print(f\" Climate features: {len(climate_cols)}\")\n",
    "print(f\" Futures columns: {len(futures_cols)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\" Total features created: {len(ALL_NEW_FEATURES)}\")\n",
    "print(f\" Top {TOP_N_FEATURES} features selected for submission\")\n",
    "print(f\" CFCS Score: {top_features_score['cfcs']}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 15008526,
     "sourceId": 126158,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 448.260262,
   "end_time": "2026-01-30T16:59:48.724968",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-30T16:52:20.464706",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
